From ed09329aac96516014249bcafec4c4b414927d2b Mon Sep 17 00:00:00 2001
From: Zhao Qiang <qiang.zhao@nxp.com>
Date: Thu, 16 Feb 2017 14:33:13 +0800
Subject: [PATCH 125/141] update fsl-mc

Signed-off-by: Zhao Qiang <qiang.zhao@nxp.com>
---
 drivers/staging/fsl-mc/bus/Kconfig                 |   21 +
 drivers/staging/fsl-mc/bus/Makefile                |    9 +-
 drivers/staging/fsl-mc/bus/dpbp.c                  |  285 +++--
 drivers/staging/fsl-mc/bus/dpcon.c                 |  431 +++++++
 drivers/staging/fsl-mc/bus/dpio/Makefile           |    9 +
 drivers/staging/fsl-mc/bus/dpio/dpio-drv.c         |  404 +++++++
 drivers/staging/fsl-mc/bus/dpio/dpio-drv.h         |   33 +
 drivers/staging/fsl-mc/bus/dpio/dpio.c             |  492 ++++++++
 drivers/staging/fsl-mc/bus/dpio/dpio_service.c     |  857 ++++++++++++++
 drivers/staging/fsl-mc/bus/dpio/fsl_dpio.h         |  475 ++++++++
 drivers/staging/fsl-mc/bus/dpio/fsl_dpio_cmd.h     |  187 +++
 drivers/staging/fsl-mc/bus/dpio/fsl_qbman_base.h   |  123 ++
 drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h |  753 ++++++++++++
 drivers/staging/fsl-mc/bus/dpio/qbman_debug.c      |  846 ++++++++++++++
 drivers/staging/fsl-mc/bus/dpio/qbman_debug.h      |  136 +++
 drivers/staging/fsl-mc/bus/dpio/qbman_portal.c     | 1218 ++++++++++++++++++++
 drivers/staging/fsl-mc/bus/dpio/qbman_portal.h     |  260 +++++
 drivers/staging/fsl-mc/bus/dpio/qbman_private.h    |  173 +++
 drivers/staging/fsl-mc/bus/dpio/qbman_sys.h        |  307 +++++
 drivers/staging/fsl-mc/bus/dpio/qbman_sys_decl.h   |   86 ++
 drivers/staging/fsl-mc/bus/dpio/qbman_test.c       |  664 +++++++++++
 drivers/staging/fsl-mc/bus/dpmcp-cmd.h             |  121 +-
 drivers/staging/fsl-mc/bus/dpmcp.c                 |  164 +--
 drivers/staging/fsl-mc/bus/dpmcp.h                 |  189 +--
 drivers/staging/fsl-mc/bus/dpmng-cmd.h             |    8 +-
 drivers/staging/fsl-mc/bus/dpmng.c                 |   29 +-
 drivers/staging/fsl-mc/bus/dprc-cmd.h              |   75 +-
 drivers/staging/fsl-mc/bus/dprc-driver.c           |  674 ++++++++++-
 drivers/staging/fsl-mc/bus/dprc.c                  |  518 +++++++--
 drivers/staging/fsl-mc/bus/mc-allocator.c          |  259 ++++-
 drivers/staging/fsl-mc/bus/mc-bus.c                |  702 +++++++++--
 drivers/staging/fsl-mc/bus/mc-ioctl.h              |   25 +
 drivers/staging/fsl-mc/bus/mc-restool.c            |  312 +++++
 drivers/staging/fsl-mc/bus/mc-sys.c                |  454 +++++++-
 drivers/staging/fsl-mc/include/dpbp-cmd.h          |  106 +-
 drivers/staging/fsl-mc/include/dpbp.h              |  205 +++-
 drivers/staging/fsl-mc/include/dpcon-cmd.h         |  209 +++-
 drivers/staging/fsl-mc/include/dpcon.h             |  421 +++++++
 drivers/staging/fsl-mc/include/dpmng.h             |   23 +-
 drivers/staging/fsl-mc/include/dprc.h              |  364 ++++--
 drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h      |  774 +++++++++++++
 drivers/staging/fsl-mc/include/fsl_dpaa2_io.h      |  693 +++++++++++
 drivers/staging/fsl-mc/include/mc-cmd.h            |   91 +-
 drivers/staging/fsl-mc/include/mc-private.h        |   75 +-
 drivers/staging/fsl-mc/include/mc-sys.h            |   66 +-
 drivers/staging/fsl-mc/include/mc.h                |   43 +
 drivers/staging/fsl-mc/include/net.h               |  480 ++++++++
 47 files changed, 13919 insertions(+), 930 deletions(-)
 create mode 100644 drivers/staging/fsl-mc/bus/dpcon.c
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/Makefile
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/dpio-drv.c
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/dpio-drv.h
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/dpio.c
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/dpio_service.c
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/fsl_dpio.h
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/fsl_dpio_cmd.h
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/fsl_qbman_base.h
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/qbman_debug.c
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/qbman_debug.h
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/qbman_portal.c
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/qbman_portal.h
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/qbman_private.h
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/qbman_sys.h
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/qbman_sys_decl.h
 create mode 100644 drivers/staging/fsl-mc/bus/dpio/qbman_test.c
 create mode 100644 drivers/staging/fsl-mc/bus/mc-ioctl.h
 create mode 100644 drivers/staging/fsl-mc/bus/mc-restool.c
 create mode 100644 drivers/staging/fsl-mc/include/dpcon.h
 create mode 100644 drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h
 create mode 100644 drivers/staging/fsl-mc/include/fsl_dpaa2_io.h
 create mode 100644 drivers/staging/fsl-mc/include/net.h

diff --git a/drivers/staging/fsl-mc/bus/Kconfig b/drivers/staging/fsl-mc/bus/Kconfig
index 0d779d9..8bef5b8 100644
--- a/drivers/staging/fsl-mc/bus/Kconfig
+++ b/drivers/staging/fsl-mc/bus/Kconfig
@@ -21,4 +21,25 @@ config FSL_MC_BUS
 	  Only enable this option when building the kernel for
 	  Freescale QorQIQ LS2xxxx SoCs.
 
+config FSL_MC_RESTOOL
+        tristate "Freescale Management Complex (MC) restool driver"
+        depends on FSL_MC_BUS
+        help
+          Driver that provides kernel support for the Freescale Management
+	  Complex resource manager user-space tool.
 
+config FSL_MC_DPIO
+	tristate "Freescale Data Path I/O (DPIO) driver"
+	depends on FSL_MC_BUS
+	help
+	  Driver for Freescale Data Path I/O (DPIO) devices.
+	  A DPIO device provides queue and buffer management facilities
+	  for software to interact with other Data Path devices. This
+	  driver does not expose the DPIO device individually, but
+	  groups them under a service layer API.
+
+config FSL_QBMAN_DEBUG
+	tristate "Freescale QBMAN Debug APIs"
+	depends on FSL_MC_DPIO
+	help
+	  QBMan debug assistant APIs.
diff --git a/drivers/staging/fsl-mc/bus/Makefile b/drivers/staging/fsl-mc/bus/Makefile
index 25433a9..f29399c 100644
--- a/drivers/staging/fsl-mc/bus/Makefile
+++ b/drivers/staging/fsl-mc/bus/Makefile
@@ -14,4 +14,11 @@ mc-bus-driver-objs := mc-bus.o \
 		      dprc-driver.o \
 		      mc-allocator.o \
 		      dpmcp.o \
-		      dpbp.o
+		      dpbp.o \
+		      dpcon.o
+
+# MC restool kernel support
+obj-$(CONFIG_FSL_MC_RESTOOL) += mc-restool.o
+
+# MC DPIO driver
+obj-$(CONFIG_FSL_MC_DPIO) += dpio/
diff --git a/drivers/staging/fsl-mc/bus/dpbp.c b/drivers/staging/fsl-mc/bus/dpbp.c
index d99ab6d..481fd9b 100644
--- a/drivers/staging/fsl-mc/bus/dpbp.c
+++ b/drivers/staging/fsl-mc/bus/dpbp.c
@@ -1,47 +1,52 @@
-/* Copyright 2013-2014 Freescale Semiconductor Inc.
-*
-* Redistribution and use in source and binary forms, with or without
-* modification, are permitted provided that the following conditions are met:
-* * Redistributions of source code must retain the above copyright
-* notice, this list of conditions and the following disclaimer.
-* * Redistributions in binary form must reproduce the above copyright
-* notice, this list of conditions and the following disclaimer in the
-* documentation and/or other materials provided with the distribution.
-* * Neither the name of the above-listed copyright holders nor the
-* names of any contributors may be used to endorse or promote products
-* derived from this software without specific prior written permission.
-*
-*
-* ALTERNATIVELY, this software may be distributed under the terms of the
-* GNU General Public License ("GPL") as published by the Free Software
-* Foundation, either version 2 of that License or (at your option) any
-* later version.
-*
-* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
-* AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-* IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
-* ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
-* LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
-* CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
-* SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
-* INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
-* CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
-* ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
-* POSSIBILITY OF SUCH DAMAGE.
-*/
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ * * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * * Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in the
+ * documentation and/or other materials provided with the distribution.
+ * * Neither the name of the above-listed copyright holders nor the
+ * names of any contributors may be used to endorse or promote products
+ * derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
 #include "../include/mc-sys.h"
 #include "../include/mc-cmd.h"
 #include "../include/dpbp.h"
 #include "../include/dpbp-cmd.h"
 
-int dpbp_open(struct fsl_mc_io *mc_io, int dpbp_id, uint16_t *token)
+int dpbp_open(struct fsl_mc_io *mc_io,
+	      uint32_t cmd_flags,
+	      int dpbp_id,
+	      uint16_t *token)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_OPEN,
-					  MC_CMD_PRI_LOW, 0);
+					  cmd_flags,
+					  0);
+
 	cmd.params[0] |= mc_enc(0, 32, dpbp_id);
 
 	/* send command to mc*/
@@ -50,18 +55,20 @@ int dpbp_open(struct fsl_mc_io *mc_io, int dpbp_id, uint16_t *token)
 		return err;
 
 	/* retrieve response parameters */
-	*token = MC_CMD_HDR_READ_TOKEN(cmd.header);
+	*token = get_mc_cmd_hdr_token(cmd.header);
 
 	return err;
 }
 EXPORT_SYMBOL(dpbp_open);
 
-int dpbp_close(struct fsl_mc_io *mc_io, uint16_t token)
+int dpbp_close(struct fsl_mc_io *mc_io,
+	       uint32_t cmd_flags,
+	       uint16_t token)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
-	cmd.header = mc_encode_cmd_header(DPBP_CMDID_CLOSE, MC_CMD_PRI_HIGH,
+	cmd.header = mc_encode_cmd_header(DPBP_CMDID_CLOSE, cmd_flags,
 					  token);
 
 	/* send command to mc*/
@@ -70,8 +77,10 @@ int dpbp_close(struct fsl_mc_io *mc_io, uint16_t token)
 EXPORT_SYMBOL(dpbp_close);
 
 int dpbp_create(struct fsl_mc_io *mc_io,
+		uint16_t dprc_token,
+		uint32_t cmd_flags,
 		const struct dpbp_cfg *cfg,
-		uint16_t *token)
+		uint32_t *object_id)
 {
 	struct mc_command cmd = { 0 };
 	int err;
@@ -80,7 +89,8 @@ int dpbp_create(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_CREATE,
-					  MC_CMD_PRI_LOW, 0);
+					  cmd_flags,
+					  dprc_token);
 
 	/* send command to mc*/
 	err = mc_send_command(mc_io, &cmd);
@@ -88,29 +98,36 @@ int dpbp_create(struct fsl_mc_io *mc_io,
 		return err;
 
 	/* retrieve response parameters */
-	*token = MC_CMD_HDR_READ_TOKEN(cmd.header);
+	*object_id = get_mc_cmd_create_object_id(&cmd);
 
 	return 0;
 }
 
-int dpbp_destroy(struct fsl_mc_io *mc_io, uint16_t token)
+int dpbp_destroy(struct fsl_mc_io *mc_io,
+		 uint16_t dprc_token,
+		uint32_t cmd_flags,
+		uint32_t object_id)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_DESTROY,
-					  MC_CMD_PRI_LOW, token);
-
+					  cmd_flags,
+					  dprc_token);
+	/* set object id to destroy */
+	set_mc_cmd_destroy_object_id(&cmd, object_id);
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
 
-int dpbp_enable(struct fsl_mc_io *mc_io, uint16_t token)
+int dpbp_enable(struct fsl_mc_io *mc_io,
+		uint32_t cmd_flags,
+		uint16_t token)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
-	cmd.header = mc_encode_cmd_header(DPBP_CMDID_ENABLE, MC_CMD_PRI_LOW,
+	cmd.header = mc_encode_cmd_header(DPBP_CMDID_ENABLE, cmd_flags,
 					  token);
 
 	/* send command to mc*/
@@ -118,25 +135,31 @@ int dpbp_enable(struct fsl_mc_io *mc_io, uint16_t token)
 }
 EXPORT_SYMBOL(dpbp_enable);
 
-int dpbp_disable(struct fsl_mc_io *mc_io, uint16_t token)
+int dpbp_disable(struct fsl_mc_io *mc_io,
+		 uint32_t cmd_flags,
+		 uint16_t token)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_DISABLE,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
 EXPORT_SYMBOL(dpbp_disable);
 
-int dpbp_is_enabled(struct fsl_mc_io *mc_io, uint16_t token, int *en)
+int dpbp_is_enabled(struct fsl_mc_io *mc_io,
+		    uint32_t cmd_flags,
+		    uint16_t token,
+		    int *en)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 	/* prepare command */
-	cmd.header = mc_encode_cmd_header(DPBP_CMDID_IS_ENABLED, MC_CMD_PRI_LOW,
+	cmd.header = mc_encode_cmd_header(DPBP_CMDID_IS_ENABLED, cmd_flags,
 					  token);
 
 	/* send command to mc*/
@@ -150,53 +173,59 @@ int dpbp_is_enabled(struct fsl_mc_io *mc_io, uint16_t token, int *en)
 	return 0;
 }
 
-int dpbp_reset(struct fsl_mc_io *mc_io, uint16_t token)
+int dpbp_reset(struct fsl_mc_io *mc_io,
+	       uint32_t cmd_flags,
+	       uint16_t token)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_RESET,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
+EXPORT_SYMBOL(dpbp_reset);
 
-int dpbp_set_irq(struct fsl_mc_io *mc_io,
-		 uint16_t token,
-		 uint8_t irq_index,
-		 uint64_t irq_paddr,
-		 uint32_t irq_val,
-		 int user_irq_id)
+int dpbp_set_irq(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
+		 uint16_t		token,
+		 uint8_t		irq_index,
+		 struct dpbp_irq_cfg	*irq_cfg)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_SET_IRQ,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
+
 	cmd.params[0] |= mc_enc(0, 8, irq_index);
-	cmd.params[0] |= mc_enc(32, 32, irq_val);
-	cmd.params[1] |= mc_enc(0, 64, irq_paddr);
-	cmd.params[2] |= mc_enc(0, 32, user_irq_id);
+	cmd.params[0] |= mc_enc(32, 32, irq_cfg->val);
+	cmd.params[1] |= mc_enc(0, 64, irq_cfg->addr);
+	cmd.params[2] |= mc_enc(0, 32, irq_cfg->irq_num);
 
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
 
-int dpbp_get_irq(struct fsl_mc_io *mc_io,
-		 uint16_t token,
-		 uint8_t irq_index,
-		 int *type,
-		 uint64_t *irq_paddr,
-		 uint32_t *irq_val,
-		 int *user_irq_id)
+int dpbp_get_irq(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
+		 uint16_t		token,
+		 uint8_t		irq_index,
+		 int			*type,
+		 struct dpbp_irq_cfg	*irq_cfg)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_GET_IRQ,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
+
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
@@ -205,14 +234,16 @@ int dpbp_get_irq(struct fsl_mc_io *mc_io,
 		return err;
 
 	/* retrieve response parameters */
-	*irq_val = (uint32_t)mc_dec(cmd.params[0], 0, 32);
-	*irq_paddr = (uint64_t)mc_dec(cmd.params[1], 0, 64);
-	*user_irq_id = (int)mc_dec(cmd.params[2], 0, 32);
+	irq_cfg->val = (uint32_t)mc_dec(cmd.params[0], 0, 32);
+	irq_cfg->addr = (uint64_t)mc_dec(cmd.params[1], 0, 64);
+	irq_cfg->irq_num = (int)mc_dec(cmd.params[2], 0, 32);
 	*type = (int)mc_dec(cmd.params[2], 32, 32);
+
 	return 0;
 }
 
 int dpbp_set_irq_enable(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
 			uint16_t token,
 			uint8_t irq_index,
 			uint8_t en)
@@ -221,7 +252,9 @@ int dpbp_set_irq_enable(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_SET_IRQ_ENABLE,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
+
 	cmd.params[0] |= mc_enc(0, 8, en);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
@@ -230,6 +263,7 @@ int dpbp_set_irq_enable(struct fsl_mc_io *mc_io,
 }
 
 int dpbp_get_irq_enable(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
 			uint16_t token,
 			uint8_t irq_index,
 			uint8_t *en)
@@ -239,7 +273,9 @@ int dpbp_get_irq_enable(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_GET_IRQ_ENABLE,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
+
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
@@ -253,6 +289,7 @@ int dpbp_get_irq_enable(struct fsl_mc_io *mc_io,
 }
 
 int dpbp_set_irq_mask(struct fsl_mc_io *mc_io,
+		      uint32_t cmd_flags,
 		      uint16_t token,
 		      uint8_t irq_index,
 		      uint32_t mask)
@@ -261,7 +298,9 @@ int dpbp_set_irq_mask(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_SET_IRQ_MASK,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
+
 	cmd.params[0] |= mc_enc(0, 32, mask);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
@@ -270,6 +309,7 @@ int dpbp_set_irq_mask(struct fsl_mc_io *mc_io,
 }
 
 int dpbp_get_irq_mask(struct fsl_mc_io *mc_io,
+		      uint32_t cmd_flags,
 		      uint16_t token,
 		      uint8_t irq_index,
 		      uint32_t *mask)
@@ -279,7 +319,9 @@ int dpbp_get_irq_mask(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_GET_IRQ_MASK,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
+
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
@@ -293,6 +335,7 @@ int dpbp_get_irq_mask(struct fsl_mc_io *mc_io,
 }
 
 int dpbp_get_irq_status(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
 			uint16_t token,
 			uint8_t irq_index,
 			uint32_t *status)
@@ -302,7 +345,10 @@ int dpbp_get_irq_status(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_GET_IRQ_STATUS,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
+
+	cmd.params[0] |= mc_enc(0, 32, *status);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
@@ -316,6 +362,7 @@ int dpbp_get_irq_status(struct fsl_mc_io *mc_io,
 }
 
 int dpbp_clear_irq_status(struct fsl_mc_io *mc_io,
+			  uint32_t cmd_flags,
 			  uint16_t token,
 			  uint8_t irq_index,
 			  uint32_t status)
@@ -324,7 +371,9 @@ int dpbp_clear_irq_status(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_CLEAR_IRQ_STATUS,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
+
 	cmd.params[0] |= mc_enc(0, 32, status);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
@@ -333,6 +382,7 @@ int dpbp_clear_irq_status(struct fsl_mc_io *mc_io,
 }
 
 int dpbp_get_attributes(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
 			uint16_t token,
 			struct dpbp_attr *attr)
 {
@@ -341,7 +391,8 @@ int dpbp_get_attributes(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPBP_CMDID_GET_ATTR,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 
 	/* send command to mc*/
 	err = mc_send_command(mc_io, &cmd);
@@ -351,8 +402,82 @@ int dpbp_get_attributes(struct fsl_mc_io *mc_io,
 	/* retrieve response parameters */
 	attr->bpid = (uint16_t)mc_dec(cmd.params[0], 16, 16);
 	attr->id = (int)mc_dec(cmd.params[0], 32, 32);
-	attr->version.major = (uint16_t)mc_dec(cmd.params[1], 0, 16);
-	attr->version.minor = (uint16_t)mc_dec(cmd.params[1], 16, 16);
+
 	return 0;
 }
 EXPORT_SYMBOL(dpbp_get_attributes);
+
+int dpbp_set_notifications(struct fsl_mc_io	*mc_io,
+			   uint32_t		cmd_flags,
+			   uint16_t		token,
+			   struct dpbp_notification_cfg	*cfg)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPBP_CMDID_SET_NOTIFICATIONS,
+					  cmd_flags,
+					  token);
+
+	cmd.params[0] |= mc_enc(0, 32, cfg->depletion_entry);
+	cmd.params[0] |= mc_enc(32, 32, cfg->depletion_exit);
+	cmd.params[1] |= mc_enc(0, 32, cfg->surplus_entry);
+	cmd.params[1] |= mc_enc(32, 32, cfg->surplus_exit);
+	cmd.params[2] |= mc_enc(0, 16, cfg->options);
+	cmd.params[3] |= mc_enc(0, 64, cfg->message_ctx);
+	cmd.params[4] |= mc_enc(0, 64, cfg->message_iova);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpbp_get_notifications(struct fsl_mc_io	*mc_io,
+			   uint32_t		cmd_flags,
+			      uint16_t		token,
+			      struct dpbp_notification_cfg	*cfg)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPBP_CMDID_GET_NOTIFICATIONS,
+					  cmd_flags,
+					  token);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	cfg->depletion_entry = (uint32_t)mc_dec(cmd.params[0], 0, 32);
+	cfg->depletion_exit = (uint32_t)mc_dec(cmd.params[0], 32, 32);
+	cfg->surplus_entry = (uint32_t)mc_dec(cmd.params[1], 0, 32);
+	cfg->surplus_exit = (uint32_t)mc_dec(cmd.params[1], 32, 32);
+	cfg->options = (uint16_t)mc_dec(cmd.params[2], 0, 16);
+	cfg->message_ctx = (uint64_t)mc_dec(cmd.params[3], 0, 64);
+	cfg->message_iova = (uint64_t)mc_dec(cmd.params[4], 0, 64);
+
+	return 0;
+}
+
+int dpbp_get_api_version(struct fsl_mc_io *mc_io,
+			 uint32_t cmd_flags,
+			 uint16_t *major_ver,
+			 uint16_t *minor_ver)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	cmd.header = mc_encode_cmd_header(DPBP_CMDID_GET_API_VERSION,
+					cmd_flags,
+					0);
+
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	get_mc_cmd_object_api_ver(&cmd, major_ver, minor_ver);
+
+	return 0;
+}
diff --git a/drivers/staging/fsl-mc/bus/dpcon.c b/drivers/staging/fsl-mc/bus/dpcon.c
new file mode 100644
index 0000000..f205caa
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpcon.c
@@ -0,0 +1,431 @@
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ * * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * * Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in the
+ * documentation and/or other materials provided with the distribution.
+ * * Neither the name of the above-listed copyright holders nor the
+ * names of any contributors may be used to endorse or promote products
+ * derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+#include "../include/mc-sys.h"
+#include "../include/mc-cmd.h"
+#include "../include/dpcon.h"
+#include "../include/dpcon-cmd.h"
+
+int dpcon_open(struct fsl_mc_io *mc_io,
+	       uint32_t cmd_flags,
+	       int dpcon_id,
+	       uint16_t *token)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_OPEN,
+					  cmd_flags,
+					  0);
+	DPCON_CMD_OPEN(cmd, dpcon_id);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	*token = get_mc_cmd_hdr_token(cmd.header);
+
+	return 0;
+}
+EXPORT_SYMBOL(dpcon_open);
+
+int dpcon_close(struct fsl_mc_io *mc_io,
+		uint32_t cmd_flags,
+		uint16_t token)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_CLOSE,
+					  cmd_flags,
+					  token);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+EXPORT_SYMBOL(dpcon_close);
+
+int dpcon_create(struct fsl_mc_io *mc_io,
+		 uint16_t dprc_token,
+		uint32_t cmd_flags,
+		const struct dpcon_cfg *cfg,
+		uint32_t *object_id)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_CREATE,
+					  cmd_flags,
+					  dprc_token);
+	DPCON_CMD_CREATE(cmd, cfg);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	*object_id = get_mc_cmd_create_object_id(&cmd);
+
+	return 0;
+}
+
+int dpcon_destroy(struct fsl_mc_io *mc_io,
+		  uint16_t dprc_token,
+		uint32_t cmd_flags,
+		uint32_t object_id)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_DESTROY,
+					  cmd_flags,
+					  dprc_token);
+	/* set object id to destroy */
+	set_mc_cmd_destroy_object_id(&cmd, object_id);
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpcon_enable(struct fsl_mc_io *mc_io,
+		 uint32_t cmd_flags,
+		 uint16_t token)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_ENABLE,
+					  cmd_flags,
+					  token);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+EXPORT_SYMBOL(dpcon_enable);
+
+int dpcon_disable(struct fsl_mc_io *mc_io,
+		  uint32_t cmd_flags,
+		  uint16_t token)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_DISABLE,
+					  cmd_flags,
+					  token);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+EXPORT_SYMBOL(dpcon_disable);
+
+int dpcon_is_enabled(struct fsl_mc_io *mc_io,
+		     uint32_t cmd_flags,
+		     uint16_t token,
+		     int *en)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_IS_ENABLED,
+					  cmd_flags,
+					  token);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPCON_RSP_IS_ENABLED(cmd, *en);
+
+	return 0;
+}
+
+int dpcon_reset(struct fsl_mc_io *mc_io,
+		uint32_t cmd_flags,
+		uint16_t token)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_RESET,
+					  cmd_flags, token);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+EXPORT_SYMBOL(dpcon_reset);
+
+int dpcon_set_irq(struct fsl_mc_io	*mc_io,
+		  uint32_t		cmd_flags,
+		  uint16_t		token,
+		  uint8_t		irq_index,
+		  struct dpcon_irq_cfg	*irq_cfg)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_SET_IRQ,
+					  cmd_flags,
+					  token);
+	DPCON_CMD_SET_IRQ(cmd, irq_index, irq_cfg);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpcon_get_irq(struct fsl_mc_io	*mc_io,
+		  uint32_t		cmd_flags,
+		  uint16_t		token,
+		  uint8_t		irq_index,
+		  int			*type,
+		  struct dpcon_irq_cfg	*irq_cfg)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_GET_IRQ,
+					  cmd_flags,
+					  token);
+	DPCON_CMD_GET_IRQ(cmd, irq_index);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPCON_RSP_GET_IRQ(cmd, *type, irq_cfg);
+
+	return 0;
+}
+
+int dpcon_set_irq_enable(struct fsl_mc_io *mc_io,
+			 uint32_t cmd_flags,
+			 uint16_t token,
+			 uint8_t irq_index,
+			 uint8_t en)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_SET_IRQ_ENABLE,
+					  cmd_flags,
+					  token);
+	DPCON_CMD_SET_IRQ_ENABLE(cmd, irq_index, en);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpcon_get_irq_enable(struct fsl_mc_io *mc_io,
+			 uint32_t cmd_flags,
+			 uint16_t token,
+			 uint8_t irq_index,
+			 uint8_t *en)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_GET_IRQ_ENABLE,
+					  cmd_flags,
+					  token);
+	DPCON_CMD_GET_IRQ_ENABLE(cmd, irq_index);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPCON_RSP_GET_IRQ_ENABLE(cmd, *en);
+
+	return 0;
+}
+
+int dpcon_set_irq_mask(struct fsl_mc_io *mc_io,
+		       uint32_t cmd_flags,
+		       uint16_t token,
+		       uint8_t irq_index,
+		       uint32_t mask)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_SET_IRQ_MASK,
+					  cmd_flags,
+					  token);
+	DPCON_CMD_SET_IRQ_MASK(cmd, irq_index, mask);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpcon_get_irq_mask(struct fsl_mc_io *mc_io,
+		       uint32_t cmd_flags,
+		       uint16_t token,
+		       uint8_t irq_index,
+		       uint32_t *mask)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_GET_IRQ_MASK,
+					  cmd_flags,
+					  token);
+	DPCON_CMD_GET_IRQ_MASK(cmd, irq_index);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPCON_RSP_GET_IRQ_MASK(cmd, *mask);
+
+	return 0;
+}
+
+int dpcon_get_irq_status(struct fsl_mc_io *mc_io,
+			 uint32_t cmd_flags,
+			 uint16_t token,
+			 uint8_t irq_index,
+			 uint32_t *status)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_GET_IRQ_STATUS,
+					  cmd_flags,
+					  token);
+	DPCON_CMD_GET_IRQ_STATUS(cmd, irq_index, *status);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPCON_RSP_GET_IRQ_STATUS(cmd, *status);
+
+	return 0;
+}
+
+int dpcon_clear_irq_status(struct fsl_mc_io *mc_io,
+			   uint32_t cmd_flags,
+			   uint16_t token,
+			   uint8_t irq_index,
+			   uint32_t status)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_CLEAR_IRQ_STATUS,
+					  cmd_flags,
+					  token);
+	DPCON_CMD_CLEAR_IRQ_STATUS(cmd, irq_index, status);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpcon_get_attributes(struct fsl_mc_io *mc_io,
+			 uint32_t cmd_flags,
+			 uint16_t token,
+			 struct dpcon_attr *attr)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_GET_ATTR,
+					  cmd_flags,
+					  token);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPCON_RSP_GET_ATTR(cmd, attr);
+
+	return 0;
+}
+EXPORT_SYMBOL(dpcon_get_attributes);
+
+int dpcon_set_notification(struct fsl_mc_io *mc_io,
+			   uint32_t cmd_flags,
+			   uint16_t token,
+			   struct dpcon_notification_cfg *cfg)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_SET_NOTIFICATION,
+					  cmd_flags,
+					  token);
+	DPCON_CMD_SET_NOTIFICATION(cmd, cfg);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+EXPORT_SYMBOL(dpcon_set_notification);
+
+int dpcon_get_api_version(struct fsl_mc_io *mc_io,
+			  uint32_t cmd_flags,
+			  uint16_t *major_ver,
+			  uint16_t *minor_ver)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	cmd.header = mc_encode_cmd_header(DPCON_CMDID_GET_API_VERSION,
+					cmd_flags,
+					0);
+
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	get_mc_cmd_object_api_ver(&cmd, major_ver, minor_ver);
+
+	return 0;
+}
diff --git a/drivers/staging/fsl-mc/bus/dpio/Makefile b/drivers/staging/fsl-mc/bus/dpio/Makefile
new file mode 100644
index 0000000..c20356b
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/Makefile
@@ -0,0 +1,9 @@
+#
+# Freescale DPIO driver
+#
+
+obj-$(CONFIG_FSL_MC_BUS) += fsl-dpio-drv.o
+
+fsl-dpio-drv-objs := dpio-drv.o dpio_service.o dpio.o qbman_portal.o
+
+obj-$(CONFIG_FSL_QBMAN_DEBUG) += qbman_debug.o
diff --git a/drivers/staging/fsl-mc/bus/dpio/dpio-drv.c b/drivers/staging/fsl-mc/bus/dpio/dpio-drv.c
new file mode 100644
index 0000000..4fbbb79
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/dpio-drv.c
@@ -0,0 +1,404 @@
+/* Copyright 2014 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *	 notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *	 notice, this list of conditions and the following disclaimer in the
+ *	 documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *	 names of its contributors may be used to endorse or promote products
+ *	 derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <linux/types.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/dma-mapping.h>
+#include <linux/kthread.h>
+#include <linux/delay.h>
+
+#include "../../include/mc.h"
+#include "../../include/fsl_dpaa2_io.h"
+
+#include "fsl_qbman_portal.h"
+#include "fsl_dpio.h"
+#include "fsl_dpio_cmd.h"
+
+#include "dpio-drv.h"
+
+#define DPIO_DESCRIPTION "DPIO Driver"
+
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_AUTHOR("Freescale Semiconductor, Inc");
+MODULE_DESCRIPTION(DPIO_DESCRIPTION);
+
+#define MAX_DPIO_IRQ_NAME 16 /* Big enough for "FSL DPIO %d" */
+
+struct dpio_priv {
+	struct dpaa2_io *io;
+	char irq_name[MAX_DPIO_IRQ_NAME];
+	struct task_struct *thread;
+};
+
+static int dpio_thread(void *data)
+{
+	struct dpaa2_io *io = data;
+
+	while (!kthread_should_stop()) {
+		int err = dpaa2_io_poll(io);
+
+		if (err) {
+			pr_err("dpaa2_io_poll() failed\n");
+			return err;
+		}
+		msleep(50);
+	}
+	return 0;
+}
+
+static irqreturn_t dpio_irq_handler(int irq_num, void *arg)
+{
+	struct device *dev = (struct device *)arg;
+	struct dpio_priv *priv = dev_get_drvdata(dev);
+
+	return dpaa2_io_irq(priv->io);
+}
+
+static void unregister_dpio_irq_handlers(struct fsl_mc_device *ls_dev)
+{
+	int i;
+	struct fsl_mc_device_irq *irq;
+	int irq_count = ls_dev->obj_desc.irq_count;
+
+	for (i = 0; i < irq_count; i++) {
+		irq = ls_dev->irqs[i];
+		devm_free_irq(&ls_dev->dev, irq->irq_number, &ls_dev->dev);
+	}
+}
+
+static int register_dpio_irq_handlers(struct fsl_mc_device *ls_dev, int cpu)
+{
+	struct dpio_priv *priv;
+	unsigned int i;
+	int error;
+	struct fsl_mc_device_irq *irq;
+	unsigned int num_irq_handlers_registered = 0;
+	int irq_count = ls_dev->obj_desc.irq_count;
+	cpumask_t mask;
+
+	priv = dev_get_drvdata(&ls_dev->dev);
+
+	if (WARN_ON(irq_count != 1))
+		return -EINVAL;
+
+	for (i = 0; i < irq_count; i++) {
+		irq = ls_dev->irqs[i];
+		error = devm_request_irq(&ls_dev->dev,
+					 irq->irq_number,
+					 dpio_irq_handler,
+					 0,
+					 priv->irq_name,
+					 &ls_dev->dev);
+		if (error < 0) {
+			dev_err(&ls_dev->dev,
+				"devm_request_irq() failed: %d\n",
+				error);
+			goto error_unregister_irq_handlers;
+		}
+
+		/* Set the IRQ affinity */
+		cpumask_clear(&mask);
+		cpumask_set_cpu(cpu, &mask);
+		if (irq_set_affinity(irq->irq_number, &mask))
+			pr_err("irq_set_affinity failed irq %d cpu %d\n",
+			       irq->irq_number, cpu);
+
+		num_irq_handlers_registered++;
+	}
+
+	return 0;
+
+error_unregister_irq_handlers:
+	for (i = 0; i < num_irq_handlers_registered; i++) {
+		irq = ls_dev->irqs[i];
+		devm_free_irq(&ls_dev->dev, irq->irq_number,
+			      &ls_dev->dev);
+	}
+
+	return error;
+}
+
+static int __cold
+dpaa2_dpio_probe(struct fsl_mc_device *ls_dev)
+{
+	struct dpio_attr dpio_attrs;
+	struct dpaa2_io_desc desc;
+	struct dpio_priv *priv;
+	int err = -ENOMEM;
+	struct device *dev = &ls_dev->dev;
+	struct dpaa2_io *defservice;
+	bool irq_allocated = false;
+	static int next_cpu;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		goto err_priv_alloc;
+
+	dev_set_drvdata(dev, priv);
+
+	err = fsl_mc_portal_allocate(ls_dev, 0, &ls_dev->mc_io);
+	if (err) {
+		dev_err(dev, "MC portal allocation failed\n");
+		err = -EPROBE_DEFER;
+		goto err_mcportal;
+	}
+
+	err = dpio_open(ls_dev->mc_io, 0, ls_dev->obj_desc.id,
+			&ls_dev->mc_handle);
+	if (err) {
+		dev_err(dev, "dpio_open() failed\n");
+		goto err_open;
+	}
+
+	err = dpio_get_attributes(ls_dev->mc_io, 0, ls_dev->mc_handle,
+				  &dpio_attrs);
+	if (err) {
+		dev_err(dev, "dpio_get_attributes() failed %d\n", err);
+		goto err_get_attr;
+	}
+	err = dpio_enable(ls_dev->mc_io, 0, ls_dev->mc_handle);
+	if (err) {
+		dev_err(dev, "dpio_enable() failed %d\n", err);
+		goto err_get_attr;
+	}
+	pr_info("ce_paddr=0x%llx, ci_paddr=0x%llx, portalid=%d, prios=%d\n",
+		ls_dev->regions[0].start,
+		ls_dev->regions[1].start,
+		dpio_attrs.qbman_portal_id,
+		dpio_attrs.num_priorities);
+
+	pr_info("ce_size=0x%llx, ci_size=0x%llx\n",
+		resource_size(&ls_dev->regions[0]),
+		resource_size(&ls_dev->regions[1]));
+
+	desc.qman_version = dpio_attrs.qbman_version;
+	/* Build DPIO driver object out of raw MC object */
+	desc.receives_notifications = dpio_attrs.num_priorities ? 1 : 0;
+	desc.has_irq = 1;
+	desc.will_poll = 1;
+	desc.has_8prio = dpio_attrs.num_priorities == 8 ? 1 : 0;
+	desc.cpu = next_cpu;
+	desc.stash_affinity = 1; /* TODO: Figure out how to determine
+				    this setting - will we ever have non-affine
+				    portals where we stash to a platform cache? */
+	next_cpu = (next_cpu + 1) % num_active_cpus();
+	desc.dpio_id = ls_dev->obj_desc.id;
+	desc.regs_cena = ioremap_cache_ns(ls_dev->regions[0].start,
+		resource_size(&ls_dev->regions[0]));
+	desc.regs_cinh = ioremap(ls_dev->regions[1].start,
+		resource_size(&ls_dev->regions[1]));
+
+	err = fsl_mc_allocate_irqs(ls_dev);
+	if (err) {
+		dev_err(dev, "DPIO fsl_mc_allocate_irqs failed\n");
+		desc.has_irq = 0;
+	} else {
+		irq_allocated = true;
+
+		snprintf(priv->irq_name, MAX_DPIO_IRQ_NAME, "FSL DPIO %d",
+			 desc.dpio_id);
+
+		err = register_dpio_irq_handlers(ls_dev, desc.cpu);
+		if (err)
+			desc.has_irq = 0;
+	}
+
+	priv->io = dpaa2_io_create(&desc);
+	if (!priv->io) {
+		dev_err(dev, "DPIO setup failed\n");
+		goto err_dpaa2_io_create;
+	}
+
+	/* If no irq then go to poll mode */
+	if (desc.has_irq == 0) {
+		dev_info(dev, "Using polling mode for DPIO %d\n",
+			 desc.dpio_id);
+		/* goto err_register_dpio_irq; */
+		/* TEMP: Start polling if IRQ could not
+		   be registered.  This will go away once
+		   KVM support for MSI is present */
+		if (irq_allocated == true)
+			fsl_mc_free_irqs(ls_dev);
+
+		if (desc.stash_affinity)
+			priv->thread = kthread_create_on_cpu(dpio_thread,
+							     priv->io,
+							     desc.cpu,
+							     "dpio_aff%u");
+		else
+			priv->thread =
+				kthread_create(dpio_thread,
+					       priv->io,
+					       "dpio_non%u",
+					       dpio_attrs.qbman_portal_id);
+		if (IS_ERR(priv->thread)) {
+			dev_err(dev, "DPIO thread failure\n");
+			err = PTR_ERR(priv->thread);
+			goto err_dpaa_thread;
+		}
+		kthread_unpark(priv->thread);
+		wake_up_process(priv->thread);
+	}
+
+	defservice = dpaa2_io_default_service();
+	err = dpaa2_io_service_add(defservice, priv->io);
+	dpaa2_io_down(defservice);
+	if (err) {
+		dev_err(dev, "DPIO add-to-service failed\n");
+		goto err_dpaa2_io_add;
+	}
+
+	dev_info(dev, "dpio: probed object %d\n", ls_dev->obj_desc.id);
+	dev_info(dev, "   receives_notifications = %d\n",
+			desc.receives_notifications);
+	dev_info(dev, "   has_irq = %d\n", desc.has_irq);
+	dpio_close(ls_dev->mc_io, 0, ls_dev->mc_handle);
+	fsl_mc_portal_free(ls_dev->mc_io);
+	return 0;
+
+err_dpaa2_io_add:
+	unregister_dpio_irq_handlers(ls_dev);
+/* TEMP: To be restored once polling is removed
+  err_register_dpio_irq:
+	fsl_mc_free_irqs(ls_dev);
+*/
+err_dpaa_thread:
+err_dpaa2_io_create:
+	dpio_disable(ls_dev->mc_io, 0, ls_dev->mc_handle);
+err_get_attr:
+	dpio_close(ls_dev->mc_io, 0, ls_dev->mc_handle);
+err_open:
+	fsl_mc_portal_free(ls_dev->mc_io);
+err_mcportal:
+	dev_set_drvdata(dev, NULL);
+	devm_kfree(dev, priv);
+err_priv_alloc:
+	return err;
+}
+
+/*
+ * Tear down interrupts for a given DPIO object
+ */
+static void dpio_teardown_irqs(struct fsl_mc_device *ls_dev)
+{
+	/* (void)disable_dpio_irqs(ls_dev); */
+	unregister_dpio_irq_handlers(ls_dev);
+	fsl_mc_free_irqs(ls_dev);
+}
+
+static int __cold
+dpaa2_dpio_remove(struct fsl_mc_device *ls_dev)
+{
+	struct device *dev;
+	struct dpio_priv *priv;
+	int err;
+
+	dev = &ls_dev->dev;
+	priv = dev_get_drvdata(dev);
+
+	/* there is no implementation yet for pulling a DPIO object out of a
+	 * running service (and they're currently always running).
+	 */
+	dev_crit(dev, "DPIO unplugging is broken, the service holds onto it\n");
+
+	if (priv->thread)
+		kthread_stop(priv->thread);
+	else
+		dpio_teardown_irqs(ls_dev);
+
+	err = fsl_mc_portal_allocate(ls_dev, 0, &ls_dev->mc_io);
+	if (err) {
+		dev_err(dev, "MC portal allocation failed\n");
+		goto err_mcportal;
+	}
+
+	err = dpio_open(ls_dev->mc_io, 0, ls_dev->obj_desc.id,
+			&ls_dev->mc_handle);
+	if (err) {
+		dev_err(dev, "dpio_open() failed\n");
+		goto err_open;
+	}
+
+	dev_set_drvdata(dev, NULL);
+	dpaa2_io_down(priv->io);
+
+	err = 0;
+
+	dpio_disable(ls_dev->mc_io, 0, ls_dev->mc_handle);
+	dpio_close(ls_dev->mc_io, 0, ls_dev->mc_handle);
+err_open:
+	fsl_mc_portal_free(ls_dev->mc_io);
+err_mcportal:
+	return err;
+}
+
+static const struct fsl_mc_device_match_id dpaa2_dpio_match_id_table[] = {
+	{
+		.vendor = FSL_MC_VENDOR_FREESCALE,
+		.obj_type = "dpio",
+		.ver_major = DPIO_VER_MAJOR,
+		.ver_minor = DPIO_VER_MINOR
+	},
+	{ .vendor = 0x0 }
+};
+
+static struct fsl_mc_driver dpaa2_dpio_driver = {
+	.driver = {
+		.name		= KBUILD_MODNAME,
+		.owner		= THIS_MODULE,
+	},
+	.probe		= dpaa2_dpio_probe,
+	.remove		= dpaa2_dpio_remove,
+	.match_id_table = dpaa2_dpio_match_id_table
+};
+
+static int dpio_driver_init(void)
+{
+	int err;
+
+	err = dpaa2_io_service_driver_init();
+	if (!err) {
+		err = fsl_mc_driver_register(&dpaa2_dpio_driver);
+		if (err)
+			dpaa2_io_service_driver_exit();
+	}
+	return err;
+}
+static void dpio_driver_exit(void)
+{
+	fsl_mc_driver_unregister(&dpaa2_dpio_driver);
+	dpaa2_io_service_driver_exit();
+}
+module_init(dpio_driver_init);
+module_exit(dpio_driver_exit);
diff --git a/drivers/staging/fsl-mc/bus/dpio/dpio-drv.h b/drivers/staging/fsl-mc/bus/dpio/dpio-drv.h
new file mode 100644
index 0000000..fe8d40b
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/dpio-drv.h
@@ -0,0 +1,33 @@
+/* Copyright 2014 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *	 notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *	 notice, this list of conditions and the following disclaimer in the
+ *	 documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *	 names of its contributors may be used to endorse or promote products
+ *	 derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+int dpaa2_io_service_driver_init(void);
+void dpaa2_io_service_driver_exit(void);
diff --git a/drivers/staging/fsl-mc/bus/dpio/dpio.c b/drivers/staging/fsl-mc/bus/dpio/dpio.c
new file mode 100644
index 0000000..61f4574
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/dpio.c
@@ -0,0 +1,492 @@
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ * * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * * Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in the
+ * documentation and/or other materials provided with the distribution.
+ * * Neither the name of the above-listed copyright holders nor the
+ * names of any contributors may be used to endorse or promote products
+ * derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+#include "../../include/mc-sys.h"
+#include "../../include/mc-cmd.h"
+#include "fsl_dpio.h"
+#include "fsl_dpio_cmd.h"
+
+int dpio_open(struct fsl_mc_io *mc_io,
+	      uint32_t cmd_flags,
+	      int dpio_id,
+	      uint16_t *token)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_OPEN,
+					  cmd_flags,
+					  0);
+	DPIO_CMD_OPEN(cmd, dpio_id);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	*token = get_mc_cmd_hdr_token(cmd.header);
+
+	return 0;
+}
+
+int dpio_close(struct fsl_mc_io *mc_io,
+	       uint32_t cmd_flags,
+	       uint16_t token)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_CLOSE,
+					  cmd_flags,
+					  token);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpio_create(struct fsl_mc_io	*mc_io,
+		uint16_t	dprc_token,
+		uint32_t	cmd_flags,
+		const struct dpio_cfg	*cfg,
+		uint32_t	*object_id)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_CREATE,
+					  cmd_flags,
+					  dprc_token);
+	DPIO_CMD_CREATE(cmd, cfg);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	*object_id = get_mc_cmd_create_object_id(&cmd);
+
+	return 0;
+}
+
+int dpio_destroy(struct fsl_mc_io	*mc_io,
+		 uint16_t	dprc_token,
+		 uint32_t	cmd_flags,
+		 uint32_t	object_id)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_DESTROY,
+			cmd_flags,
+			dprc_token);
+	/* set object id to destroy */
+	set_mc_cmd_destroy_object_id(&cmd, object_id);
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpio_enable(struct fsl_mc_io *mc_io,
+		uint32_t cmd_flags,
+		uint16_t token)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_ENABLE,
+					  cmd_flags,
+					  token);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpio_disable(struct fsl_mc_io *mc_io,
+		 uint32_t cmd_flags,
+		 uint16_t token)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_DISABLE,
+					  cmd_flags,
+					  token);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpio_is_enabled(struct fsl_mc_io *mc_io,
+		    uint32_t cmd_flags,
+		    uint16_t token,
+		    int *en)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_IS_ENABLED, cmd_flags,
+					  token);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPIO_RSP_IS_ENABLED(cmd, *en);
+
+	return 0;
+}
+
+int dpio_reset(struct fsl_mc_io *mc_io,
+	       uint32_t cmd_flags,
+	       uint16_t token)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_RESET,
+					  cmd_flags,
+					  token);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpio_set_irq(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
+		 uint16_t		token,
+		 uint8_t		irq_index,
+		 struct dpio_irq_cfg	*irq_cfg)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_SET_IRQ,
+					  cmd_flags,
+					  token);
+	DPIO_CMD_SET_IRQ(cmd, irq_index, irq_cfg);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpio_get_irq(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
+		 uint16_t		token,
+		 uint8_t		irq_index,
+		 int			*type,
+		 struct dpio_irq_cfg	*irq_cfg)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_GET_IRQ,
+					  cmd_flags,
+					  token);
+	DPIO_CMD_GET_IRQ(cmd, irq_index);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPIO_RSP_GET_IRQ(cmd, *type, irq_cfg);
+
+	return 0;
+}
+
+int dpio_set_irq_enable(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
+			uint16_t token,
+			uint8_t irq_index,
+			uint8_t en)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_SET_IRQ_ENABLE,
+					  cmd_flags,
+					  token);
+	DPIO_CMD_SET_IRQ_ENABLE(cmd, irq_index, en);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpio_get_irq_enable(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
+			uint16_t token,
+			uint8_t irq_index,
+			uint8_t *en)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_GET_IRQ_ENABLE,
+					  cmd_flags,
+					  token);
+	DPIO_CMD_GET_IRQ_ENABLE(cmd, irq_index);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPIO_RSP_GET_IRQ_ENABLE(cmd, *en);
+
+	return 0;
+}
+
+int dpio_set_irq_mask(struct fsl_mc_io *mc_io,
+		      uint32_t cmd_flags,
+		      uint16_t token,
+		      uint8_t irq_index,
+		      uint32_t mask)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_SET_IRQ_MASK,
+					  cmd_flags,
+					  token);
+	DPIO_CMD_SET_IRQ_MASK(cmd, irq_index, mask);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpio_get_irq_mask(struct fsl_mc_io *mc_io,
+		      uint32_t cmd_flags,
+		      uint16_t token,
+		      uint8_t irq_index,
+		      uint32_t *mask)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_GET_IRQ_MASK,
+					  cmd_flags,
+					  token);
+	DPIO_CMD_GET_IRQ_MASK(cmd, irq_index);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPIO_RSP_GET_IRQ_MASK(cmd, *mask);
+
+	return 0;
+}
+
+int dpio_get_irq_status(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
+			uint16_t token,
+			uint8_t irq_index,
+			uint32_t *status)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_GET_IRQ_STATUS,
+					  cmd_flags,
+					  token);
+	DPIO_CMD_GET_IRQ_STATUS(cmd, irq_index, *status);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPIO_RSP_GET_IRQ_STATUS(cmd, *status);
+
+	return 0;
+}
+
+int dpio_clear_irq_status(struct fsl_mc_io *mc_io,
+			  uint32_t cmd_flags,
+			  uint16_t token,
+			  uint8_t irq_index,
+			  uint32_t status)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_CLEAR_IRQ_STATUS,
+					  cmd_flags,
+					  token);
+	DPIO_CMD_CLEAR_IRQ_STATUS(cmd, irq_index, status);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpio_get_attributes(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
+			uint16_t token,
+			struct dpio_attr *attr)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_GET_ATTR,
+					  cmd_flags,
+					  token);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPIO_RSP_GET_ATTR(cmd, attr);
+
+	return 0;
+}
+
+int dpio_set_stashing_destination(struct fsl_mc_io *mc_io,
+				  uint32_t cmd_flags,
+				  uint16_t token,
+				  uint8_t sdest)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_SET_STASHING_DEST,
+					  cmd_flags,
+					  token);
+	DPIO_CMD_SET_STASHING_DEST(cmd, sdest);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpio_get_stashing_destination(struct fsl_mc_io *mc_io,
+				  uint32_t cmd_flags,
+				  uint16_t token,
+				  uint8_t *sdest)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_GET_STASHING_DEST,
+					  cmd_flags,
+					  token);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPIO_RSP_GET_STASHING_DEST(cmd, *sdest);
+
+	return 0;
+}
+
+int dpio_add_static_dequeue_channel(struct fsl_mc_io *mc_io,
+				    uint32_t cmd_flags,
+				    uint16_t token,
+				    int dpcon_id,
+				    uint8_t *channel_index)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_ADD_STATIC_DEQUEUE_CHANNEL,
+					  cmd_flags,
+					  token);
+	DPIO_CMD_ADD_STATIC_DEQUEUE_CHANNEL(cmd, dpcon_id);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	DPIO_RSP_ADD_STATIC_DEQUEUE_CHANNEL(cmd, *channel_index);
+
+	return 0;
+}
+
+int dpio_remove_static_dequeue_channel(struct fsl_mc_io *mc_io,
+				       uint32_t cmd_flags,
+				       uint16_t token,
+				       int dpcon_id)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(
+				DPIO_CMDID_REMOVE_STATIC_DEQUEUE_CHANNEL,
+				cmd_flags,
+				token);
+	DPIO_CMD_REMOVE_STATIC_DEQUEUE_CHANNEL(cmd, dpcon_id);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+
+int dpio_get_api_version(struct fsl_mc_io *mc_io,
+			 uint32_t cmd_flags,
+			 uint16_t *major_ver,
+			 uint16_t *minor_ver)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	cmd.header = mc_encode_cmd_header(DPIO_CMDID_GET_API_VERSION,
+					cmd_flags,
+					0);
+
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	get_mc_cmd_object_api_ver(&cmd, major_ver, minor_ver);
+
+	return 0;
+}
diff --git a/drivers/staging/fsl-mc/bus/dpio/dpio_service.c b/drivers/staging/fsl-mc/bus/dpio/dpio_service.c
new file mode 100644
index 0000000..a8a0259
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/dpio_service.c
@@ -0,0 +1,857 @@
+/* Copyright 2014 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *	 notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *	 notice, this list of conditions and the following disclaimer in the
+ *	 documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *	 names of its contributors may be used to endorse or promote products
+ *	 derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include <linux/types.h>
+#include "fsl_qbman_portal.h"
+#include "../../include/mc.h"
+#include "../../include/fsl_dpaa2_io.h"
+#include "fsl_dpio.h"
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+
+#include "dpio-drv.h"
+#include "qbman_debug.h"
+
+#define UNIMPLEMENTED() pr_err("FOO: %s unimplemented!\n", __func__)
+
+#define MAGIC_SERVICE 0xabcd9876
+#define MAGIC_OBJECT 0x1234fedc
+
+struct dpaa2_io {
+	/* If MAGIC_SERVICE, this is a group of objects, use the 'service' part
+	 * of the union. If MAGIC_OBJECT, use the 'object' part of the union. If
+	 * it's neither, something got corrupted. This is mainly to satisfy
+	 * dpaa2_io_from_registration(), which dereferences a caller-
+	 * instantiated struct and so warrants a bug-checking step - hence the
+	 * magic rather than a boolean.
+	 */
+	unsigned int magic;
+	atomic_t refs;
+	union {
+		struct dpaa2_io_service {
+			spinlock_t lock;
+			struct list_head list;
+			/* for targeted dpaa2_io selection */
+			struct dpaa2_io *objects_by_cpu[NR_CPUS];
+			cpumask_t cpus_notifications;
+			cpumask_t cpus_stashing;
+			int has_nonaffine;
+			/* slight hack. record the special case of the
+			 * "default service", because that's the case where we
+			 * need to avoid a kfree() ... */
+			int is_defservice;
+		} service;
+		struct dpaa2_io_object {
+			struct dpaa2_io_desc dpio_desc;
+			struct qbman_swp_desc swp_desc;
+			struct qbman_swp *swp;
+			/* If the object is part of a service, this is it (and
+			 * 'node' is linked into the service's list) */
+			struct dpaa2_io *service;
+			struct list_head node;
+			/* Interrupt mask, as used with
+			 * qbman_swp_interrupt_[gs]et_vanish(). This isn't
+			 * locked, because the higher layer is driving all
+			 * "ingress" processing. */
+			uint32_t irq_mask;
+			/* As part of simplifying assumptions, we provide an
+			 * irq-safe lock for each type of DPIO operation that
+			 * isn't innately lockless. The selection algorithms
+			 * (which are simplified) require this, whereas
+			 * eventually adherence to cpu-affinity will presumably
+			 * relax the locking requirements. */
+			spinlock_t lock_mgmt_cmd;
+			spinlock_t lock_notifications;
+			struct list_head notifications;
+		} object;
+	};
+};
+
+struct dpaa2_io_store {
+	unsigned int max;
+	dma_addr_t paddr;
+	struct dpaa2_dq *vaddr;
+	void *alloced_addr; /* the actual return from kmalloc as it may
+			       be adjusted for alignment purposes */
+	unsigned int idx; /* position of the next-to-be-returned entry */
+	struct qbman_swp *swp; /* portal used to issue VDQCR */
+	struct device *dev; /* device used for DMA mapping */
+};
+
+static struct dpaa2_io def_serv;
+
+/**********************/
+/* Internal functions */
+/**********************/
+
+static void service_init(struct dpaa2_io *d, int is_defservice)
+{
+	struct dpaa2_io_service *s = &d->service;
+
+	d->magic = MAGIC_SERVICE;
+	atomic_set(&d->refs, 1);
+	spin_lock_init(&s->lock);
+	INIT_LIST_HEAD(&s->list);
+	cpumask_clear(&s->cpus_notifications);
+	cpumask_clear(&s->cpus_stashing);
+	s->has_nonaffine = 0;
+	s->is_defservice = is_defservice;
+}
+
+/* Selection algorithms, stupid ones at that. These are to handle the case where
+ * the given dpaa2_io is a service, by choosing the non-service dpaa2_io within
+ * it to use.
+ */
+static struct dpaa2_io *_service_select_by_cpu_slow(struct dpaa2_io_service *ss,
+						   int cpu)
+{
+	struct dpaa2_io *o;
+	unsigned long irqflags;
+
+	spin_lock_irqsave(&ss->lock, irqflags);
+	/* TODO: this is about the dumbest and slowest selection algorithm you
+	 * could imagine. (We're looking for something working first, and
+	 * something efficient second...)
+	 */
+	list_for_each_entry(o, &ss->list, object.node)
+		if (o->object.dpio_desc.cpu == cpu)
+			goto found;
+
+	/* No joy. Try the first nonaffine portal (bleurgh) */
+	if (ss->has_nonaffine)
+		list_for_each_entry(o, &ss->list, object.node)
+			if (!o->object.dpio_desc.stash_affinity)
+				goto found;
+
+	/* No joy. Try the first object. Told you it was horrible. */
+	if (!list_empty(&ss->list))
+		o = list_entry(ss->list.next, struct dpaa2_io, object.node);
+	else
+		o = NULL;
+
+found:
+	spin_unlock_irqrestore(&ss->lock, irqflags);
+	return o;
+}
+
+static struct dpaa2_io *service_select_by_cpu(struct dpaa2_io *d, int cpu)
+{
+	struct dpaa2_io_service *ss;
+	unsigned long irqflags;
+
+	if (!d)
+		d = &def_serv;
+	else if (d->magic == MAGIC_OBJECT)
+		return d;
+	BUG_ON(d->magic != MAGIC_SERVICE);
+
+	ss = &d->service;
+
+	/* If cpu==-1, choose the current cpu, with no guarantees about
+	 * potentially being migrated away.
+	 */
+	if (unlikely(cpu < 0)) {
+		spin_lock_irqsave(&ss->lock, irqflags);
+		cpu = smp_processor_id();
+		spin_unlock_irqrestore(&ss->lock, irqflags);
+
+		return _service_select_by_cpu_slow(ss, cpu);
+	}
+
+	/* If a specific cpu was requested, pick it up immediately */
+	return ss->objects_by_cpu[cpu];
+}
+
+static inline struct dpaa2_io *service_select_any(struct dpaa2_io *d)
+{
+	struct dpaa2_io_service *ss;
+	struct dpaa2_io *o;
+	unsigned long irqflags;
+
+	if (!d)
+		d = &def_serv;
+	else if (d->magic == MAGIC_OBJECT)
+		return d;
+	BUG_ON(d->magic != MAGIC_SERVICE);
+
+	/*
+	 * Lock the service, looking for the first DPIO object in the list,
+	 * ignore everything else about that DPIO, and choose it to do the
+	 * operation! As a post-selection step, move the DPIO to the end of
+	 * the list. It should improve load-balancing a little, although it
+	 * might also incur a performance hit, given that the lock is *global*
+	 * and this may be called on the fast-path...
+	 */
+	ss = &d->service;
+	spin_lock_irqsave(&ss->lock, irqflags);
+	if (!list_empty(&ss->list)) {
+		o = list_entry(ss->list.next, struct dpaa2_io, object.node);
+		list_del(&o->object.node);
+		list_add_tail(&o->object.node, &ss->list);
+	} else
+		o = NULL;
+	spin_unlock_irqrestore(&ss->lock, irqflags);
+	return o;
+}
+
+/* If the context is not preemptible, select the service affine to the
+ * current cpu. Otherwise, "select any".
+ */
+static inline struct dpaa2_io *_service_select(struct dpaa2_io *d)
+{
+	struct dpaa2_io *temp = d;
+
+	if (likely(!preemptible())) {
+		d = service_select_by_cpu(d, smp_processor_id());
+		if (likely(d))
+			return d;
+	}
+	return service_select_any(temp);
+}
+
+/**********************/
+/* Exported functions */
+/**********************/
+
+struct dpaa2_io *dpaa2_io_create(const struct dpaa2_io_desc *desc)
+{
+	struct dpaa2_io *ret = kmalloc(sizeof(*ret), GFP_KERNEL);
+	struct dpaa2_io_object *o = &ret->object;
+
+	if (!ret)
+		return NULL;
+	ret->magic = MAGIC_OBJECT;
+	atomic_set(&ret->refs, 1);
+	o->dpio_desc = *desc;
+	o->swp_desc.cena_bar = o->dpio_desc.regs_cena;
+	o->swp_desc.cinh_bar = o->dpio_desc.regs_cinh;
+	o->swp_desc.qman_version = o->dpio_desc.qman_version;
+	o->swp = qbman_swp_init(&o->swp_desc);
+	o->service = NULL;
+	if (!o->swp) {
+		kfree(ret);
+		return NULL;
+	}
+	INIT_LIST_HEAD(&o->node);
+	spin_lock_init(&o->lock_mgmt_cmd);
+	spin_lock_init(&o->lock_notifications);
+	INIT_LIST_HEAD(&o->notifications);
+	if (!o->dpio_desc.has_irq)
+		qbman_swp_interrupt_set_vanish(o->swp, 0xffffffff);
+	else {
+		/* For now only enable DQRR interrupts */
+		qbman_swp_interrupt_set_trigger(o->swp,
+						QBMAN_SWP_INTERRUPT_DQRI);
+	}
+	qbman_swp_interrupt_clear_status(o->swp, 0xffffffff);
+	if (o->dpio_desc.receives_notifications)
+		qbman_swp_push_set(o->swp, 0, 1);
+	return ret;
+}
+EXPORT_SYMBOL(dpaa2_io_create);
+
+struct dpaa2_io *dpaa2_io_create_service(void)
+{
+	struct dpaa2_io *ret = kmalloc(sizeof(*ret), GFP_KERNEL);
+
+	if (ret)
+		service_init(ret, 0);
+	return ret;
+}
+EXPORT_SYMBOL(dpaa2_io_create_service);
+
+struct dpaa2_io *dpaa2_io_default_service(void)
+{
+	atomic_inc(&def_serv.refs);
+	return &def_serv;
+}
+EXPORT_SYMBOL(dpaa2_io_default_service);
+
+void dpaa2_io_down(struct dpaa2_io *d)
+{
+	if (!atomic_dec_and_test(&d->refs))
+		return;
+	if (d->magic == MAGIC_SERVICE) {
+		BUG_ON(!list_empty(&d->service.list));
+		if (d->service.is_defservice)
+			/* avoid the kfree()! */
+			return;
+	} else {
+		BUG_ON(d->magic != MAGIC_OBJECT);
+		BUG_ON(d->object.service);
+		BUG_ON(!list_empty(&d->object.notifications));
+	}
+	kfree(d);
+}
+EXPORT_SYMBOL(dpaa2_io_down);
+
+int dpaa2_io_service_add(struct dpaa2_io *s, struct dpaa2_io *o)
+{
+	struct dpaa2_io_service *ss = &s->service;
+	struct dpaa2_io_object *oo = &o->object;
+	int res = -EINVAL;
+
+	if ((s->magic != MAGIC_SERVICE) || (o->magic != MAGIC_OBJECT))
+		return res;
+	atomic_inc(&o->refs);
+	atomic_inc(&s->refs);
+	spin_lock(&ss->lock);
+	/* 'obj' must not already be associated with a service */
+	if (!oo->service) {
+		oo->service = s;
+		list_add(&oo->node, &ss->list);
+		if (oo->dpio_desc.receives_notifications) {
+			cpumask_set_cpu(oo->dpio_desc.cpu,
+					&ss->cpus_notifications);
+			/* Update the fast-access array */
+			ss->objects_by_cpu[oo->dpio_desc.cpu] =
+				container_of(oo, struct dpaa2_io, object);
+		}
+		if (oo->dpio_desc.stash_affinity)
+			cpumask_set_cpu(oo->dpio_desc.cpu,
+					&ss->cpus_stashing);
+		if (!oo->dpio_desc.stash_affinity)
+			ss->has_nonaffine = 1;
+		/* success */
+		res = 0;
+	}
+	spin_unlock(&ss->lock);
+	if (res) {
+		dpaa2_io_down(s);
+		dpaa2_io_down(o);
+	}
+	return res;
+}
+EXPORT_SYMBOL(dpaa2_io_service_add);
+
+int dpaa2_io_get_descriptor(struct dpaa2_io *obj, struct dpaa2_io_desc *desc)
+{
+	if (obj->magic == MAGIC_SERVICE)
+		return -EINVAL;
+	BUG_ON(obj->magic != MAGIC_OBJECT);
+	*desc = obj->object.dpio_desc;
+	return 0;
+}
+EXPORT_SYMBOL(dpaa2_io_get_descriptor);
+
+#define DPAA_POLL_MAX 32
+
+int dpaa2_io_poll(struct dpaa2_io *obj)
+{
+	const struct dpaa2_dq *dq;
+	struct qbman_swp *swp;
+	int max = 0;
+
+	if (obj->magic != MAGIC_OBJECT)
+		return -EINVAL;
+	swp = obj->object.swp;
+	dq = qbman_swp_dqrr_next(swp);
+	while (dq) {
+		if (qbman_result_is_SCN(dq)) {
+			struct dpaa2_io_notification_ctx *ctx;
+			uint64_t q64;
+
+			q64 = qbman_result_SCN_ctx(dq);
+			ctx = (void *)q64;
+			ctx->cb(ctx);
+		} else
+			pr_crit("Unrecognised/ignored DQRR entry\n");
+		qbman_swp_dqrr_consume(swp, dq);
+		++max;
+		if (max > DPAA_POLL_MAX)
+			return 0;
+		dq = qbman_swp_dqrr_next(swp);
+	}
+	return 0;
+}
+EXPORT_SYMBOL(dpaa2_io_poll);
+
+int dpaa2_io_irq(struct dpaa2_io *obj)
+{
+	struct qbman_swp *swp;
+	uint32_t status;
+
+	if (obj->magic != MAGIC_OBJECT)
+		return -EINVAL;
+	swp = obj->object.swp;
+	status = qbman_swp_interrupt_read_status(swp);
+	if (!status)
+		return IRQ_NONE;
+	dpaa2_io_poll(obj);
+	qbman_swp_interrupt_clear_status(swp, status);
+	qbman_swp_interrupt_set_inhibit(swp, 0);
+	return IRQ_HANDLED;
+}
+EXPORT_SYMBOL(dpaa2_io_irq);
+
+int dpaa2_io_pause_poll(struct dpaa2_io *obj)
+{
+	UNIMPLEMENTED();
+	return -EINVAL;
+}
+EXPORT_SYMBOL(dpaa2_io_pause_poll);
+
+int dpaa2_io_resume_poll(struct dpaa2_io *obj)
+{
+	UNIMPLEMENTED();
+	return -EINVAL;
+}
+EXPORT_SYMBOL(dpaa2_io_resume_poll);
+
+void dpaa2_io_service_notifications(struct dpaa2_io *s, cpumask_t *mask)
+{
+	struct dpaa2_io_service *ss = &s->service;
+
+	BUG_ON(s->magic != MAGIC_SERVICE);
+	cpumask_copy(mask, &ss->cpus_notifications);
+}
+EXPORT_SYMBOL(dpaa2_io_service_notifications);
+
+void dpaa2_io_service_stashing(struct dpaa2_io *s, cpumask_t *mask)
+{
+	struct dpaa2_io_service *ss = &s->service;
+
+	BUG_ON(s->magic != MAGIC_SERVICE);
+	cpumask_copy(mask, &ss->cpus_stashing);
+}
+EXPORT_SYMBOL(dpaa2_io_service_stashing);
+
+int dpaa2_io_service_has_nonaffine(struct dpaa2_io *s)
+{
+	struct dpaa2_io_service *ss = &s->service;
+
+	BUG_ON(s->magic != MAGIC_SERVICE);
+	return ss->has_nonaffine;
+}
+EXPORT_SYMBOL(dpaa2_io_service_has_nonaffine);
+
+int dpaa2_io_service_register(struct dpaa2_io *d,
+			     struct dpaa2_io_notification_ctx *ctx)
+{
+	unsigned long irqflags;
+
+	d = service_select_by_cpu(d, ctx->desired_cpu);
+	if (!d)
+		return -ENODEV;
+	ctx->dpio_id = d->object.dpio_desc.dpio_id;
+	ctx->qman64 = (uint64_t)ctx;
+	ctx->dpio_private = d;
+	spin_lock_irqsave(&d->object.lock_notifications, irqflags);
+	list_add(&ctx->node, &d->object.notifications);
+	spin_unlock_irqrestore(&d->object.lock_notifications, irqflags);
+	if (ctx->is_cdan)
+		/* Enable the generation of CDAN notifications */
+		qbman_swp_CDAN_set_context_enable(d->object.swp,
+						  (uint16_t)ctx->id,
+						  ctx->qman64);
+	return 0;
+}
+EXPORT_SYMBOL(dpaa2_io_service_register);
+
+int dpaa2_io_service_deregister(struct dpaa2_io *service,
+			       struct dpaa2_io_notification_ctx *ctx)
+{
+	struct dpaa2_io *d = ctx->dpio_private;
+	unsigned long irqflags;
+
+	if (!service)
+		service = &def_serv;
+	BUG_ON((service != d) && (service != d->object.service));
+	if (ctx->is_cdan)
+		qbman_swp_CDAN_disable(d->object.swp,
+				       (uint16_t)ctx->id);
+	spin_lock_irqsave(&d->object.lock_notifications, irqflags);
+	list_del(&ctx->node);
+	spin_unlock_irqrestore(&d->object.lock_notifications, irqflags);
+	return 0;
+}
+EXPORT_SYMBOL(dpaa2_io_service_deregister);
+
+int dpaa2_io_service_rearm(struct dpaa2_io *d,
+			  struct dpaa2_io_notification_ctx *ctx)
+{
+	unsigned long irqflags;
+	int err;
+
+	d = _service_select(d);
+	if (!d)
+		return -ENODEV;
+	spin_lock_irqsave(&d->object.lock_mgmt_cmd, irqflags);
+	if (ctx->is_cdan)
+		err = qbman_swp_CDAN_enable(d->object.swp, (uint16_t)ctx->id);
+	else
+		err = qbman_swp_fq_schedule(d->object.swp, ctx->id);
+	spin_unlock_irqrestore(&d->object.lock_mgmt_cmd, irqflags);
+	return err;
+}
+EXPORT_SYMBOL(dpaa2_io_service_rearm);
+
+int dpaa2_io_from_registration(struct dpaa2_io_notification_ctx *ctx,
+			      struct dpaa2_io **io)
+{
+	struct dpaa2_io_notification_ctx *tmp;
+	struct dpaa2_io *d = ctx->dpio_private;
+	unsigned long irqflags;
+	int ret = 0;
+
+	BUG_ON(d->magic != MAGIC_OBJECT);
+	/* Iterate the notifications associated with 'd' looking for a match. If
+	 * not, we've been passed an unregistered ctx! */
+	spin_lock_irqsave(&d->object.lock_notifications, irqflags);
+	list_for_each_entry(tmp, &d->object.notifications, node)
+		if (tmp == ctx)
+			goto found;
+	ret = -EINVAL;
+found:
+	spin_unlock_irqrestore(&d->object.lock_notifications, irqflags);
+	if (!ret) {
+		atomic_inc(&d->refs);
+		*io = d;
+	}
+	return ret;
+}
+EXPORT_SYMBOL(dpaa2_io_from_registration);
+
+int dpaa2_io_service_get_persistent(struct dpaa2_io *service, int cpu,
+				   struct dpaa2_io **ret)
+{
+	if (cpu == -1)
+		*ret = service_select_any(service);
+	else
+		*ret = service_select_by_cpu(service, cpu);
+	if (*ret) {
+		atomic_inc(&(*ret)->refs);
+		return 0;
+	}
+	return -ENODEV;
+}
+EXPORT_SYMBOL(dpaa2_io_service_get_persistent);
+
+int dpaa2_io_service_pull_fq(struct dpaa2_io *d, uint32_t fqid,
+			    struct dpaa2_io_store *s)
+{
+	struct qbman_pull_desc pd;
+	int err;
+
+	qbman_pull_desc_clear(&pd);
+	qbman_pull_desc_set_storage(&pd, s->vaddr, s->paddr, 1);
+	qbman_pull_desc_set_numframes(&pd, (uint8_t)s->max);
+	qbman_pull_desc_set_fq(&pd, fqid);
+	d = _service_select(d);
+	if (!d)
+		return -ENODEV;
+	s->swp = d->object.swp;
+	err = qbman_swp_pull(d->object.swp, &pd);
+	if (err)
+		s->swp = NULL;
+	return err;
+}
+EXPORT_SYMBOL(dpaa2_io_service_pull_fq);
+
+int dpaa2_io_service_pull_channel(struct dpaa2_io *d, uint32_t channelid,
+				 struct dpaa2_io_store *s)
+{
+	struct qbman_pull_desc pd;
+	int err;
+
+	qbman_pull_desc_clear(&pd);
+	qbman_pull_desc_set_storage(&pd, s->vaddr, s->paddr, 1);
+	qbman_pull_desc_set_numframes(&pd, (uint8_t)s->max);
+	qbman_pull_desc_set_channel(&pd, channelid, qbman_pull_type_prio);
+	d = _service_select(d);
+	if (!d)
+		return -ENODEV;
+	s->swp = d->object.swp;
+	err = qbman_swp_pull(d->object.swp, &pd);
+	if (err)
+		s->swp = NULL;
+	return err;
+}
+EXPORT_SYMBOL(dpaa2_io_service_pull_channel);
+
+int dpaa2_io_service_enqueue_fq(struct dpaa2_io *d,
+			       uint32_t fqid,
+			       const struct dpaa2_fd *fd)
+{
+	struct qbman_eq_desc ed;
+
+	d = _service_select(d);
+	if (!d)
+		return -ENODEV;
+	qbman_eq_desc_clear(&ed);
+	qbman_eq_desc_set_no_orp(&ed, 0);
+	qbman_eq_desc_set_fq(&ed, fqid);
+	return qbman_swp_enqueue(d->object.swp, &ed,
+				 (const struct qbman_fd *)fd);
+}
+EXPORT_SYMBOL(dpaa2_io_service_enqueue_fq);
+
+int dpaa2_io_service_enqueue_orp_fq(struct dpaa2_io *d,
+				    uint32_t fqid,
+				    const struct dpaa2_fd *fd,
+				    uint16_t orp_id,
+				    uint16_t seqnum,
+				    int last)
+{
+	struct qbman_eq_desc ed;
+
+	d = _service_select(d);
+	if (!d)
+		return -ENODEV;
+	qbman_eq_desc_clear(&ed);
+	qbman_eq_desc_set_orp(&ed, 0, orp_id, seqnum, !last);
+	qbman_eq_desc_set_fq(&ed, fqid);
+	return qbman_swp_enqueue(d->object.swp, &ed,
+				 (const struct qbman_fd *)fd);
+}
+EXPORT_SYMBOL(dpaa2_io_service_enqueue_orp_fq);
+
+int dpaa2_io_service_enqueue_qd(struct dpaa2_io *d,
+			       uint32_t qdid, uint8_t prio, uint16_t qdbin,
+			       const struct dpaa2_fd *fd)
+{
+	struct qbman_eq_desc ed;
+
+	d = _service_select(d);
+	if (!d)
+		return -ENODEV;
+	qbman_eq_desc_clear(&ed);
+	qbman_eq_desc_set_no_orp(&ed, 0);
+	qbman_eq_desc_set_qd(&ed, qdid, qdbin, prio);
+	return qbman_swp_enqueue(d->object.swp, &ed,
+				 (const struct qbman_fd *)fd);
+}
+EXPORT_SYMBOL(dpaa2_io_service_enqueue_qd);
+
+int dpaa2_io_service_enqueue_orp_qd(struct dpaa2_io *d,
+				    uint32_t qdid, uint8_t prio,
+				    uint16_t qdbin,
+				    const struct dpaa2_fd *fd,
+				    uint16_t orp_id,
+				    uint16_t seqnum,
+				    int last)
+{
+	struct qbman_eq_desc ed;
+
+	d = _service_select(d);
+	if (!d)
+		return -ENODEV;
+	qbman_eq_desc_clear(&ed);
+	qbman_eq_desc_set_orp(&ed, 0, orp_id, seqnum, !last);
+	qbman_eq_desc_set_qd(&ed, qdid, qdbin, prio);
+	return qbman_swp_enqueue(d->object.swp, &ed,
+				 (const struct qbman_fd *)fd);
+}
+EXPORT_SYMBOL(dpaa2_io_service_enqueue_orp_qd);
+
+int dpaa2_io_service_orp_seqnum_drop(struct dpaa2_io *d,
+				     uint16_t orp_id, uint16_t seqnum)
+{
+	struct qbman_eq_desc ed;
+	struct qbman_fd fd;
+
+	d = _service_select(d);
+	if (!d)
+		return -ENODEV;
+	qbman_eq_desc_clear(&ed);
+	qbman_eq_desc_set_orp_hole(&ed, orp_id, seqnum);
+	return qbman_swp_enqueue(d->object.swp, &ed, &fd);
+}
+EXPORT_SYMBOL(dpaa2_io_service_orp_seqnum_drop);
+
+int dpaa2_io_service_release(struct dpaa2_io *d,
+			    uint32_t bpid,
+			    const uint64_t *buffers,
+			    unsigned int num_buffers)
+{
+	struct qbman_release_desc rd;
+
+	d = _service_select(d);
+	if (!d)
+		return -ENODEV;
+	qbman_release_desc_clear(&rd);
+	qbman_release_desc_set_bpid(&rd, bpid);
+	return qbman_swp_release(d->object.swp, &rd, buffers, num_buffers);
+}
+EXPORT_SYMBOL(dpaa2_io_service_release);
+
+int dpaa2_io_service_acquire(struct dpaa2_io *d,
+			    uint32_t bpid,
+			    uint64_t *buffers,
+			    unsigned int num_buffers)
+{
+	unsigned long irqflags;
+	int err;
+
+	d = _service_select(d);
+	if (!d)
+		return -ENODEV;
+	spin_lock_irqsave(&d->object.lock_mgmt_cmd, irqflags);
+	err = qbman_swp_acquire(d->object.swp, bpid, buffers, num_buffers);
+	spin_unlock_irqrestore(&d->object.lock_mgmt_cmd, irqflags);
+	return err;
+}
+EXPORT_SYMBOL(dpaa2_io_service_acquire);
+
+struct dpaa2_io_store *dpaa2_io_store_create(unsigned int max_frames,
+					   struct device *dev)
+{
+	struct dpaa2_io_store *ret = kmalloc(sizeof(*ret), GFP_KERNEL);
+	size_t size;
+
+	BUG_ON(!max_frames || (max_frames > 16));
+	if (!ret)
+		return NULL;
+	ret->max = max_frames;
+	size = max_frames * sizeof(struct dpaa2_dq) + 64;
+	ret->alloced_addr = kmalloc(size, GFP_KERNEL);
+	if (!ret->alloced_addr) {
+		kfree(ret);
+		return NULL;
+	}
+	ret->vaddr =  PTR_ALIGN(ret->alloced_addr, 64);
+	ret->paddr = dma_map_single(dev, ret->vaddr,
+				    sizeof(struct dpaa2_dq) * max_frames,
+				    DMA_FROM_DEVICE);
+	if (dma_mapping_error(dev, ret->paddr)) {
+		kfree(ret->alloced_addr);
+		kfree(ret);
+		return NULL;
+	}
+	ret->idx = 0;
+	ret->dev = dev;
+	return ret;
+}
+EXPORT_SYMBOL(dpaa2_io_store_create);
+
+void dpaa2_io_store_destroy(struct dpaa2_io_store *s)
+{
+	dma_unmap_single(s->dev, s->paddr, sizeof(struct dpaa2_dq) * s->max,
+			 DMA_FROM_DEVICE);
+	kfree(s->alloced_addr);
+	kfree(s);
+}
+EXPORT_SYMBOL(dpaa2_io_store_destroy);
+
+struct dpaa2_dq *dpaa2_io_store_next(struct dpaa2_io_store *s, int *is_last)
+{
+	int match;
+	struct dpaa2_dq *ret = &s->vaddr[s->idx];
+
+	match = qbman_result_has_new_result(s->swp, ret);
+	if (!match) {
+		*is_last = 0;
+		return NULL;
+	}
+	BUG_ON(!qbman_result_is_DQ(ret));
+	s->idx++;
+	if (dpaa2_dq_is_pull_complete(ret)) {
+		*is_last = 1;
+		s->idx = 0;
+		/* If we get an empty dequeue result to terminate a zero-results
+		 * vdqcr, return NULL to the caller rather than expecting him to
+		 * check non-NULL results every time. */
+		if (!(dpaa2_dq_flags(ret) & DPAA2_DQ_STAT_VALIDFRAME))
+			ret = NULL;
+	} else
+		*is_last = 0;
+	return ret;
+}
+EXPORT_SYMBOL(dpaa2_io_store_next);
+
+#ifdef CONFIG_FSL_QBMAN_DEBUG
+int dpaa2_io_query_fq_count(struct dpaa2_io *d, uint32_t fqid,
+			   uint32_t *fcnt, uint32_t *bcnt)
+{
+	struct qbman_attr state;
+	struct qbman_swp *swp;
+	unsigned long irqflags;
+	int ret;
+
+	d = service_select_any(d);
+	if (!d)
+		return -ENODEV;
+
+	swp = d->object.swp;
+	spin_lock_irqsave(&d->object.lock_mgmt_cmd, irqflags);
+	ret = qbman_fq_query_state(swp, fqid, &state);
+	spin_unlock_irqrestore(&d->object.lock_mgmt_cmd, irqflags);
+	if (ret)
+		return ret;
+	*fcnt = qbman_fq_state_frame_count(&state);
+	*bcnt = qbman_fq_state_byte_count(&state);
+
+	return 0;
+}
+EXPORT_SYMBOL(dpaa2_io_query_fq_count);
+
+int dpaa2_io_query_bp_count(struct dpaa2_io *d, uint32_t bpid,
+			   uint32_t *num)
+{
+	struct qbman_attr state;
+	struct qbman_swp *swp;
+	unsigned long irqflags;
+	int ret;
+
+	d = service_select_any(d);
+	if (!d)
+		return -ENODEV;
+
+	swp = d->object.swp;
+	spin_lock_irqsave(&d->object.lock_mgmt_cmd, irqflags);
+	ret = qbman_bp_query(swp, bpid, &state);
+	spin_unlock_irqrestore(&d->object.lock_mgmt_cmd, irqflags);
+	if (ret)
+		return ret;
+	*num = qbman_bp_info_num_free_bufs(&state);
+	return 0;
+}
+EXPORT_SYMBOL(dpaa2_io_query_bp_count);
+
+#endif
+
+/* module init/exit hooks called from dpio-drv.c. These are declared in
+ * dpio-drv.h.
+ */
+int dpaa2_io_service_driver_init(void)
+{
+	service_init(&def_serv, 1);
+	return 0;
+}
+
+void dpaa2_io_service_driver_exit(void)
+{
+	if (atomic_read(&def_serv.refs) != 1)
+		pr_err("default DPIO service leaves dangling DPIO objects!\n");
+}
diff --git a/drivers/staging/fsl-mc/bus/dpio/fsl_dpio.h b/drivers/staging/fsl-mc/bus/dpio/fsl_dpio.h
new file mode 100644
index 0000000..668e0fa
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/fsl_dpio.h
@@ -0,0 +1,475 @@
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ * * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * * Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in the
+ * documentation and/or other materials provided with the distribution.
+ * * Neither the name of the above-listed copyright holders nor the
+ * names of any contributors may be used to endorse or promote products
+ * derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef __FSL_DPIO_H
+#define __FSL_DPIO_H
+
+/* Data Path I/O Portal API
+ * Contains initialization APIs and runtime control APIs for DPIO
+ */
+
+struct fsl_mc_io;
+
+/**
+ * dpio_open() - Open a control session for the specified object
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @dpio_id:	DPIO unique ID
+ * @token:	Returned token; use in subsequent API calls
+ *
+ * This function can be used to open a control session for an
+ * already created object; an object may have been declared in
+ * the DPL or by calling the dpio_create() function.
+ * This function returns a unique authentication token,
+ * associated with the specific object ID and any MC portals
+ * assigned to the parent container; this token must be used in
+ * all subsequent commands for this specific object.
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_open(struct fsl_mc_io	*mc_io,
+	      uint32_t		cmd_flags,
+	      int		dpio_id,
+	      uint16_t		*token);
+
+/**
+ * dpio_close() - Close the control session of the object
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_close(struct fsl_mc_io	*mc_io,
+	       uint32_t		cmd_flags,
+	       uint16_t		token);
+
+/**
+ * enum dpio_channel_mode - DPIO notification channel mode
+ * @DPIO_NO_CHANNEL: No support for notification channel
+ * @DPIO_LOCAL_CHANNEL: Notifications on data availability can be received by a
+ *	dedicated channel in the DPIO; user should point the queue's
+ *	destination in the relevant interface to this DPIO
+ */
+enum dpio_channel_mode {
+	DPIO_NO_CHANNEL = 0,
+	DPIO_LOCAL_CHANNEL = 1,
+};
+
+/**
+ * struct dpio_cfg - Structure representing DPIO configuration
+ * @channel_mode: Notification channel mode
+ * @num_priorities: Number of priorities for the notification channel (1-8);
+ *			relevant only if 'channel_mode = DPIO_LOCAL_CHANNEL'
+ */
+struct dpio_cfg {
+	enum dpio_channel_mode	channel_mode;
+	uint8_t			num_priorities;
+};
+
+/**
+ * dpio_create() - Create the DPIO object.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @dprc_token:	Parent container token; '0' for default container
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @cfg:	Configuration structure
+ * @obj_id: returned object id
+ *
+ * Create the DPIO object, allocate required resources and
+ * perform required initialization.
+ *
+ * The object can be created either by declaring it in the
+ * DPL file, or by calling this function.
+ *
+ * The function accepts an authentication token of a parent
+ * container that this object should be assigned to. The token
+ * can be '0' so the object will be assigned to the default container.
+ * The newly created object can be opened with the returned
+ * object id and using the container's associated tokens and MC portals.
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_create(struct fsl_mc_io	*mc_io,
+		uint16_t		dprc_token,
+		uint32_t		cmd_flags,
+		const struct dpio_cfg	*cfg,
+		uint32_t		*obj_id);
+
+/**
+ * dpio_destroy() - Destroy the DPIO object and release all its resources.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @dprc_token: Parent container token; '0' for default container
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @object_id:	The object id; it must be a valid id within the container that
+ * created this object;
+ *
+ * The function accepts the authentication token of the parent container that
+ * created the object (not the one that currently owns the object). The object
+ * is searched within parent using the provided 'object_id'.
+ * All tokens to the object must be closed before calling destroy.
+ *
+ * Return:	'0' on Success; Error code otherwise
+ */
+int dpio_destroy(struct fsl_mc_io	*mc_io,
+		 uint16_t		dprc_token,
+		uint32_t		cmd_flags,
+		uint32_t		object_id);
+
+/**
+ * dpio_enable() - Enable the DPIO, allow I/O portal operations.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ *
+ * Return:	'0' on Success; Error code otherwise
+ */
+int dpio_enable(struct fsl_mc_io	*mc_io,
+		uint32_t		cmd_flags,
+		uint16_t		token);
+
+/**
+ * dpio_disable() - Disable the DPIO, stop any I/O portal operation.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ *
+ * Return:	'0' on Success; Error code otherwise
+ */
+int dpio_disable(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
+		 uint16_t		token);
+
+/**
+ * dpio_is_enabled() - Check if the DPIO is enabled.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @en:	Returns '1' if object is enabled; '0' otherwise
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_is_enabled(struct fsl_mc_io	*mc_io,
+		    uint32_t		cmd_flags,
+		    uint16_t		token,
+		    int			*en);
+
+/**
+ * dpio_reset() - Reset the DPIO, returns the object to initial state.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_reset(struct fsl_mc_io	*mc_io,
+	       uint32_t		cmd_flags,
+	       uint16_t		token);
+
+/**
+ * dpio_set_stashing_destination() - Set the stashing destination.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @sdest:	stashing destination value
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_set_stashing_destination(struct fsl_mc_io	*mc_io,
+				  uint32_t		cmd_flags,
+				  uint16_t		token,
+				  uint8_t		sdest);
+
+/**
+ * dpio_get_stashing_destination() - Get the stashing destination..
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @sdest:	Returns the stashing destination value
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_get_stashing_destination(struct fsl_mc_io	*mc_io,
+				  uint32_t		cmd_flags,
+				  uint16_t		token,
+				  uint8_t		*sdest);
+
+/**
+ * dpio_add_static_dequeue_channel() - Add a static dequeue channel.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @dpcon_id:	DPCON object ID
+ * @channel_index: Returned channel index to be used in qbman API
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_add_static_dequeue_channel(struct fsl_mc_io	*mc_io,
+				    uint32_t		cmd_flags,
+				    uint16_t		token,
+				    int			dpcon_id,
+				    uint8_t		*channel_index);
+
+/**
+ * dpio_remove_static_dequeue_channel() - Remove a static dequeue channel.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @dpcon_id:	DPCON object ID
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_remove_static_dequeue_channel(struct fsl_mc_io	*mc_io,
+				       uint32_t		cmd_flags,
+				       uint16_t		token,
+				       int		dpcon_id);
+
+/**
+ * DPIO IRQ Index and Events
+ */
+
+/**
+ * Irq software-portal index
+ */
+#define DPIO_IRQ_SWP_INDEX				0
+
+/**
+ * struct dpio_irq_cfg - IRQ configuration
+ * @addr:	Address that must be written to signal a message-based interrupt
+ * @val:	Value to write into irq_addr address
+ * @irq_num: A user defined number associated with this IRQ
+ */
+struct dpio_irq_cfg {
+	     uint64_t		addr;
+	     uint32_t		val;
+	     int		irq_num;
+};
+
+/**
+ * dpio_set_irq() - Set IRQ information for the DPIO to trigger an interrupt.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @irq_index:	Identifies the interrupt index to configure
+ * @irq_cfg:	IRQ configuration
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_set_irq(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
+		 uint16_t		token,
+		 uint8_t		irq_index,
+		 struct dpio_irq_cfg	*irq_cfg);
+
+/**
+ * dpio_get_irq() - Get IRQ information from the DPIO.
+ *
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @irq_index:	The interrupt index to configure
+ * @type:	Interrupt type: 0 represents message interrupt
+ *		type (both irq_addr and irq_val are valid)
+ * @irq_cfg:	IRQ attributes
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_get_irq(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
+		 uint16_t		token,
+		 uint8_t		irq_index,
+		 int			*type,
+		 struct dpio_irq_cfg	*irq_cfg);
+
+/**
+ * dpio_set_irq_enable() - Set overall interrupt state.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @irq_index:	The interrupt index to configure
+ * @en:		Interrupt state - enable = 1, disable = 0
+ *
+ * Allows GPP software to control when interrupts are generated.
+ * Each interrupt can have up to 32 causes.  The enable/disable control's the
+ * overall interrupt state. if the interrupt is disabled no causes will cause
+ * an interrupt.
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_set_irq_enable(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
+			uint16_t		token,
+			uint8_t			irq_index,
+			uint8_t			en);
+
+/**
+ * dpio_get_irq_enable() - Get overall interrupt state
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @irq_index:	The interrupt index to configure
+ * @en:		Returned interrupt state - enable = 1, disable = 0
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_get_irq_enable(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
+			uint16_t		token,
+			uint8_t			irq_index,
+			uint8_t			*en);
+
+/**
+ * dpio_set_irq_mask() - Set interrupt mask.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @irq_index:	The interrupt index to configure
+ * @mask:	event mask to trigger interrupt;
+ *			each bit:
+ *				0 = ignore event
+ *				1 = consider event for asserting IRQ
+ *
+ * Every interrupt can have up to 32 causes and the interrupt model supports
+ * masking/unmasking each cause independently
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_set_irq_mask(struct fsl_mc_io	*mc_io,
+		      uint32_t		cmd_flags,
+		      uint16_t		token,
+		      uint8_t		irq_index,
+		      uint32_t		mask);
+
+/**
+ * dpio_get_irq_mask() - Get interrupt mask.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @irq_index:	The interrupt index to configure
+ * @mask:	Returned event mask to trigger interrupt
+ *
+ * Every interrupt can have up to 32 causes and the interrupt model supports
+ * masking/unmasking each cause independently
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_get_irq_mask(struct fsl_mc_io	*mc_io,
+		      uint32_t		cmd_flags,
+		      uint16_t		token,
+		      uint8_t		irq_index,
+		      uint32_t		*mask);
+
+/**
+ * dpio_get_irq_status() - Get the current status of any pending interrupts.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @irq_index:	The interrupt index to configure
+ * @status:	Returned interrupts status - one bit per cause:
+ *			0 = no interrupt pending
+ *			1 = interrupt pending
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_get_irq_status(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
+			uint16_t		token,
+			uint8_t			irq_index,
+			uint32_t		*status);
+
+/**
+ * dpio_clear_irq_status() - Clear a pending interrupt's status
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @irq_index:	The interrupt index to configure
+ * @status:	bits to clear (W1C) - one bit per cause:
+ *			0 = don't change
+ *			1 = clear status bit
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpio_clear_irq_status(struct fsl_mc_io	*mc_io,
+			  uint32_t		cmd_flags,
+			  uint16_t		token,
+			  uint8_t		irq_index,
+			  uint32_t		status);
+
+/**
+ * struct dpio_attr - Structure representing DPIO attributes
+ * @id: DPIO object ID
+ * @qbman_portal_ce_offset: offset of the software portal cache-enabled area
+ * @qbman_portal_ci_offset: offset of the software portal cache-inhibited area
+ * @qbman_portal_id: Software portal ID
+ * @channel_mode: Notification channel mode
+ * @num_priorities: Number of priorities for the notification channel (1-8);
+ *			relevant only if 'channel_mode = DPIO_LOCAL_CHANNEL'
+ * @qbman_version: QBMAN version
+ */
+struct dpio_attr {
+	int			id;
+	uint64_t		qbman_portal_ce_offset;
+	uint64_t		qbman_portal_ci_offset;
+	uint16_t		qbman_portal_id;
+	enum dpio_channel_mode	channel_mode;
+	uint8_t			num_priorities;
+	uint32_t		qbman_version;
+	uint32_t		clk;
+};
+
+/**
+ * dpio_get_attributes() - Retrieve DPIO attributes
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPIO object
+ * @attr:	Returned object's attributes
+ *
+ * Return:	'0' on Success; Error code otherwise
+ */
+int dpio_get_attributes(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
+			uint16_t		token,
+			struct dpio_attr	*attr);
+
+/**
+ * dpio_get_api_version() - Get Data Path I/O API version
+ * @mc_io:  Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @major_ver:	Major version of data path i/o API
+ * @minor_ver:	Minor version of data path i/o API
+ *
+ * Return:  '0' on Success; Error code otherwise.
+ */
+int dpio_get_api_version(struct fsl_mc_io *mc_io,
+			 uint32_t cmd_flags,
+			 uint16_t *major_ver,
+			 uint16_t *minor_ver);
+
+#endif /* __FSL_DPIO_H */
diff --git a/drivers/staging/fsl-mc/bus/dpio/fsl_dpio_cmd.h b/drivers/staging/fsl-mc/bus/dpio/fsl_dpio_cmd.h
new file mode 100644
index 0000000..8fd078b
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/fsl_dpio_cmd.h
@@ -0,0 +1,187 @@
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ * * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * * Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in the
+ * documentation and/or other materials provided with the distribution.
+ * * Neither the name of the above-listed copyright holders nor the
+ * names of any contributors may be used to endorse or promote products
+ * derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef _FSL_DPIO_CMD_H
+#define _FSL_DPIO_CMD_H
+
+/* DPIO Version */
+#define DPIO_VER_MAJOR				4
+#define DPIO_VER_MINOR				2
+#define DPIO_CMD_BASE_VERSION			1
+#define DPIO_CMD_ID_OFFSET			4
+
+/* Command IDs */
+#define DPIO_CMDID_CLOSE                         ((0x800 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_OPEN                          ((0x803 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_CREATE                        ((0x903 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_DESTROY                       ((0x983 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_GET_API_VERSION               ((0xa03 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+
+#define DPIO_CMDID_ENABLE                        ((0x002 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_DISABLE                       ((0x003 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_GET_ATTR                      ((0x004 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_RESET                         ((0x005 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_IS_ENABLED                    ((0x006 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+
+#define DPIO_CMDID_SET_IRQ                       ((0x010 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_GET_IRQ                       ((0x011 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_SET_IRQ_ENABLE                ((0x012 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_GET_IRQ_ENABLE                ((0x013 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_SET_IRQ_MASK                  ((0x014 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_GET_IRQ_MASK                  ((0x015 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_GET_IRQ_STATUS                ((0x016 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_CLEAR_IRQ_STATUS              ((0x017 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+
+#define DPIO_CMDID_SET_STASHING_DEST             ((0x120 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_GET_STASHING_DEST             ((0x121 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_ADD_STATIC_DEQUEUE_CHANNEL    ((0x122 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+#define DPIO_CMDID_REMOVE_STATIC_DEQUEUE_CHANNEL ((0x123 << DPIO_CMD_ID_OFFSET) | DPIO_CMD_BASE_VERSION)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_CMD_OPEN(cmd, dpio_id) \
+	MC_CMD_OP(cmd, 0, 0,  32, uint32_t,     dpio_id)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_CMD_CREATE(cmd, cfg) \
+do { \
+	MC_CMD_OP(cmd, 0, 16, 2,  enum dpio_channel_mode,	\
+					   cfg->channel_mode);\
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t, cfg->num_priorities);\
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_RSP_IS_ENABLED(cmd, en) \
+	MC_RSP_OP(cmd, 0, 0,  1,  int,	    en)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_CMD_SET_IRQ(cmd, irq_index, irq_cfg) \
+do { \
+	MC_CMD_OP(cmd, 0, 0,  8,  uint8_t,  irq_index);\
+	MC_CMD_OP(cmd, 0, 32, 32, uint32_t, irq_cfg->val);\
+	MC_CMD_OP(cmd, 1, 0,  64, uint64_t, irq_cfg->addr);\
+	MC_CMD_OP(cmd, 2, 0,  32, int,	    irq_cfg->irq_num); \
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_CMD_GET_IRQ(cmd, irq_index) \
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_RSP_GET_IRQ(cmd, type, irq_cfg) \
+do { \
+	MC_RSP_OP(cmd, 0, 0,  32, uint32_t, irq_cfg->val); \
+	MC_RSP_OP(cmd, 1, 0,  64, uint64_t, irq_cfg->addr); \
+	MC_RSP_OP(cmd, 2, 0,  32, int,	    irq_cfg->irq_num); \
+	MC_RSP_OP(cmd, 2, 32, 32, int,	    type); \
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_CMD_SET_IRQ_ENABLE(cmd, irq_index, en) \
+do { \
+	MC_CMD_OP(cmd, 0, 0,  8,  uint8_t, en); \
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t, irq_index);\
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_CMD_GET_IRQ_ENABLE(cmd, irq_index) \
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_RSP_GET_IRQ_ENABLE(cmd, en) \
+	MC_RSP_OP(cmd, 0, 0,  8,  uint8_t,  en)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_CMD_SET_IRQ_MASK(cmd, irq_index, mask) \
+do { \
+	MC_CMD_OP(cmd, 0, 0,  32, uint32_t, mask); \
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index);\
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_CMD_GET_IRQ_MASK(cmd, irq_index) \
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_RSP_GET_IRQ_MASK(cmd, mask) \
+	MC_RSP_OP(cmd, 0, 0,  32, uint32_t, mask)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_CMD_GET_IRQ_STATUS(cmd, irq_index, status) \
+do { \
+	MC_CMD_OP(cmd, 0, 0,  32, uint32_t, status);\
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index);\
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_RSP_GET_IRQ_STATUS(cmd, status) \
+	MC_RSP_OP(cmd, 0, 0,  32, uint32_t, status)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_CMD_CLEAR_IRQ_STATUS(cmd, irq_index, status) \
+do { \
+	MC_CMD_OP(cmd, 0, 0,  32, uint32_t, status); \
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index);\
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_RSP_GET_ATTR(cmd, attr) \
+do { \
+	MC_RSP_OP(cmd, 0, 0,  32, int,	    attr->id);\
+	MC_RSP_OP(cmd, 0, 32, 16, uint16_t, attr->qbman_portal_id);\
+	MC_RSP_OP(cmd, 0, 48, 8,  uint8_t,  attr->num_priorities);\
+	MC_RSP_OP(cmd, 0, 56, 4,  enum dpio_channel_mode, attr->channel_mode);\
+	MC_RSP_OP(cmd, 1, 0,  64, uint64_t, attr->qbman_portal_ce_offset);\
+	MC_RSP_OP(cmd, 2, 0,  64, uint64_t, attr->qbman_portal_ci_offset);\
+	MC_RSP_OP(cmd, 3, 0, 32, uint32_t, attr->qbman_version);\
+	MC_RSP_OP(cmd, 4, 0,  32, uint32_t, attr->clk);\
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_CMD_SET_STASHING_DEST(cmd, sdest) \
+	MC_CMD_OP(cmd, 0, 0,  8,  uint8_t,  sdest)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_RSP_GET_STASHING_DEST(cmd, sdest) \
+	MC_RSP_OP(cmd, 0, 0,  8,  uint8_t,  sdest)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_CMD_ADD_STATIC_DEQUEUE_CHANNEL(cmd, dpcon_id) \
+	MC_CMD_OP(cmd, 0, 0,  32, int,      dpcon_id)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_RSP_ADD_STATIC_DEQUEUE_CHANNEL(cmd, channel_index) \
+	MC_RSP_OP(cmd, 0, 0,  8,  uint8_t,  channel_index)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPIO_CMD_REMOVE_STATIC_DEQUEUE_CHANNEL(cmd, dpcon_id) \
+	MC_CMD_OP(cmd, 0, 0,  32, int,      dpcon_id)
+
+#endif /* _FSL_DPIO_CMD_H */
diff --git a/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_base.h b/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_base.h
new file mode 100644
index 0000000..2874ff8
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_base.h
@@ -0,0 +1,123 @@
+/* Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef _FSL_QBMAN_BASE_H
+#define _FSL_QBMAN_BASE_H
+
+/**
+ * struct qbman_block_desc - qbman block descriptor structure
+ *
+ * Descriptor for a QBMan instance on the SoC. On partitions/targets that do not
+ * control this QBMan instance, these values may simply be place-holders. The
+ * idea is simply that we be able to distinguish between them, eg. so that SWP
+ * descriptors can identify which QBMan instance they belong to.
+ */
+struct qbman_block_desc {
+	void *ccsr_reg_bar; /* CCSR register map */
+	int irq_rerr;  /* Recoverable error interrupt line */
+	int irq_nrerr; /* Non-recoverable error interrupt line */
+};
+
+/**
+ * struct qbman_swp_desc - qbman software portal descriptor structure
+ *
+ * Descriptor for a QBMan software portal, expressed in terms that make sense to
+ * the user context. Ie. on MC, this information is likely to be true-physical,
+ * and instantiated statically at compile-time. On GPP, this information is
+ * likely to be obtained via "discovery" over a partition's "layerscape bus"
+ * (ie. in response to a MC portal command), and would take into account any
+ * virtualisation of the GPP user's address space and/or interrupt numbering.
+ */
+struct qbman_swp_desc {
+	const struct qbman_block_desc *block; /* The QBMan instance */
+	void *cena_bar; /* Cache-enabled portal register map */
+	void *cinh_bar; /* Cache-inhibited portal register map */
+	uint32_t qman_version;
+};
+
+/* Driver object for managing a QBMan portal */
+struct qbman_swp;
+
+/**
+ * struct qbman_fd - basci structure for qbman frame descriptor
+ *
+ * Place-holder for FDs, we represent it via the simplest form that we need for
+ * now. Different overlays may be needed to support different options, etc. (It
+ * is impractical to define One True Struct, because the resulting encoding
+ * routines (lots of read-modify-writes) would be worst-case performance whether
+ * or not circumstances required them.)
+ *
+ * Note, as with all data-structures exchanged between software and hardware (be
+ * they located in the portal register map or DMA'd to and from main-memory),
+ * the driver ensures that the caller of the driver API sees the data-structures
+ * in host-endianness. "struct qbman_fd" is no exception. The 32-bit words
+ * contained within this structure are represented in host-endianness, even if
+ * hardware always treats them as little-endian. As such, if any of these fields
+ * are interpreted in a binary (rather than numerical) fashion by hardware
+ * blocks (eg. accelerators), then the user should be careful. We illustrate
+ * with an example;
+ *
+ * Suppose the desired behaviour of an accelerator is controlled by the "frc"
+ * field of the FDs that are sent to it. Suppose also that the behaviour desired
+ * by the user corresponds to an "frc" value which is expressed as the literal
+ * sequence of bytes 0xfe, 0xed, 0xab, and 0xba. So "frc" should be the 32-bit
+ * value in which 0xfe is the first byte and 0xba is the last byte, and as
+ * hardware is little-endian, this amounts to a 32-bit "value" of 0xbaabedfe. If
+ * the software is little-endian also, this can simply be achieved by setting
+ * frc=0xbaabedfe. On the other hand, if software is big-endian, it should set
+ * frc=0xfeedabba! The best away of avoiding trouble with this sort of thing is
+ * to treat the 32-bit words as numerical values, in which the offset of a field
+ * from the beginning of the first byte (as required or generated by hardware)
+ * is numerically encoded by a left-shift (ie. by raising the field to a
+ * corresponding power of 2).  Ie. in the current example, software could set
+ * "frc" in the following way, and it would work correctly on both little-endian
+ * and big-endian operation;
+ *    fd.frc = (0xfe << 0) | (0xed << 8) | (0xab << 16) | (0xba << 24);
+ */
+struct qbman_fd {
+	union {
+		uint32_t words[8];
+		struct qbman_fd_simple {
+			uint32_t addr_lo;
+			uint32_t addr_hi;
+			uint32_t len;
+			/* offset in the MS 16 bits, BPID in the LS 16 bits */
+			uint32_t bpid_offset;
+			uint32_t frc; /* frame context */
+			/* "err", "va", "cbmt", "asal", [...] */
+			uint32_t ctrl;
+			/* flow context */
+			uint32_t flc_lo;
+			uint32_t flc_hi;
+		} simple;
+	};
+};
+
+#endif /* !_FSL_QBMAN_BASE_H */
diff --git a/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h b/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h
new file mode 100644
index 0000000..c9e543e
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/fsl_qbman_portal.h
@@ -0,0 +1,753 @@
+/* Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef _FSL_QBMAN_PORTAL_H
+#define _FSL_QBMAN_PORTAL_H
+
+#include "fsl_qbman_base.h"
+
+/**
+ * qbman_swp_init() - Create a functional object representing the given
+ * QBMan portal descriptor.
+ * @d: the given qbman swp descriptor
+ *
+ * Return qbman_swp portal object for success, NULL if the object cannot
+ * be created.
+ */
+struct qbman_swp *qbman_swp_init(const struct qbman_swp_desc *d);
+/**
+ * qbman_swp_finish() - Create and destroy a functional object representing
+ * the given QBMan portal descriptor.
+ * @p: the qbman_swp object to be destroyed.
+ *
+ */
+void qbman_swp_finish(struct qbman_swp *p);
+
+/**
+ * qbman_swp_get_desc() - Get the descriptor of the given portal object.
+ * @p: the given portal object.
+ *
+ * Return the descriptor for this portal.
+ */
+const struct qbman_swp_desc *qbman_swp_get_desc(struct qbman_swp *p);
+
+	/**************/
+	/* Interrupts */
+	/**************/
+
+/* See the QBMan driver API documentation for details on the interrupt
+ * mechanisms. */
+#define QBMAN_SWP_INTERRUPT_EQRI ((uint32_t)0x00000001)
+#define QBMAN_SWP_INTERRUPT_EQDI ((uint32_t)0x00000002)
+#define QBMAN_SWP_INTERRUPT_DQRI ((uint32_t)0x00000004)
+#define QBMAN_SWP_INTERRUPT_RCRI ((uint32_t)0x00000008)
+#define QBMAN_SWP_INTERRUPT_RCDI ((uint32_t)0x00000010)
+#define QBMAN_SWP_INTERRUPT_VDCI ((uint32_t)0x00000020)
+
+/**
+ * qbman_swp_interrupt_get_vanish()
+ * qbman_swp_interrupt_set_vanish() - Get/Set the data in software portal
+ * interrupt status disable register.
+ * @p: the given software portal object.
+ * @mask: The mask to set in SWP_IDSR register.
+ *
+ * Return the settings in SWP_ISDR register for Get function.
+ */
+uint32_t qbman_swp_interrupt_get_vanish(struct qbman_swp *p);
+void qbman_swp_interrupt_set_vanish(struct qbman_swp *p, uint32_t mask);
+
+/**
+ * qbman_swp_interrupt_read_status()
+ * qbman_swp_interrupt_clear_status() - Get/Set the data in software portal
+ * interrupt status register.
+ * @p: the given software portal object.
+ * @mask: The mask to set in SWP_ISR register.
+ *
+ * Return the settings in SWP_ISR register for Get function.
+ *
+ */
+uint32_t qbman_swp_interrupt_read_status(struct qbman_swp *p);
+void qbman_swp_interrupt_clear_status(struct qbman_swp *p, uint32_t mask);
+
+/**
+ * qbman_swp_interrupt_get_trigger()
+ * qbman_swp_interrupt_set_trigger() - Get/Set the data in software portal
+ * interrupt enable register.
+ * @p: the given software portal object.
+ * @mask: The mask to set in SWP_IER register.
+ *
+ * Return the settings in SWP_IER register for Get function.
+ */
+uint32_t qbman_swp_interrupt_get_trigger(struct qbman_swp *p);
+void qbman_swp_interrupt_set_trigger(struct qbman_swp *p, uint32_t mask);
+
+/**
+ * qbman_swp_interrupt_get_inhibit()
+ * qbman_swp_interrupt_set_inhibit() - Set/Set the data in software portal
+ * interrupt inhibit register.
+ * @p: the given software portal object.
+ * @mask: The mask to set in SWP_IIR register.
+ *
+ * Return the settings in SWP_IIR register for Get function.
+ */
+int qbman_swp_interrupt_get_inhibit(struct qbman_swp *p);
+void qbman_swp_interrupt_set_inhibit(struct qbman_swp *p, int inhibit);
+
+	/************/
+	/* Dequeues */
+	/************/
+
+/* See the QBMan driver API documentation for details on the enqueue
+ * mechanisms. NB: the use of a 'dpaa2_' prefix for this type is because it is
+ * primarily used by the "DPIO" layer that sits above (and hides) the QBMan
+ * driver. The structure is defined in the DPIO interface, but to avoid circular
+ * dependencies we just pre/re-declare it here opaquely. */
+struct dpaa2_dq;
+
+/* ------------------- */
+/* Push-mode dequeuing */
+/* ------------------- */
+
+/**
+ * qbman_swp_push_get() - Get the push dequeue setup.
+ * @p: the software portal object.
+ * @channel_idx: the channel index to query.
+ * @enabled: returned boolean to show whether the push dequeue is enabled for
+ * the given channel.
+ */
+void qbman_swp_push_get(struct qbman_swp *, uint8_t channel_idx, int *enabled);
+/**
+ * qbman_swp_push_set() - Enable or disable push dequeue.
+ * @p: the software portal object.
+ * @channel_idx: the channel index..
+ * @enable: enable or disable push dequeue.
+ *
+ * The user of a portal can enable and disable push-mode dequeuing of up to 16
+ * channels independently. It does not specify this toggling by channel IDs, but
+ * rather by specifying the index (from 0 to 15) that has been mapped to the
+ * desired channel.
+ */
+void qbman_swp_push_set(struct qbman_swp *, uint8_t channel_idx, int enable);
+
+/* ------------------- */
+/* Pull-mode dequeuing */
+/* ------------------- */
+
+/**
+ * struct qbman_pull_desc - the structure for pull dequeue descriptor
+ */
+struct qbman_pull_desc {
+	uint32_t dont_manipulate_directly[6];
+};
+
+enum qbman_pull_type_e {
+	/* dequeue with priority precedence, respect intra-class scheduling */
+	qbman_pull_type_prio = 1,
+	/* dequeue with active FQ precedence, respect ICS */
+	qbman_pull_type_active,
+	/* dequeue with active FQ precedence, no ICS */
+	qbman_pull_type_active_noics
+};
+
+/**
+ * qbman_pull_desc_clear() - Clear the contents of a descriptor to
+ * default/starting state.
+ * @d: the pull dequeue descriptor to be cleared.
+ */
+void qbman_pull_desc_clear(struct qbman_pull_desc *d);
+
+/**
+ * qbman_pull_desc_set_storage()- Set the pull dequeue storage
+ * @d: the pull dequeue descriptor to be set.
+ * @storage: the pointer of the memory to store the dequeue result.
+ * @storage_phys: the physical address of the storage memory.
+ * @stash: to indicate whether write allocate is enabled.
+ *
+ * If not called, or if called with 'storage' as NULL, the result pull dequeues
+ * will produce results to DQRR. If 'storage' is non-NULL, then results are
+ * produced to the given memory location (using the physical/DMA address which
+ * the caller provides in 'storage_phys'), and 'stash' controls whether or not
+ * those writes to main-memory express a cache-warming attribute.
+ */
+void qbman_pull_desc_set_storage(struct qbman_pull_desc *d,
+				 struct dpaa2_dq *storage,
+				 dma_addr_t storage_phys,
+				 int stash);
+/**
+ * qbman_pull_desc_set_numframes() - Set the number of frames to be dequeued.
+ * @d: the pull dequeue descriptor to be set.
+ * @numframes: number of frames to be set, must be between 1 and 16, inclusive.
+ */
+void qbman_pull_desc_set_numframes(struct qbman_pull_desc *, uint8_t numframes);
+
+/**
+ * qbman_pull_desc_set_fq() - Set fqid from which the dequeue command dequeues.
+ * @fqid: the frame queue index of the given FQ.
+ *
+ * qbman_pull_desc_set_wq() - Set wqid from which the dequeue command dequeues.
+ * @wqid: composed of channel id and wqid within the channel.
+ * @dct: the dequeue command type.
+ *
+ * qbman_pull_desc_set_channel() - Set channelid from which the dequeue command
+ * dequeues.
+ * @chid: the channel id to be dequeued.
+ * @dct: the dequeue command type.
+ *
+ * Exactly one of the following descriptor "actions" should be set. (Calling any
+ * one of these will replace the effect of any prior call to one of these.)
+ * - pull dequeue from the given frame queue (FQ)
+ * - pull dequeue from any FQ in the given work queue (WQ)
+ * - pull dequeue from any FQ in any WQ in the given channel
+ */
+void qbman_pull_desc_set_fq(struct qbman_pull_desc *, uint32_t fqid);
+void qbman_pull_desc_set_wq(struct qbman_pull_desc *, uint32_t wqid,
+			    enum qbman_pull_type_e dct);
+void qbman_pull_desc_set_channel(struct qbman_pull_desc *, uint32_t chid,
+				 enum qbman_pull_type_e dct);
+
+/**
+ * qbman_swp_pull() - Issue the pull dequeue command
+ * @s: the software portal object.
+ * @d: the software portal descriptor which has been configured with
+ * the set of qbman_pull_desc_set_*() calls.
+ *
+ * Return 0 for success, and -EBUSY if the software portal is not ready
+ * to do pull dequeue.
+ */
+int qbman_swp_pull(struct qbman_swp *, struct qbman_pull_desc *d);
+
+/* -------------------------------- */
+/* Polling DQRR for dequeue results */
+/* -------------------------------- */
+
+/**
+ * qbman_swp_dqrr_next() - Get an valid DQRR entry.
+ * @s: the software portal object.
+ *
+ * Return NULL if there are no unconsumed DQRR entries. Return a DQRR entry
+ * only once, so repeated calls can return a sequence of DQRR entries, without
+ * requiring they be consumed immediately or in any particular order.
+ */
+const struct dpaa2_dq *qbman_swp_dqrr_next(struct qbman_swp *s);
+
+/**
+ * qbman_swp_dqrr_consume() -  Consume DQRR entries previously returned from
+ * qbman_swp_dqrr_next().
+ * @s: the software portal object.
+ * @dq: the DQRR entry to be consumed.
+ */
+void qbman_swp_dqrr_consume(struct qbman_swp *s, const struct dpaa2_dq *dq);
+
+/* ------------------------------------------------- */
+/* Polling user-provided storage for dequeue results */
+/* ------------------------------------------------- */
+/**
+ * qbman_result_has_new_result() - Check and get the dequeue response from the
+ * dq storage memory set in pull dequeue command
+ * @s: the software portal object.
+ * @dq: the dequeue result read from the memory.
+ *
+ * Only used for user-provided storage of dequeue results, not DQRR. For
+ * efficiency purposes, the driver will perform any required endianness
+ * conversion to ensure that the user's dequeue result storage is in host-endian
+ * format (whether or not that is the same as the little-endian format that
+ * hardware DMA'd to the user's storage). As such, once the user has called
+ * qbman_result_has_new_result() and been returned a valid dequeue result,
+ * they should not call it again on the same memory location (except of course
+ * if another dequeue command has been executed to produce a new result to that
+ * location).
+ *
+ * Return 1 for getting a valid dequeue result, or 0 for not getting a valid
+ * dequeue result.
+ */
+int qbman_result_has_new_result(struct qbman_swp *,
+				  const struct dpaa2_dq *);
+
+/* -------------------------------------------------------- */
+/* Parsing dequeue entries (DQRR and user-provided storage) */
+/* -------------------------------------------------------- */
+
+/**
+ * qbman_result_is_DQ() - check the dequeue result is a dequeue response or not
+ * @dq: the dequeue result to be checked.
+ *
+ * DQRR entries may contain non-dequeue results, ie. notifications
+ */
+int qbman_result_is_DQ(const struct dpaa2_dq *);
+
+/**
+ * qbman_result_is_SCN() - Check the dequeue result is notification or not
+ * @dq: the dequeue result to be checked.
+ *
+ * All the non-dequeue results (FQDAN/CDAN/CSCN/...) are "state change
+ * notifications" of one type or another. Some APIs apply to all of them, of the
+ * form qbman_result_SCN_***().
+ */
+static inline int qbman_result_is_SCN(const struct dpaa2_dq *dq)
+{
+	return !qbman_result_is_DQ(dq);
+}
+
+/**
+ * Recognise different notification types, only required if the user allows for
+ * these to occur, and cares about them when they do.
+ */
+int qbman_result_is_FQDAN(const struct dpaa2_dq *);
+				/* FQ Data Availability */
+int qbman_result_is_CDAN(const struct dpaa2_dq *);
+				/* Channel Data Availability */
+int qbman_result_is_CSCN(const struct dpaa2_dq *);
+				/* Congestion State Change */
+int qbman_result_is_BPSCN(const struct dpaa2_dq *);
+				/* Buffer Pool State Change */
+int qbman_result_is_CGCU(const struct dpaa2_dq *);
+				/* Congestion Group Count Update */
+/* Frame queue state change notifications; (FQDAN in theory counts too as it
+ * leaves a FQ parked, but it is primarily a data availability notification) */
+int qbman_result_is_FQRN(const struct dpaa2_dq *); /* Retirement */
+int qbman_result_is_FQRNI(const struct dpaa2_dq *);
+				/* Retirement Immediate */
+int qbman_result_is_FQPN(const struct dpaa2_dq *); /* Park */
+
+/* NB: for parsing dequeue results (when "is_DQ" is TRUE), use the higher-layer
+ * dpaa2_dq_*() functions. */
+
+/* State-change notifications (FQDAN/CDAN/CSCN/...). */
+/**
+ * qbman_result_SCN_state() - Get the state field in State-change notification
+ */
+uint8_t qbman_result_SCN_state(const struct dpaa2_dq *);
+/**
+ * qbman_result_SCN_rid() - Get the resource id in State-change notification
+ */
+uint32_t qbman_result_SCN_rid(const struct dpaa2_dq *);
+/**
+ * qbman_result_SCN_ctx() - Get the context data in State-change notification
+ */
+uint64_t qbman_result_SCN_ctx(const struct dpaa2_dq *);
+/**
+ * qbman_result_SCN_state_in_mem() - Get the state field in State-change
+ * notification which is written to memory instead of DQRR.
+ */
+uint8_t qbman_result_SCN_state_in_mem(const struct dpaa2_dq *);
+/**
+ * qbman_result_SCN_rid_in_mem() - Get the resource id in State-change
+ * notification which is written to memory instead of DQRR.
+ */
+uint32_t qbman_result_SCN_rid_in_mem(const struct dpaa2_dq *);
+
+/* Type-specific "resource IDs". Mainly for illustration purposes, though it
+ * also gives the appropriate type widths. */
+#define qbman_result_FQDAN_fqid(dq) qbman_result_SCN_rid(dq)
+#define qbman_result_FQRN_fqid(dq) qbman_result_SCN_rid(dq)
+#define qbman_result_FQRNI_fqid(dq) qbman_result_SCN_rid(dq)
+#define qbman_result_FQPN_fqid(dq) qbman_result_SCN_rid(dq)
+#define qbman_result_CDAN_cid(dq) ((uint16_t)qbman_result_SCN_rid(dq))
+#define qbman_result_CSCN_cgid(dq) ((uint16_t)qbman_result_SCN_rid(dq))
+
+/**
+ * qbman_result_bpscn_bpid() - Get the bpid from BPSCN
+ *
+ * Return the buffer pool id.
+ */
+uint16_t qbman_result_bpscn_bpid(const struct dpaa2_dq *);
+/**
+ * qbman_result_bpscn_has_free_bufs() - Check whether there are free
+ * buffers in the pool from BPSCN.
+ *
+ * Return the number of free buffers.
+ */
+int qbman_result_bpscn_has_free_bufs(const struct dpaa2_dq *);
+/**
+ * qbman_result_bpscn_is_depleted() - Check BPSCN to see whether the
+ * buffer pool is depleted.
+ *
+ * Return the status of buffer pool depletion.
+ */
+int qbman_result_bpscn_is_depleted(const struct dpaa2_dq *);
+/**
+ * qbman_result_bpscn_is_surplus() - Check BPSCN to see whether the buffer
+ * pool is surplus or not.
+ *
+ * Return the status of buffer pool surplus.
+ */
+int qbman_result_bpscn_is_surplus(const struct dpaa2_dq *);
+/**
+ * qbman_result_bpscn_ctx() - Get the BPSCN CTX from BPSCN message
+ *
+ * Return the BPSCN context.
+ */
+uint64_t qbman_result_bpscn_ctx(const struct dpaa2_dq *);
+
+/* Parsing CGCU */
+/**
+ * qbman_result_cgcu_cgid() - Check CGCU resouce id, i.e. cgid
+ *
+ * Return the CGCU resource id.
+ */
+uint16_t qbman_result_cgcu_cgid(const struct dpaa2_dq *);
+/**
+ * qbman_result_cgcu_icnt() - Get the I_CNT from CGCU
+ *
+ * Return instantaneous count in the CGCU notification.
+ */
+uint64_t qbman_result_cgcu_icnt(const struct dpaa2_dq *);
+
+	/************/
+	/* Enqueues */
+	/************/
+/**
+ * struct qbman_eq_desc - structure of enqueue descriptor
+ */
+struct qbman_eq_desc {
+	uint32_t dont_manipulate_directly[8];
+};
+
+/**
+ * struct qbman_eq_response - structure of enqueue response
+ */
+struct qbman_eq_response {
+	uint32_t dont_manipulate_directly[16];
+};
+
+/**
+ * qbman_eq_desc_clear() - Clear the contents of a descriptor to
+ * default/starting state.
+ */
+void qbman_eq_desc_clear(struct qbman_eq_desc *);
+
+/* Exactly one of the following descriptor "actions" should be set. (Calling
+ * any one of these will replace the effect of any prior call to one of these.)
+ * - enqueue without order-restoration
+ * - enqueue with order-restoration
+ * - fill a hole in the order-restoration sequence, without any enqueue
+ * - advance NESN (Next Expected Sequence Number), without any enqueue
+ * 'respond_success' indicates whether an enqueue response should be DMA'd
+ * after success (otherwise a response is DMA'd only after failure).
+ * 'incomplete' indicates that other fragments of the same 'seqnum' are yet to
+ * be enqueued.
+ */
+/**
+ * qbman_eq_desc_set_no_orp() - Set enqueue descriptor without orp
+ * @d: the enqueue descriptor.
+ * @response_success: 1 = enqueue with response always; 0 = enqueue with
+ * rejections returned on a FQ.
+ */
+void qbman_eq_desc_set_no_orp(struct qbman_eq_desc *d, int respond_success);
+
+/**
+ * qbman_eq_desc_set_orp() - Set order-resotration in the enqueue descriptor
+ * @d: the enqueue descriptor.
+ * @response_success: 1 = enqueue with response always; 0 = enqueue with
+ * rejections returned on a FQ.
+ * @opr_id: the order point record id.
+ * @seqnum: the order restoration sequence number.
+ * @incomplete: indiates whether this is the last fragments using the same
+ * sequeue number.
+ */
+void qbman_eq_desc_set_orp(struct qbman_eq_desc *d, int respond_success,
+			   uint32_t opr_id, uint32_t seqnum, int incomplete);
+
+/**
+ * qbman_eq_desc_set_orp_hole() - fill a hole in the order-restoration sequence
+ * without any enqueue
+ * @d: the enqueue descriptor.
+ * @opr_id: the order point record id.
+ * @seqnum: the order restoration sequence number.
+ */
+void qbman_eq_desc_set_orp_hole(struct qbman_eq_desc *d, uint32_t opr_id,
+				uint32_t seqnum);
+
+/**
+ * qbman_eq_desc_set_orp_nesn() -  advance NESN (Next Expected Sequence Number)
+ * without any enqueue
+ * @d: the enqueue descriptor.
+ * @opr_id: the order point record id.
+ * @seqnum: the order restoration sequence number.
+ */
+void qbman_eq_desc_set_orp_nesn(struct qbman_eq_desc *d, uint32_t opr_id,
+				uint32_t seqnum);
+
+/**
+ * qbman_eq_desc_set_response() - Set the enqueue response info.
+ * @d: the enqueue descriptor
+ * @storage_phys: the physical address of the enqueue response in memory.
+ * @stash: indicate that the write allocation enabled or not.
+ *
+ * In the case where an enqueue response is DMA'd, this determines where that
+ * response should go. (The physical/DMA address is given for hardware's
+ * benefit, but software should interpret it as a "struct qbman_eq_response"
+ * data structure.) 'stash' controls whether or not the write to main-memory
+ * expresses a cache-warming attribute.
+ */
+void qbman_eq_desc_set_response(struct qbman_eq_desc *d,
+				dma_addr_t storage_phys,
+				int stash);
+/**
+ * qbman_eq_desc_set_token() - Set token for the enqueue command
+ * @d: the enqueue descriptor
+ * @token: the token to be set.
+ *
+ * token is the value that shows up in an enqueue response that can be used to
+ * detect when the results have been published. The easiest technique is to zero
+ * result "storage" before issuing an enqueue, and use any non-zero 'token'
+ * value.
+ */
+void qbman_eq_desc_set_token(struct qbman_eq_desc *d, uint8_t token);
+
+/**
+ * qbman_eq_desc_set_fq()
+ * qbman_eq_desc_set_qd() - Set eithe FQ or Queuing Destination for the enqueue
+ * command.
+ * @d: the enqueue descriptor
+ * @fqid: the id of the frame queue to be enqueued.
+ * @qdid: the id of the queuing destination to be enqueued.
+ * @qd_bin: the queuing destination bin
+ * @qd_prio: the queuing destination priority.
+ *
+ * Exactly one of the following descriptor "targets" should be set. (Calling any
+ * one of these will replace the effect of any prior call to one of these.)
+ * - enqueue to a frame queue
+ * - enqueue to a queuing destination
+ * Note, that none of these will have any affect if the "action" type has been
+ * set to "orp_hole" or "orp_nesn".
+ */
+void qbman_eq_desc_set_fq(struct qbman_eq_desc *, uint32_t fqid);
+void qbman_eq_desc_set_qd(struct qbman_eq_desc *, uint32_t qdid,
+			  uint32_t qd_bin, uint32_t qd_prio);
+
+/**
+ * qbman_eq_desc_set_eqdi() - enable/disable EQDI interrupt
+ * @d: the enqueue descriptor
+ * @enable: boolean to enable/disable EQDI
+ *
+ * Determines whether or not the portal's EQDI interrupt source should be
+ * asserted after the enqueue command is completed.
+ */
+void qbman_eq_desc_set_eqdi(struct qbman_eq_desc *, int enable);
+
+/**
+ * qbman_eq_desc_set_dca() - Set DCA mode in the enqueue command.
+ * @d: the enqueue descriptor.
+ * @enable: enabled/disable DCA mode.
+ * @dqrr_idx: DCAP_CI, the DCAP consumer index.
+ * @park: determine the whether park the FQ or not
+ *
+ * Determines whether or not a portal DQRR entry should be consumed once the
+ * enqueue command is completed.  (And if so, and the DQRR entry corresponds
+ * to a held-active (order-preserving) FQ, whether the FQ should be parked
+ * instead of being rescheduled.)
+ */
+void qbman_eq_desc_set_dca(struct qbman_eq_desc *, int enable,
+				uint32_t dqrr_idx, int park);
+
+/**
+ * qbman_swp_enqueue() - Issue an enqueue command.
+ * @s: the software portal used for enqueue.
+ * @d: the enqueue descriptor.
+ * @fd: the frame descriptor to be enqueued.
+ *
+ * Please note that 'fd' should only be NULL if the "action" of the
+ * descriptor is "orp_hole" or "orp_nesn".
+ *
+ * Return 0 for successful enqueue, -EBUSY if the EQCR is not ready.
+ */
+int qbman_swp_enqueue(struct qbman_swp *, const struct qbman_eq_desc *,
+		      const struct qbman_fd *fd);
+
+/**
+ * qbman_swp_enqueue_thresh() - Set the threshold for EQRI interrupt.
+ *
+ * An EQRI interrupt can be generated when the fill-level of EQCR falls below
+ * the 'thresh' value set here. Setting thresh==0 (the default) disables.
+ */
+int qbman_swp_enqueue_thresh(struct qbman_swp *, unsigned int thresh);
+
+	/*******************/
+	/* Buffer releases */
+	/*******************/
+/**
+ * struct qbman_release_desc - The structure for buffer release descriptor
+ */
+struct qbman_release_desc {
+	uint32_t dont_manipulate_directly[1];
+};
+
+/**
+ * qbman_release_desc_clear() - Clear the contents of a descriptor to
+ * default/starting state.
+ */
+void qbman_release_desc_clear(struct qbman_release_desc *);
+
+/**
+ * qbman_release_desc_set_bpid() - Set the ID of the buffer pool to release to
+ */
+void qbman_release_desc_set_bpid(struct qbman_release_desc *, uint32_t bpid);
+
+/**
+ * qbman_release_desc_set_rcdi() - Determines whether or not the portal's RCDI
+ * interrupt source should be asserted after the release command is completed.
+ */
+void qbman_release_desc_set_rcdi(struct qbman_release_desc *, int enable);
+
+/**
+ * qbman_swp_release() - Issue a buffer release command.
+ * @s: the software portal object.
+ * @d: the release descriptor.
+ * @buffers: a pointer pointing to the buffer address to be released.
+ * @num_buffers: number of buffers to be released,  must be less than 8.
+ *
+ * Return 0 for success, -EBUSY if the release command ring is not ready.
+ */
+int qbman_swp_release(struct qbman_swp *s, const struct qbman_release_desc *d,
+		      const uint64_t *buffers, unsigned int num_buffers);
+
+	/*******************/
+	/* Buffer acquires */
+	/*******************/
+
+/**
+ * qbman_swp_acquire() - Issue a buffer acquire command.
+ * @s: the software portal object.
+ * @bpid: the buffer pool index.
+ * @buffers: a pointer pointing to the acquired buffer address|es.
+ * @num_buffers: number of buffers to be acquired, must be less than 8.
+ *
+ * Return 0 for success, or negative error code if the acquire command
+ * fails.
+ */
+int qbman_swp_acquire(struct qbman_swp *, uint32_t bpid, uint64_t *buffers,
+		      unsigned int num_buffers);
+
+	/*****************/
+	/* FQ management */
+	/*****************/
+
+/**
+ * qbman_swp_fq_schedule() - Move the fq to the scheduled state.
+ * @s: the software portal object.
+ * @fqid: the index of frame queue to be scheduled.
+ *
+ * There are a couple of different ways that a FQ can end up parked state,
+ * This schedules it.
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
+int qbman_swp_fq_schedule(struct qbman_swp *s, uint32_t fqid);
+
+/**
+ * qbman_swp_fq_force() - Force the FQ to fully scheduled state.
+ * @s: the software portal object.
+ * @fqid: the index of frame queue to be forced.
+ *
+ * Force eligible will force a tentatively-scheduled FQ to be fully-scheduled
+ * and thus be available for selection by any channel-dequeuing behaviour (push
+ * or pull). If the FQ is subsequently "dequeued" from the channel and is still
+ * empty at the time this happens, the resulting dq_entry will have no FD.
+ * (qbman_result_DQ_fd() will return NULL.)
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
+int qbman_swp_fq_force(struct qbman_swp *s, uint32_t fqid);
+
+/**
+ * qbman_swp_fq_xon()
+ * qbman_swp_fq_xoff() - XON/XOFF the frame queue.
+ * @s: the software portal object.
+ * @fqid: the index of frame queue.
+ *
+ * These functions change the FQ flow-control stuff between XON/XOFF. (The
+ * default is XON.) This setting doesn't affect enqueues to the FQ, just
+ * dequeues. XOFF FQs will remain in the tenatively-scheduled state, even when
+ * non-empty, meaning they won't be selected for scheduled dequeuing. If a FQ is
+ * changed to XOFF after it had already become truly-scheduled to a channel, and
+ * a pull dequeue of that channel occurs that selects that FQ for dequeuing,
+ * then the resulting dq_entry will have no FD. (qbman_result_DQ_fd() will
+ * return NULL.)
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
+int qbman_swp_fq_xon(struct qbman_swp *s, uint32_t fqid);
+int qbman_swp_fq_xoff(struct qbman_swp *s, uint32_t fqid);
+
+	/**********************/
+	/* Channel management */
+	/**********************/
+
+/* If the user has been allocated a channel object that is going to generate
+ * CDANs to another channel, then these functions will be necessary.
+ * CDAN-enabled channels only generate a single CDAN notification, after which
+ * it they need to be reenabled before they'll generate another. (The idea is
+ * that pull dequeuing will occur in reaction to the CDAN, followed by a
+ * reenable step.) Each function generates a distinct command to hardware, so a
+ * combination function is provided if the user wishes to modify the "context"
+ * (which shows up in each CDAN message) each time they reenable, as a single
+ * command to hardware. */
+/**
+ * qbman_swp_CDAN_set_context() - Set CDAN context
+ * @s: the software portal object.
+ * @channelid: the channel index.
+ * @ctx: the context to be set in CDAN.
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
+int qbman_swp_CDAN_set_context(struct qbman_swp *, uint16_t channelid,
+				uint64_t ctx);
+
+/**
+ * qbman_swp_CDAN_enable() - Enable CDAN for the channel.
+ * @s: the software portal object.
+ * @channelid: the index of the channel to generate CDAN.
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
+int qbman_swp_CDAN_enable(struct qbman_swp *, uint16_t channelid);
+
+/**
+ * qbman_swp_CDAN_disable() - disable CDAN for the channel.
+ * @s: the software portal object.
+ * @channelid: the index of the channel to generate CDAN.
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
+int qbman_swp_CDAN_disable(struct qbman_swp *, uint16_t channelid);
+
+/**
+ * qbman_swp_CDAN_set_context_enable() - Set CDAN contest and enable CDAN
+ * @s: the software portal object.
+ * @channelid: the index of the channel to generate CDAN.
+ * @ctx: the context set in CDAN.
+ *
+ * Return 0 for success, or negative error code for failure.
+ */
+int qbman_swp_CDAN_set_context_enable(struct qbman_swp *, uint16_t channelid,
+				      uint64_t ctx);
+
+#endif /* !_FSL_QBMAN_PORTAL_H */
diff --git a/drivers/staging/fsl-mc/bus/dpio/qbman_debug.c b/drivers/staging/fsl-mc/bus/dpio/qbman_debug.c
new file mode 100644
index 0000000..12e33d3
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/qbman_debug.c
@@ -0,0 +1,846 @@
+/* Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "qbman_portal.h"
+#include "qbman_debug.h"
+#include "fsl_qbman_portal.h"
+
+/* QBMan portal management command code */
+#define QBMAN_BP_QUERY            0x32
+#define QBMAN_FQ_QUERY            0x44
+#define QBMAN_FQ_QUERY_NP         0x45
+#define QBMAN_CGR_QUERY           0x51
+#define QBMAN_WRED_QUERY          0x54
+#define QBMAN_CGR_STAT_QUERY      0x55
+#define QBMAN_CGR_STAT_QUERY_CLR  0x56
+
+enum qbman_attr_usage_e {
+	qbman_attr_usage_fq,
+	qbman_attr_usage_bpool,
+	qbman_attr_usage_cgr,
+};
+
+struct int_qbman_attr {
+	uint32_t words[32];
+	enum qbman_attr_usage_e usage;
+};
+
+#define attr_type_set(a, e) \
+{ \
+	struct qbman_attr *__attr = a; \
+	enum qbman_attr_usage_e __usage = e; \
+	((struct int_qbman_attr *)__attr)->usage = __usage; \
+}
+
+#define ATTR32(d) (&(d)->dont_manipulate_directly[0])
+#define ATTR32_1(d) (&(d)->dont_manipulate_directly[16])
+
+static struct qb_attr_code code_bp_bpid = QB_CODE(0, 16, 16);
+static struct qb_attr_code code_bp_bdi = QB_CODE(1, 16, 1);
+static struct qb_attr_code code_bp_va = QB_CODE(1, 17, 1);
+static struct qb_attr_code code_bp_wae = QB_CODE(1, 18, 1);
+static struct qb_attr_code code_bp_swdet = QB_CODE(4, 0, 16);
+static struct qb_attr_code code_bp_swdxt = QB_CODE(4, 16, 16);
+static struct qb_attr_code code_bp_hwdet = QB_CODE(5, 0, 16);
+static struct qb_attr_code code_bp_hwdxt = QB_CODE(5, 16, 16);
+static struct qb_attr_code code_bp_swset = QB_CODE(6, 0, 16);
+static struct qb_attr_code code_bp_swsxt = QB_CODE(6, 16, 16);
+static struct qb_attr_code code_bp_vbpid = QB_CODE(7, 0, 14);
+static struct qb_attr_code code_bp_icid = QB_CODE(7, 16, 15);
+static struct qb_attr_code code_bp_pl = QB_CODE(7, 31, 1);
+static struct qb_attr_code code_bp_bpscn_addr_lo = QB_CODE(8, 0, 32);
+static struct qb_attr_code code_bp_bpscn_addr_hi = QB_CODE(9, 0, 32);
+static struct qb_attr_code code_bp_bpscn_ctx_lo = QB_CODE(10, 0, 32);
+static struct qb_attr_code code_bp_bpscn_ctx_hi = QB_CODE(11, 0, 32);
+static struct qb_attr_code code_bp_hw_targ = QB_CODE(12, 0, 16);
+static struct qb_attr_code code_bp_state = QB_CODE(1, 24, 3);
+static struct qb_attr_code code_bp_fill = QB_CODE(2, 0, 32);
+static struct qb_attr_code code_bp_hdptr = QB_CODE(3, 0, 32);
+static struct qb_attr_code code_bp_sdcnt = QB_CODE(13, 0, 8);
+static struct qb_attr_code code_bp_hdcnt = QB_CODE(13, 1, 8);
+static struct qb_attr_code code_bp_sscnt = QB_CODE(13, 2, 8);
+
+void qbman_bp_attr_clear(struct qbman_attr *a)
+{
+	memset(a, 0, sizeof(*a));
+	attr_type_set(a, qbman_attr_usage_bpool);
+}
+
+int qbman_bp_query(struct qbman_swp *s, uint32_t bpid,
+		   struct qbman_attr *a)
+{
+	uint32_t *p;
+	uint32_t verb, rslt;
+	uint32_t *attr = ATTR32(a);
+
+	qbman_bp_attr_clear(a);
+
+	/* Start the management command */
+	p = qbman_swp_mc_start(s);
+	if (!p)
+		return -EBUSY;
+
+	/* Encode the caller-provided attributes */
+	qb_attr_code_encode(&code_bp_bpid, p, bpid);
+
+	/* Complete the management command */
+	p = qbman_swp_mc_complete(s, p, p[0] | QBMAN_BP_QUERY);
+
+	/* Decode the outcome */
+	verb = qb_attr_code_decode(&code_generic_verb, p);
+	rslt = qb_attr_code_decode(&code_generic_rslt, p);
+	BUG_ON(verb != QBMAN_BP_QUERY);
+
+	/* Determine success or failure */
+	if (unlikely(rslt != QBMAN_MC_RSLT_OK)) {
+		pr_err("Query of BPID 0x%x failed, code=0x%02x\n", bpid, rslt);
+		return -EIO;
+	}
+
+	/* For the query, word[0] of the result contains only the
+	 * verb/rslt fields, so skip word[0].
+	 */
+	word_copy(&attr[1], &p[1], 15);
+	return 0;
+}
+
+void qbman_bp_attr_get_bdi(struct qbman_attr *a, int *bdi, int *va, int *wae)
+{
+	uint32_t *p = ATTR32(a);
+
+	*bdi = !!qb_attr_code_decode(&code_bp_bdi, p);
+	*va = !!qb_attr_code_decode(&code_bp_va, p);
+	*wae = !!qb_attr_code_decode(&code_bp_wae, p);
+}
+
+static uint32_t qbman_bp_thresh_to_value(uint32_t val)
+{
+	return (val & 0xff) << ((val & 0xf00) >> 8);
+}
+
+void qbman_bp_attr_get_swdet(struct qbman_attr *a, uint32_t *swdet)
+{
+	uint32_t *p = ATTR32(a);
+
+	*swdet = qbman_bp_thresh_to_value(qb_attr_code_decode(&code_bp_swdet,
+					  p));
+}
+void qbman_bp_attr_get_swdxt(struct qbman_attr *a, uint32_t *swdxt)
+{
+	uint32_t *p = ATTR32(a);
+
+	*swdxt = qbman_bp_thresh_to_value(qb_attr_code_decode(&code_bp_swdxt,
+					  p));
+}
+void qbman_bp_attr_get_hwdet(struct qbman_attr *a, uint32_t *hwdet)
+{
+	uint32_t *p = ATTR32(a);
+
+	*hwdet = qbman_bp_thresh_to_value(qb_attr_code_decode(&code_bp_hwdet,
+					  p));
+}
+void qbman_bp_attr_get_hwdxt(struct qbman_attr *a, uint32_t *hwdxt)
+{
+	uint32_t *p = ATTR32(a);
+
+	*hwdxt = qbman_bp_thresh_to_value(qb_attr_code_decode(&code_bp_hwdxt,
+					  p));
+}
+
+void qbman_bp_attr_get_swset(struct qbman_attr *a, uint32_t *swset)
+{
+	uint32_t *p = ATTR32(a);
+
+	*swset = qbman_bp_thresh_to_value(qb_attr_code_decode(&code_bp_swset,
+					  p));
+}
+
+void qbman_bp_attr_get_swsxt(struct qbman_attr *a, uint32_t *swsxt)
+{
+	uint32_t *p = ATTR32(a);
+
+	*swsxt = qbman_bp_thresh_to_value(qb_attr_code_decode(&code_bp_swsxt,
+					  p));
+}
+
+void qbman_bp_attr_get_vbpid(struct qbman_attr *a, uint32_t *vbpid)
+{
+	uint32_t *p = ATTR32(a);
+
+	*vbpid = qb_attr_code_decode(&code_bp_vbpid, p);
+}
+
+void qbman_bp_attr_get_icid(struct qbman_attr *a, uint32_t *icid, int *pl)
+{
+	uint32_t *p = ATTR32(a);
+
+	*icid = qb_attr_code_decode(&code_bp_icid, p);
+	*pl = !!qb_attr_code_decode(&code_bp_pl, p);
+}
+
+void qbman_bp_attr_get_bpscn_addr(struct qbman_attr *a, uint64_t *bpscn_addr)
+{
+	uint32_t *p = ATTR32(a);
+
+	*bpscn_addr = ((uint64_t)qb_attr_code_decode(&code_bp_bpscn_addr_hi,
+			p) << 32) |
+			(uint64_t)qb_attr_code_decode(&code_bp_bpscn_addr_lo,
+			p);
+}
+
+void qbman_bp_attr_get_bpscn_ctx(struct qbman_attr *a, uint64_t *bpscn_ctx)
+{
+	uint32_t *p = ATTR32(a);
+
+	*bpscn_ctx = ((uint64_t)qb_attr_code_decode(&code_bp_bpscn_ctx_hi, p)
+			<< 32) |
+			(uint64_t)qb_attr_code_decode(&code_bp_bpscn_ctx_lo,
+			p);
+}
+
+void qbman_bp_attr_get_hw_targ(struct qbman_attr *a, uint32_t *hw_targ)
+{
+	uint32_t *p = ATTR32(a);
+
+	*hw_targ = qb_attr_code_decode(&code_bp_hw_targ, p);
+}
+
+int qbman_bp_info_has_free_bufs(struct qbman_attr *a)
+{
+	uint32_t *p = ATTR32(a);
+
+	return !(int)(qb_attr_code_decode(&code_bp_state, p) & 0x1);
+}
+
+int qbman_bp_info_is_depleted(struct qbman_attr *a)
+{
+	uint32_t *p = ATTR32(a);
+
+	return (int)(qb_attr_code_decode(&code_bp_state, p) & 0x2);
+}
+
+int qbman_bp_info_is_surplus(struct qbman_attr *a)
+{
+	uint32_t *p = ATTR32(a);
+
+	return (int)(qb_attr_code_decode(&code_bp_state, p) & 0x4);
+}
+
+uint32_t qbman_bp_info_num_free_bufs(struct qbman_attr *a)
+{
+	uint32_t *p = ATTR32(a);
+
+	return qb_attr_code_decode(&code_bp_fill, p);
+}
+
+uint32_t qbman_bp_info_hdptr(struct qbman_attr *a)
+{
+	uint32_t *p = ATTR32(a);
+
+	return qb_attr_code_decode(&code_bp_hdptr, p);
+}
+
+uint32_t qbman_bp_info_sdcnt(struct qbman_attr *a)
+{
+	uint32_t *p = ATTR32(a);
+
+	return qb_attr_code_decode(&code_bp_sdcnt, p);
+}
+
+uint32_t qbman_bp_info_hdcnt(struct qbman_attr *a)
+{
+	uint32_t *p = ATTR32(a);
+
+	return qb_attr_code_decode(&code_bp_hdcnt, p);
+}
+
+uint32_t qbman_bp_info_sscnt(struct qbman_attr *a)
+{
+	uint32_t *p = ATTR32(a);
+
+	return qb_attr_code_decode(&code_bp_sscnt, p);
+}
+
+static struct qb_attr_code code_fq_fqid = QB_CODE(1, 0, 24);
+static struct qb_attr_code code_fq_cgrid = QB_CODE(2, 16, 16);
+static struct qb_attr_code code_fq_destwq = QB_CODE(3, 0, 15);
+static struct qb_attr_code code_fq_fqctrl = QB_CODE(3, 24, 8);
+static struct qb_attr_code code_fq_icscred = QB_CODE(4, 0, 15);
+static struct qb_attr_code code_fq_tdthresh = QB_CODE(4, 16, 13);
+static struct qb_attr_code code_fq_oa_len = QB_CODE(5, 0, 12);
+static struct qb_attr_code code_fq_oa_ics = QB_CODE(5, 14, 1);
+static struct qb_attr_code code_fq_oa_cgr = QB_CODE(5, 15, 1);
+static struct qb_attr_code code_fq_mctl_bdi = QB_CODE(5, 24, 1);
+static struct qb_attr_code code_fq_mctl_ff = QB_CODE(5, 25, 1);
+static struct qb_attr_code code_fq_mctl_va = QB_CODE(5, 26, 1);
+static struct qb_attr_code code_fq_mctl_ps = QB_CODE(5, 27, 1);
+static struct qb_attr_code code_fq_ctx_lower32 = QB_CODE(6, 0, 32);
+static struct qb_attr_code code_fq_ctx_upper32 = QB_CODE(7, 0, 32);
+static struct qb_attr_code code_fq_icid = QB_CODE(8, 0, 15);
+static struct qb_attr_code code_fq_pl = QB_CODE(8, 15, 1);
+static struct qb_attr_code code_fq_vfqid = QB_CODE(9, 0, 24);
+static struct qb_attr_code code_fq_erfqid = QB_CODE(10, 0, 24);
+
+void qbman_fq_attr_clear(struct qbman_attr *a)
+{
+	memset(a, 0, sizeof(*a));
+	attr_type_set(a, qbman_attr_usage_fq);
+}
+
+/* FQ query function for programmable fields */
+int qbman_fq_query(struct qbman_swp *s, uint32_t fqid, struct qbman_attr *desc)
+{
+	uint32_t *p;
+	uint32_t verb, rslt;
+	uint32_t *d = ATTR32(desc);
+
+	qbman_fq_attr_clear(desc);
+
+	p = qbman_swp_mc_start(s);
+	if (!p)
+		return -EBUSY;
+	qb_attr_code_encode(&code_fq_fqid, p, fqid);
+	p = qbman_swp_mc_complete(s, p, QBMAN_FQ_QUERY);
+
+	/* Decode the outcome */
+	verb = qb_attr_code_decode(&code_generic_verb, p);
+	rslt = qb_attr_code_decode(&code_generic_rslt, p);
+	BUG_ON(verb != QBMAN_FQ_QUERY);
+
+	/* Determine success or failure */
+	if (unlikely(rslt != QBMAN_MC_RSLT_OK)) {
+		pr_err("Query of FQID 0x%x failed, code=0x%02x\n",
+		       fqid, rslt);
+		return -EIO;
+	}
+	/* For the configure, word[0] of the command contains only the WE-mask.
+	 * For the query, word[0] of the result contains only the verb/rslt
+	 * fields. Skip word[0] in the latter case. */
+	word_copy(&d[1], &p[1], 15);
+	return 0;
+}
+
+void qbman_fq_attr_get_fqctrl(struct qbman_attr *d, uint32_t *fqctrl)
+{
+	uint32_t *p = ATTR32(d);
+
+	*fqctrl = qb_attr_code_decode(&code_fq_fqctrl, p);
+}
+
+void qbman_fq_attr_get_cgrid(struct qbman_attr *d, uint32_t *cgrid)
+{
+	uint32_t *p = ATTR32(d);
+
+	*cgrid = qb_attr_code_decode(&code_fq_cgrid, p);
+}
+
+void qbman_fq_attr_get_destwq(struct qbman_attr *d, uint32_t *destwq)
+{
+	uint32_t *p = ATTR32(d);
+
+	*destwq = qb_attr_code_decode(&code_fq_destwq, p);
+}
+
+void qbman_fq_attr_get_icscred(struct qbman_attr *d, uint32_t *icscred)
+{
+	uint32_t *p = ATTR32(d);
+
+	*icscred = qb_attr_code_decode(&code_fq_icscred, p);
+}
+
+static struct qb_attr_code code_tdthresh_exp = QB_CODE(0, 0, 5);
+static struct qb_attr_code code_tdthresh_mant = QB_CODE(0, 5, 8);
+static uint32_t qbman_thresh_to_value(uint32_t val)
+{
+	uint32_t m, e;
+
+	m = qb_attr_code_decode(&code_tdthresh_mant, &val);
+	e = qb_attr_code_decode(&code_tdthresh_exp, &val);
+	return m << e;
+}
+
+void qbman_fq_attr_get_tdthresh(struct qbman_attr *d, uint32_t *tdthresh)
+{
+	uint32_t *p = ATTR32(d);
+
+	*tdthresh = qbman_thresh_to_value(qb_attr_code_decode(&code_fq_tdthresh,
+					p));
+}
+
+void qbman_fq_attr_get_oa(struct qbman_attr *d,
+			  int *oa_ics, int *oa_cgr, int32_t *oa_len)
+{
+	uint32_t *p = ATTR32(d);
+
+	*oa_ics = !!qb_attr_code_decode(&code_fq_oa_ics, p);
+	*oa_cgr = !!qb_attr_code_decode(&code_fq_oa_cgr, p);
+	*oa_len = qb_attr_code_makesigned(&code_fq_oa_len,
+			qb_attr_code_decode(&code_fq_oa_len, p));
+}
+
+void qbman_fq_attr_get_mctl(struct qbman_attr *d,
+			    int *bdi, int *ff, int *va, int *ps)
+{
+	uint32_t *p = ATTR32(d);
+
+	*bdi = !!qb_attr_code_decode(&code_fq_mctl_bdi, p);
+	*ff = !!qb_attr_code_decode(&code_fq_mctl_ff, p);
+	*va = !!qb_attr_code_decode(&code_fq_mctl_va, p);
+	*ps = !!qb_attr_code_decode(&code_fq_mctl_ps, p);
+}
+
+void qbman_fq_attr_get_ctx(struct qbman_attr *d, uint32_t *hi, uint32_t *lo)
+{
+	uint32_t *p = ATTR32(d);
+
+	*hi = qb_attr_code_decode(&code_fq_ctx_upper32, p);
+	*lo = qb_attr_code_decode(&code_fq_ctx_lower32, p);
+}
+
+void qbman_fq_attr_get_icid(struct qbman_attr *d, uint32_t *icid, int *pl)
+{
+	uint32_t *p = ATTR32(d);
+
+	*icid = qb_attr_code_decode(&code_fq_icid, p);
+	*pl = !!qb_attr_code_decode(&code_fq_pl, p);
+}
+
+void qbman_fq_attr_get_vfqid(struct qbman_attr *d, uint32_t *vfqid)
+{
+	uint32_t *p = ATTR32(d);
+
+	*vfqid = qb_attr_code_decode(&code_fq_vfqid, p);
+}
+
+void qbman_fq_attr_get_erfqid(struct qbman_attr *d, uint32_t *erfqid)
+{
+	uint32_t *p = ATTR32(d);
+
+	*erfqid = qb_attr_code_decode(&code_fq_erfqid, p);
+}
+
+/* Query FQ Non-Programmalbe Fields */
+static struct qb_attr_code code_fq_np_state = QB_CODE(0, 16, 3);
+static struct qb_attr_code code_fq_np_fe = QB_CODE(0, 19, 1);
+static struct qb_attr_code code_fq_np_x = QB_CODE(0, 20, 1);
+static struct qb_attr_code code_fq_np_r = QB_CODE(0, 21, 1);
+static struct qb_attr_code code_fq_np_oe = QB_CODE(0, 22, 1);
+static struct qb_attr_code code_fq_np_frm_cnt = QB_CODE(6, 0, 24);
+static struct qb_attr_code code_fq_np_byte_cnt = QB_CODE(7, 0, 32);
+
+int qbman_fq_query_state(struct qbman_swp *s, uint32_t fqid,
+			 struct qbman_attr *state)
+{
+	uint32_t *p;
+	uint32_t verb, rslt;
+	uint32_t *d = ATTR32(state);
+
+	qbman_fq_attr_clear(state);
+
+	p = qbman_swp_mc_start(s);
+	if (!p)
+		return -EBUSY;
+	qb_attr_code_encode(&code_fq_fqid, p, fqid);
+	p = qbman_swp_mc_complete(s, p, QBMAN_FQ_QUERY_NP);
+
+	/* Decode the outcome */
+	verb = qb_attr_code_decode(&code_generic_verb, p);
+	rslt = qb_attr_code_decode(&code_generic_rslt, p);
+	BUG_ON(verb != QBMAN_FQ_QUERY_NP);
+
+	/* Determine success or failure */
+	if (unlikely(rslt != QBMAN_MC_RSLT_OK)) {
+		pr_err("Query NP fields of FQID 0x%x failed, code=0x%02x\n",
+		       fqid, rslt);
+		return -EIO;
+	}
+	word_copy(&d[0], &p[0], 16);
+	return 0;
+}
+
+uint32_t qbman_fq_state_schedstate(const struct qbman_attr *state)
+{
+	const uint32_t *p = ATTR32(state);
+
+	return qb_attr_code_decode(&code_fq_np_state, p);
+}
+
+int qbman_fq_state_force_eligible(const struct qbman_attr *state)
+{
+	const uint32_t *p = ATTR32(state);
+
+	return !!qb_attr_code_decode(&code_fq_np_fe, p);
+}
+
+int qbman_fq_state_xoff(const struct qbman_attr *state)
+{
+	const uint32_t *p = ATTR32(state);
+
+	return !!qb_attr_code_decode(&code_fq_np_x, p);
+}
+
+int qbman_fq_state_retirement_pending(const struct qbman_attr *state)
+{
+	const uint32_t *p = ATTR32(state);
+
+	return !!qb_attr_code_decode(&code_fq_np_r, p);
+}
+
+int qbman_fq_state_overflow_error(const struct qbman_attr *state)
+{
+	const uint32_t *p = ATTR32(state);
+
+	return !!qb_attr_code_decode(&code_fq_np_oe, p);
+}
+
+uint32_t qbman_fq_state_frame_count(const struct qbman_attr *state)
+{
+	const uint32_t *p = ATTR32(state);
+
+	return qb_attr_code_decode(&code_fq_np_frm_cnt, p);
+}
+
+uint32_t qbman_fq_state_byte_count(const struct qbman_attr *state)
+{
+	const uint32_t *p = ATTR32(state);
+
+	return qb_attr_code_decode(&code_fq_np_byte_cnt, p);
+}
+
+/* Query CGR */
+static struct qb_attr_code code_cgr_cgid = QB_CODE(0, 16, 16);
+static struct qb_attr_code code_cgr_cscn_wq_en_enter = QB_CODE(2, 0, 1);
+static struct qb_attr_code code_cgr_cscn_wq_en_exit = QB_CODE(2, 1, 1);
+static struct qb_attr_code code_cgr_cscn_wq_icd = QB_CODE(2, 2, 1);
+static struct qb_attr_code code_cgr_mode = QB_CODE(3, 16, 2);
+static struct qb_attr_code code_cgr_rej_cnt_mode = QB_CODE(3, 18, 1);
+static struct qb_attr_code code_cgr_cscn_bdi = QB_CODE(3, 19, 1);
+static struct qb_attr_code code_cgr_cscn_wr_en_enter = QB_CODE(3, 24, 1);
+static struct qb_attr_code code_cgr_cscn_wr_en_exit = QB_CODE(3, 25, 1);
+static struct qb_attr_code code_cgr_cg_wr_ae = QB_CODE(3, 26, 1);
+static struct qb_attr_code code_cgr_cscn_dcp_en = QB_CODE(3, 27, 1);
+static struct qb_attr_code code_cgr_cg_wr_va = QB_CODE(3, 28, 1);
+static struct qb_attr_code code_cgr_i_cnt_wr_en = QB_CODE(4, 0, 1);
+static struct qb_attr_code code_cgr_i_cnt_wr_bnd = QB_CODE(4, 1, 5);
+static struct qb_attr_code code_cgr_td_en = QB_CODE(4, 8, 1);
+static struct qb_attr_code code_cgr_cs_thres = QB_CODE(4, 16, 13);
+static struct qb_attr_code code_cgr_cs_thres_x = QB_CODE(5, 0, 13);
+static struct qb_attr_code code_cgr_td_thres = QB_CODE(5, 16, 13);
+static struct qb_attr_code code_cgr_cscn_tdcp = QB_CODE(6, 0, 16);
+static struct qb_attr_code code_cgr_cscn_wqid = QB_CODE(6, 16, 16);
+static struct qb_attr_code code_cgr_cscn_vcgid = QB_CODE(7, 0, 16);
+static struct qb_attr_code code_cgr_cg_icid = QB_CODE(7, 16, 15);
+static struct qb_attr_code code_cgr_cg_pl = QB_CODE(7, 31, 1);
+static struct qb_attr_code code_cgr_cg_wr_addr_lo = QB_CODE(8, 0, 32);
+static struct qb_attr_code code_cgr_cg_wr_addr_hi = QB_CODE(9, 0, 32);
+static struct qb_attr_code code_cgr_cscn_ctx_lo = QB_CODE(10, 0, 32);
+static struct qb_attr_code code_cgr_cscn_ctx_hi = QB_CODE(11, 0, 32);
+
+void qbman_cgr_attr_clear(struct qbman_attr *a)
+{
+	memset(a, 0, sizeof(*a));
+	attr_type_set(a, qbman_attr_usage_cgr);
+}
+
+int qbman_cgr_query(struct qbman_swp *s, uint32_t cgid, struct qbman_attr *attr)
+{
+	uint32_t *p;
+	uint32_t verb, rslt;
+	uint32_t *d[2];
+	int i;
+	uint32_t query_verb;
+
+	d[0] = ATTR32(attr);
+	d[1] = ATTR32_1(attr);
+
+	qbman_cgr_attr_clear(attr);
+
+	for (i = 0; i < 2; i++) {
+		p = qbman_swp_mc_start(s);
+		if (!p)
+			return -EBUSY;
+		query_verb = i ? QBMAN_WRED_QUERY : QBMAN_CGR_QUERY;
+
+		qb_attr_code_encode(&code_cgr_cgid, p, cgid);
+		p = qbman_swp_mc_complete(s, p, p[0] | query_verb);
+
+		/* Decode the outcome */
+		verb = qb_attr_code_decode(&code_generic_verb, p);
+		rslt = qb_attr_code_decode(&code_generic_rslt, p);
+		BUG_ON(verb != query_verb);
+
+		/* Determine success or failure */
+		if (unlikely(rslt != QBMAN_MC_RSLT_OK)) {
+			pr_err("Query CGID 0x%x failed,", cgid);
+			pr_err(" verb=0x%02x, code=0x%02x\n", verb, rslt);
+			return -EIO;
+		}
+		/* For the configure, word[0] of the command contains only the
+		 * verb/cgid. For the query, word[0] of the result contains
+		 * only the verb/rslt fields. Skip word[0] in the latter case.
+		 */
+		word_copy(&d[i][1], &p[1], 15);
+	}
+	return 0;
+}
+
+void qbman_cgr_attr_get_ctl1(struct qbman_attr *d, int *cscn_wq_en_enter,
+			     int *cscn_wq_en_exit, int *cscn_wq_icd)
+	{
+	uint32_t *p = ATTR32(d);
+	*cscn_wq_en_enter = !!qb_attr_code_decode(&code_cgr_cscn_wq_en_enter,
+									 p);
+	*cscn_wq_en_exit = !!qb_attr_code_decode(&code_cgr_cscn_wq_en_exit, p);
+	*cscn_wq_icd = !!qb_attr_code_decode(&code_cgr_cscn_wq_icd, p);
+}
+
+void qbman_cgr_attr_get_mode(struct qbman_attr *d, uint32_t *mode,
+			     int *rej_cnt_mode, int *cscn_bdi)
+{
+	uint32_t *p = ATTR32(d);
+	*mode = qb_attr_code_decode(&code_cgr_mode, p);
+	*rej_cnt_mode = !!qb_attr_code_decode(&code_cgr_rej_cnt_mode, p);
+	*cscn_bdi = !!qb_attr_code_decode(&code_cgr_cscn_bdi, p);
+}
+
+void qbman_cgr_attr_get_ctl2(struct qbman_attr *d, int *cscn_wr_en_enter,
+			     int *cscn_wr_en_exit, int *cg_wr_ae,
+			     int *cscn_dcp_en, int *cg_wr_va)
+{
+	uint32_t *p = ATTR32(d);
+	*cscn_wr_en_enter = !!qb_attr_code_decode(&code_cgr_cscn_wr_en_enter,
+									p);
+	*cscn_wr_en_exit = !!qb_attr_code_decode(&code_cgr_cscn_wr_en_exit, p);
+	*cg_wr_ae = !!qb_attr_code_decode(&code_cgr_cg_wr_ae, p);
+	*cscn_dcp_en = !!qb_attr_code_decode(&code_cgr_cscn_dcp_en, p);
+	*cg_wr_va = !!qb_attr_code_decode(&code_cgr_cg_wr_va, p);
+}
+
+void qbman_cgr_attr_get_iwc(struct qbman_attr *d, int *i_cnt_wr_en,
+			    uint32_t *i_cnt_wr_bnd)
+{
+	uint32_t *p = ATTR32(d);
+	*i_cnt_wr_en = !!qb_attr_code_decode(&code_cgr_i_cnt_wr_en, p);
+	*i_cnt_wr_bnd = qb_attr_code_decode(&code_cgr_i_cnt_wr_bnd, p);
+}
+
+void qbman_cgr_attr_get_tdc(struct qbman_attr *d, int *td_en)
+{
+	uint32_t *p = ATTR32(d);
+	*td_en = !!qb_attr_code_decode(&code_cgr_td_en, p);
+}
+
+void qbman_cgr_attr_get_cs_thres(struct qbman_attr *d, uint32_t *cs_thres)
+{
+	uint32_t *p = ATTR32(d);
+	*cs_thres = qbman_thresh_to_value(qb_attr_code_decode(
+						&code_cgr_cs_thres, p));
+}
+
+void qbman_cgr_attr_get_cs_thres_x(struct qbman_attr *d,
+				   uint32_t *cs_thres_x)
+{
+	uint32_t *p = ATTR32(d);
+	*cs_thres_x = qbman_thresh_to_value(qb_attr_code_decode(
+					    &code_cgr_cs_thres_x, p));
+}
+
+void qbman_cgr_attr_get_td_thres(struct qbman_attr *d, uint32_t *td_thres)
+{
+	uint32_t *p = ATTR32(d);
+	*td_thres = qbman_thresh_to_value(qb_attr_code_decode(
+					  &code_cgr_td_thres, p));
+}
+
+void qbman_cgr_attr_get_cscn_tdcp(struct qbman_attr *d, uint32_t *cscn_tdcp)
+{
+	uint32_t *p = ATTR32(d);
+	*cscn_tdcp = qb_attr_code_decode(&code_cgr_cscn_tdcp, p);
+}
+
+void qbman_cgr_attr_get_cscn_wqid(struct qbman_attr *d, uint32_t *cscn_wqid)
+{
+	uint32_t *p = ATTR32(d);
+	*cscn_wqid = qb_attr_code_decode(&code_cgr_cscn_wqid, p);
+}
+
+void qbman_cgr_attr_get_cscn_vcgid(struct qbman_attr *d,
+				   uint32_t *cscn_vcgid)
+{
+	uint32_t *p = ATTR32(d);
+	*cscn_vcgid = qb_attr_code_decode(&code_cgr_cscn_vcgid, p);
+}
+
+void qbman_cgr_attr_get_cg_icid(struct qbman_attr *d, uint32_t *icid,
+				int *pl)
+{
+	uint32_t *p = ATTR32(d);
+	*icid = qb_attr_code_decode(&code_cgr_cg_icid, p);
+	*pl = !!qb_attr_code_decode(&code_cgr_cg_pl, p);
+}
+
+void qbman_cgr_attr_get_cg_wr_addr(struct qbman_attr *d,
+				   uint64_t *cg_wr_addr)
+{
+	uint32_t *p = ATTR32(d);
+	*cg_wr_addr = ((uint64_t)qb_attr_code_decode(&code_cgr_cg_wr_addr_hi,
+			p) << 32) |
+			(uint64_t)qb_attr_code_decode(&code_cgr_cg_wr_addr_lo,
+			p);
+}
+
+void qbman_cgr_attr_get_cscn_ctx(struct qbman_attr *d, uint64_t *cscn_ctx)
+{
+	uint32_t *p = ATTR32(d);
+	*cscn_ctx = ((uint64_t)qb_attr_code_decode(&code_cgr_cscn_ctx_hi, p)
+			<< 32) |
+			(uint64_t)qb_attr_code_decode(&code_cgr_cscn_ctx_lo, p);
+}
+
+#define WRED_EDP_WORD(n) (18 + n/4)
+#define WRED_EDP_OFFSET(n) (8 * (n % 4))
+#define WRED_PARM_DP_WORD(n) (n + 20)
+#define WRED_WE_EDP(n) (16 + n * 2)
+#define WRED_WE_PARM_DP(n) (17 + n * 2)
+void qbman_cgr_attr_wred_get_edp(struct qbman_attr *d, uint32_t idx,
+				 int *edp)
+{
+	uint32_t *p = ATTR32(d);
+	struct qb_attr_code code_wred_edp = QB_CODE(WRED_EDP_WORD(idx),
+						WRED_EDP_OFFSET(idx), 8);
+	*edp = (int)qb_attr_code_decode(&code_wred_edp, p);
+}
+
+void qbman_cgr_attr_wred_dp_decompose(uint32_t dp, uint64_t *minth,
+				      uint64_t *maxth, uint8_t *maxp)
+{
+	uint8_t ma, mn, step_i, step_s, pn;
+
+	ma = (uint8_t)(dp >> 24);
+	mn = (uint8_t)(dp >> 19) & 0x1f;
+	step_i = (uint8_t)(dp >> 11);
+	step_s = (uint8_t)(dp >> 6) & 0x1f;
+	pn = (uint8_t)dp & 0x3f;
+
+	*maxp = ((pn<<2) * 100)/256;
+
+	if (mn == 0)
+		*maxth = ma;
+	else
+		*maxth = ((ma+256) * (1<<(mn-1)));
+
+	if (step_s == 0)
+		*minth = *maxth - step_i;
+	else
+		*minth = *maxth - (256 + step_i) * (1<<(step_s - 1));
+}
+
+void qbman_cgr_attr_wred_get_parm_dp(struct qbman_attr *d, uint32_t idx,
+				     uint32_t *dp)
+{
+	uint32_t *p = ATTR32(d);
+	struct qb_attr_code code_wred_parm_dp = QB_CODE(WRED_PARM_DP_WORD(idx),
+						0, 8);
+	*dp = qb_attr_code_decode(&code_wred_parm_dp, p);
+}
+
+/* Query CGR/CCGR/CQ statistics */
+static struct qb_attr_code code_cgr_stat_ct = QB_CODE(4, 0, 32);
+static struct qb_attr_code code_cgr_stat_frame_cnt_lo = QB_CODE(4, 0, 32);
+static struct qb_attr_code code_cgr_stat_frame_cnt_hi = QB_CODE(5, 0, 8);
+static struct qb_attr_code code_cgr_stat_byte_cnt_lo = QB_CODE(6, 0, 32);
+static struct qb_attr_code code_cgr_stat_byte_cnt_hi = QB_CODE(7, 0, 16);
+static int qbman_cgr_statistics_query(struct qbman_swp *s, uint32_t cgid,
+				      int clear, uint32_t command_type,
+				      uint64_t *frame_cnt, uint64_t *byte_cnt)
+{
+	uint32_t *p;
+	uint32_t verb, rslt;
+	uint32_t query_verb;
+	uint32_t hi, lo;
+
+	p = qbman_swp_mc_start(s);
+	if (!p)
+		return -EBUSY;
+
+	qb_attr_code_encode(&code_cgr_cgid, p, cgid);
+	if (command_type < 2)
+		qb_attr_code_encode(&code_cgr_stat_ct, p, command_type);
+	query_verb = clear ?
+			QBMAN_CGR_STAT_QUERY_CLR : QBMAN_CGR_STAT_QUERY;
+	p = qbman_swp_mc_complete(s, p, p[0] | query_verb);
+
+	/* Decode the outcome */
+	verb = qb_attr_code_decode(&code_generic_verb, p);
+	rslt = qb_attr_code_decode(&code_generic_rslt, p);
+	BUG_ON(verb != query_verb);
+
+	/* Determine success or failure */
+	if (unlikely(rslt != QBMAN_MC_RSLT_OK)) {
+		pr_err("Query statistics of CGID 0x%x failed,", cgid);
+		pr_err(" verb=0x%02x code=0x%02x\n", verb, rslt);
+		return -EIO;
+	}
+
+	if (*frame_cnt) {
+		hi = qb_attr_code_decode(&code_cgr_stat_frame_cnt_hi, p);
+		lo = qb_attr_code_decode(&code_cgr_stat_frame_cnt_lo, p);
+		*frame_cnt = ((uint64_t)hi << 32) | (uint64_t)lo;
+	}
+	if (*byte_cnt) {
+		hi = qb_attr_code_decode(&code_cgr_stat_byte_cnt_hi, p);
+		lo = qb_attr_code_decode(&code_cgr_stat_byte_cnt_lo, p);
+		*byte_cnt = ((uint64_t)hi << 32) | (uint64_t)lo;
+	}
+
+	return 0;
+}
+
+int qbman_cgr_reject_statistics(struct qbman_swp *s, uint32_t cgid, int clear,
+				uint64_t *frame_cnt, uint64_t *byte_cnt)
+{
+	return qbman_cgr_statistics_query(s, cgid, clear, 0xff,
+					  frame_cnt, byte_cnt);
+}
+
+int qbman_ccgr_reject_statistics(struct qbman_swp *s, uint32_t cgid, int clear,
+				 uint64_t *frame_cnt, uint64_t *byte_cnt)
+{
+	return qbman_cgr_statistics_query(s, cgid, clear, 1,
+					  frame_cnt, byte_cnt);
+}
+
+int qbman_cq_dequeue_statistics(struct qbman_swp *s, uint32_t cgid, int clear,
+				uint64_t *frame_cnt, uint64_t *byte_cnt)
+{
+	return qbman_cgr_statistics_query(s, cgid, clear, 0,
+					  frame_cnt, byte_cnt);
+}
diff --git a/drivers/staging/fsl-mc/bus/dpio/qbman_debug.h b/drivers/staging/fsl-mc/bus/dpio/qbman_debug.h
new file mode 100644
index 0000000..1e6b002
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/qbman_debug.h
@@ -0,0 +1,136 @@
+/* Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+struct qbman_attr {
+	uint32_t dont_manipulate_directly[40];
+};
+
+/* Buffer pool query commands */
+int qbman_bp_query(struct qbman_swp *s, uint32_t bpid,
+		   struct qbman_attr *a);
+void qbman_bp_attr_get_bdi(struct qbman_attr *a, int *bdi, int *va, int *wae);
+void qbman_bp_attr_get_swdet(struct qbman_attr *a, uint32_t *swdet);
+void qbman_bp_attr_get_swdxt(struct qbman_attr *a, uint32_t *swdxt);
+void qbman_bp_attr_get_hwdet(struct qbman_attr *a, uint32_t *hwdet);
+void qbman_bp_attr_get_hwdxt(struct qbman_attr *a, uint32_t *hwdxt);
+void qbman_bp_attr_get_swset(struct qbman_attr *a, uint32_t *swset);
+void qbman_bp_attr_get_swsxt(struct qbman_attr *a, uint32_t *swsxt);
+void qbman_bp_attr_get_vbpid(struct qbman_attr *a, uint32_t *vbpid);
+void qbman_bp_attr_get_icid(struct qbman_attr *a, uint32_t *icid, int *pl);
+void qbman_bp_attr_get_bpscn_addr(struct qbman_attr *a, uint64_t *bpscn_addr);
+void qbman_bp_attr_get_bpscn_ctx(struct qbman_attr *a, uint64_t *bpscn_ctx);
+void qbman_bp_attr_get_hw_targ(struct qbman_attr *a, uint32_t *hw_targ);
+int qbman_bp_info_has_free_bufs(struct qbman_attr *a);
+int qbman_bp_info_is_depleted(struct qbman_attr *a);
+int qbman_bp_info_is_surplus(struct qbman_attr *a);
+uint32_t qbman_bp_info_num_free_bufs(struct qbman_attr *a);
+uint32_t qbman_bp_info_hdptr(struct qbman_attr *a);
+uint32_t qbman_bp_info_sdcnt(struct qbman_attr *a);
+uint32_t qbman_bp_info_hdcnt(struct qbman_attr *a);
+uint32_t qbman_bp_info_sscnt(struct qbman_attr *a);
+
+/* FQ query function for programmable fields */
+int qbman_fq_query(struct qbman_swp *s, uint32_t fqid,
+		   struct qbman_attr *desc);
+void qbman_fq_attr_get_fqctrl(struct qbman_attr *d, uint32_t *fqctrl);
+void qbman_fq_attr_get_cgrid(struct qbman_attr *d, uint32_t *cgrid);
+void qbman_fq_attr_get_destwq(struct qbman_attr *d, uint32_t *destwq);
+void qbman_fq_attr_get_icscred(struct qbman_attr *d, uint32_t *icscred);
+void qbman_fq_attr_get_tdthresh(struct qbman_attr *d, uint32_t *tdthresh);
+void qbman_fq_attr_get_oa(struct qbman_attr *d,
+			  int *oa_ics, int *oa_cgr, int32_t *oa_len);
+void qbman_fq_attr_get_mctl(struct qbman_attr *d,
+			    int *bdi, int *ff, int *va, int *ps);
+void qbman_fq_attr_get_ctx(struct qbman_attr *d, uint32_t *hi, uint32_t *lo);
+void qbman_fq_attr_get_icid(struct qbman_attr *d, uint32_t *icid, int *pl);
+void qbman_fq_attr_get_vfqid(struct qbman_attr *d, uint32_t *vfqid);
+void qbman_fq_attr_get_erfqid(struct qbman_attr *d, uint32_t *erfqid);
+
+/* FQ query command for non-programmable fields*/
+enum qbman_fq_schedstate_e {
+	qbman_fq_schedstate_oos = 0,
+	qbman_fq_schedstate_retired,
+	qbman_fq_schedstate_tentatively_scheduled,
+	qbman_fq_schedstate_truly_scheduled,
+	qbman_fq_schedstate_parked,
+	qbman_fq_schedstate_held_active,
+};
+
+int qbman_fq_query_state(struct qbman_swp *s, uint32_t fqid,
+			 struct qbman_attr *state);
+uint32_t qbman_fq_state_schedstate(const struct qbman_attr *state);
+int qbman_fq_state_force_eligible(const struct qbman_attr *state);
+int qbman_fq_state_xoff(const struct qbman_attr *state);
+int qbman_fq_state_retirement_pending(const struct qbman_attr *state);
+int qbman_fq_state_overflow_error(const struct qbman_attr *state);
+uint32_t qbman_fq_state_frame_count(const struct qbman_attr *state);
+uint32_t qbman_fq_state_byte_count(const struct qbman_attr *state);
+
+/* CGR query */
+int qbman_cgr_query(struct qbman_swp *s, uint32_t cgid,
+		    struct qbman_attr *attr);
+void qbman_cgr_attr_get_ctl1(struct qbman_attr *d, int *cscn_wq_en_enter,
+			     int *cscn_wq_en_exit, int *cscn_wq_icd);
+void qbman_cgr_attr_get_mode(struct qbman_attr *d, uint32_t *mode,
+			     int *rej_cnt_mode, int *cscn_bdi);
+void qbman_cgr_attr_get_ctl2(struct qbman_attr *d, int *cscn_wr_en_enter,
+			     int *cscn_wr_en_exit, int *cg_wr_ae,
+			     int *cscn_dcp_en, int *cg_wr_va);
+void qbman_cgr_attr_get_iwc(struct qbman_attr *d, int *i_cnt_wr_en,
+			    uint32_t *i_cnt_wr_bnd);
+void qbman_cgr_attr_get_tdc(struct qbman_attr *d, int *td_en);
+void qbman_cgr_attr_get_cs_thres(struct qbman_attr *d, uint32_t *cs_thres);
+void qbman_cgr_attr_get_cs_thres_x(struct qbman_attr *d,
+				   uint32_t *cs_thres_x);
+void qbman_cgr_attr_get_td_thres(struct qbman_attr *d, uint32_t *td_thres);
+void qbman_cgr_attr_get_cscn_tdcp(struct qbman_attr *d, uint32_t *cscn_tdcp);
+void qbman_cgr_attr_get_cscn_wqid(struct qbman_attr *d, uint32_t *cscn_wqid);
+void qbman_cgr_attr_get_cscn_vcgid(struct qbman_attr *d,
+				   uint32_t *cscn_vcgid);
+void qbman_cgr_attr_get_cg_icid(struct qbman_attr *d, uint32_t *icid,
+				int *pl);
+void qbman_cgr_attr_get_cg_wr_addr(struct qbman_attr *d,
+				   uint64_t *cg_wr_addr);
+void qbman_cgr_attr_get_cscn_ctx(struct qbman_attr *d, uint64_t *cscn_ctx);
+void qbman_cgr_attr_wred_get_edp(struct qbman_attr *d, uint32_t idx,
+				 int *edp);
+void qbman_cgr_attr_wred_dp_decompose(uint32_t dp, uint64_t *minth,
+				      uint64_t *maxth, uint8_t *maxp);
+void qbman_cgr_attr_wred_get_parm_dp(struct qbman_attr *d, uint32_t idx,
+				     uint32_t *dp);
+
+/* CGR/CCGR/CQ statistics query */
+int qbman_cgr_reject_statistics(struct qbman_swp *s, uint32_t cgid, int clear,
+				uint64_t *frame_cnt, uint64_t *byte_cnt);
+int qbman_ccgr_reject_statistics(struct qbman_swp *s, uint32_t cgid, int clear,
+				 uint64_t *frame_cnt, uint64_t *byte_cnt);
+int qbman_cq_dequeue_statistics(struct qbman_swp *s, uint32_t cgid, int clear,
+				uint64_t *frame_cnt, uint64_t *byte_cnt);
diff --git a/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c b/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c
new file mode 100644
index 0000000..e77bbd2
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/qbman_portal.c
@@ -0,0 +1,1218 @@
+/* Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "qbman_portal.h"
+
+/* QBMan portal management command codes */
+#define QBMAN_MC_ACQUIRE       0x30
+#define QBMAN_WQCHAN_CONFIGURE 0x46
+
+/* CINH register offsets */
+#define QBMAN_CINH_SWP_EQAR    0x8c0
+#define QBMAN_CINH_SWP_DQPI    0xa00
+#define QBMAN_CINH_SWP_DCAP    0xac0
+#define QBMAN_CINH_SWP_SDQCR   0xb00
+#define QBMAN_CINH_SWP_RAR     0xcc0
+#define QBMAN_CINH_SWP_ISR     0xe00
+#define QBMAN_CINH_SWP_IER     0xe40
+#define QBMAN_CINH_SWP_ISDR    0xe80
+#define QBMAN_CINH_SWP_IIR     0xec0
+
+/* CENA register offsets */
+#define QBMAN_CENA_SWP_EQCR(n) (0x000 + ((uint32_t)(n) << 6))
+#define QBMAN_CENA_SWP_DQRR(n) (0x200 + ((uint32_t)(n) << 6))
+#define QBMAN_CENA_SWP_RCR(n)  (0x400 + ((uint32_t)(n) << 6))
+#define QBMAN_CENA_SWP_CR      0x600
+#define QBMAN_CENA_SWP_RR(vb)  (0x700 + ((uint32_t)(vb) >> 1))
+#define QBMAN_CENA_SWP_VDQCR   0x780
+
+/* Reverse mapping of QBMAN_CENA_SWP_DQRR() */
+#define QBMAN_IDX_FROM_DQRR(p) (((unsigned long)p & 0x1ff) >> 6)
+
+/* QBMan FQ management command codes */
+#define QBMAN_FQ_SCHEDULE	0x48
+#define QBMAN_FQ_FORCE		0x49
+#define QBMAN_FQ_XON		0x4d
+#define QBMAN_FQ_XOFF		0x4e
+
+/*******************************/
+/* Pre-defined attribute codes */
+/*******************************/
+
+struct qb_attr_code code_generic_verb = QB_CODE(0, 0, 7);
+struct qb_attr_code code_generic_rslt = QB_CODE(0, 8, 8);
+
+/*************************/
+/* SDQCR attribute codes */
+/*************************/
+
+/* we put these here because at least some of them are required by
+ * qbman_swp_init() */
+struct qb_attr_code code_sdqcr_dct = QB_CODE(0, 24, 2);
+struct qb_attr_code code_sdqcr_fc = QB_CODE(0, 29, 1);
+struct qb_attr_code code_sdqcr_tok = QB_CODE(0, 16, 8);
+static struct qb_attr_code code_eq_dca_idx;
+#define CODE_SDQCR_DQSRC(n) QB_CODE(0, n, 1)
+enum qbman_sdqcr_dct {
+	qbman_sdqcr_dct_null = 0,
+	qbman_sdqcr_dct_prio_ics,
+	qbman_sdqcr_dct_active_ics,
+	qbman_sdqcr_dct_active
+};
+enum qbman_sdqcr_fc {
+	qbman_sdqcr_fc_one = 0,
+	qbman_sdqcr_fc_up_to_3 = 1
+};
+struct qb_attr_code code_sdqcr_dqsrc = QB_CODE(0, 0, 16);
+
+/*********************************/
+/* Portal constructor/destructor */
+/*********************************/
+
+/* Software portals should always be in the power-on state when we initialise,
+ * due to the CCSR-based portal reset functionality that MC has.
+ *
+ * Erk! Turns out that QMan versions prior to 4.1 do not correctly reset DQRR
+ * valid-bits, so we need to support a workaround where we don't trust
+ * valid-bits when detecting new entries until any stale ring entries have been
+ * overwritten at least once. The idea is that we read PI for the first few
+ * entries, then switch to valid-bit after that. The trick is to clear the
+ * bug-work-around boolean once the PI wraps around the ring for the first time.
+ *
+ * Note: this still carries a slight additional cost once the decrementer hits
+ * zero, so ideally the workaround should only be compiled in if the compiled
+ * image needs to support affected chips. We use WORKAROUND_DQRR_RESET_BUG for
+ * this.
+ */
+struct qbman_swp *qbman_swp_init(const struct qbman_swp_desc *d)
+{
+	int ret;
+	struct qbman_swp *p = kmalloc(sizeof(*p), GFP_KERNEL);
+
+	if (!p)
+		return NULL;
+	p->desc = d;
+#ifdef QBMAN_CHECKING
+	p->mc.check = swp_mc_can_start;
+#endif
+	p->mc.valid_bit = QB_VALID_BIT;
+	p->sdq = 0;
+	qb_attr_code_encode(&code_sdqcr_dct, &p->sdq, qbman_sdqcr_dct_prio_ics);
+	qb_attr_code_encode(&code_sdqcr_fc, &p->sdq, qbman_sdqcr_fc_up_to_3);
+	qb_attr_code_encode(&code_sdqcr_tok, &p->sdq, 0xbb);
+	atomic_set(&p->vdq.busy, 1);
+	p->vdq.valid_bit = QB_VALID_BIT;
+	p->dqrr.next_idx = 0;
+	p->dqrr.valid_bit = QB_VALID_BIT;
+	/* TODO: should also read PI/CI type registers and check that they're on
+	 * PoR values. If we're asked to initialise portals that aren't in reset
+	 * state, bad things will follow. */
+#ifdef WORKAROUND_DQRR_RESET_BUG
+	p->dqrr.reset_bug = 1;
+#endif
+	if ((p->desc->qman_version & 0xFFFF0000) < QMAN_REV_4100) {
+		p->dqrr.dqrr_size = 4;
+		/* Set size of DQRR to 4, encoded in 2 bits */
+		code_eq_dca_idx = (struct qb_attr_code)QB_CODE(0, 8, 2);
+	} else {
+		p->dqrr.dqrr_size = 8;
+		/* Set size of DQRR to 8, encoded in 3 bits */
+		code_eq_dca_idx = (struct qb_attr_code)QB_CODE(0, 8, 3);
+	}
+	ret = qbman_swp_sys_init(&p->sys, d, p->dqrr.dqrr_size);
+	if (ret) {
+		kfree(p);
+		pr_err("qbman_swp_sys_init() failed %d\n", ret);
+		return NULL;
+	}
+	/* SDQCR needs to be initialized to 0 when no channels are
+	   being dequeued from or else the QMan HW will indicate an
+	   error.  The values that were calculated above will be
+	   applied when dequeues from a specific channel are enabled */
+	qbman_cinh_write(&p->sys, QBMAN_CINH_SWP_SDQCR, 0);
+	return p;
+}
+
+void qbman_swp_finish(struct qbman_swp *p)
+{
+#ifdef QBMAN_CHECKING
+	BUG_ON(p->mc.check != swp_mc_can_start);
+#endif
+	qbman_swp_sys_finish(&p->sys);
+	kfree(p);
+}
+
+const struct qbman_swp_desc *qbman_swp_get_desc(struct qbman_swp *p)
+{
+	return p->desc;
+}
+
+/**************/
+/* Interrupts */
+/**************/
+
+uint32_t qbman_swp_interrupt_get_vanish(struct qbman_swp *p)
+{
+	return qbman_cinh_read(&p->sys, QBMAN_CINH_SWP_ISDR);
+}
+
+void qbman_swp_interrupt_set_vanish(struct qbman_swp *p, uint32_t mask)
+{
+	qbman_cinh_write(&p->sys, QBMAN_CINH_SWP_ISDR, mask);
+}
+
+uint32_t qbman_swp_interrupt_read_status(struct qbman_swp *p)
+{
+	return qbman_cinh_read(&p->sys, QBMAN_CINH_SWP_ISR);
+}
+
+void qbman_swp_interrupt_clear_status(struct qbman_swp *p, uint32_t mask)
+{
+	qbman_cinh_write(&p->sys, QBMAN_CINH_SWP_ISR, mask);
+}
+
+uint32_t qbman_swp_interrupt_get_trigger(struct qbman_swp *p)
+{
+	return qbman_cinh_read(&p->sys, QBMAN_CINH_SWP_IER);
+}
+
+void qbman_swp_interrupt_set_trigger(struct qbman_swp *p, uint32_t mask)
+{
+	qbman_cinh_write(&p->sys, QBMAN_CINH_SWP_IER, mask);
+}
+
+int qbman_swp_interrupt_get_inhibit(struct qbman_swp *p)
+{
+	return qbman_cinh_read(&p->sys, QBMAN_CINH_SWP_IIR);
+}
+
+void qbman_swp_interrupt_set_inhibit(struct qbman_swp *p, int inhibit)
+{
+	qbman_cinh_write(&p->sys, QBMAN_CINH_SWP_IIR, inhibit ? 0xffffffff : 0);
+}
+
+/***********************/
+/* Management commands */
+/***********************/
+
+/*
+ * Internal code common to all types of management commands.
+ */
+
+void *qbman_swp_mc_start(struct qbman_swp *p)
+{
+	void *ret;
+#ifdef QBMAN_CHECKING
+	BUG_ON(p->mc.check != swp_mc_can_start);
+#endif
+	ret = qbman_cena_write_start(&p->sys, QBMAN_CENA_SWP_CR);
+#ifdef QBMAN_CHECKING
+	if (!ret)
+		p->mc.check = swp_mc_can_submit;
+#endif
+	return ret;
+}
+
+void qbman_swp_mc_submit(struct qbman_swp *p, void *cmd, uint32_t cmd_verb)
+{
+	uint32_t *v = cmd;
+#ifdef QBMAN_CHECKING
+	BUG_ON(!p->mc.check != swp_mc_can_submit);
+#endif
+	/* TBD: "|=" is going to hurt performance. Need to move as many fields
+	 * out of word zero, and for those that remain, the "OR" needs to occur
+	 * at the caller side. This debug check helps to catch cases where the
+	 * caller wants to OR but has forgotten to do so. */
+	BUG_ON((*v & cmd_verb) != *v);
+	*v = cmd_verb | p->mc.valid_bit;
+	qbman_cena_write_complete(&p->sys, QBMAN_CENA_SWP_CR, cmd);
+#ifdef QBMAN_CHECKING
+	p->mc.check = swp_mc_can_poll;
+#endif
+}
+
+void *qbman_swp_mc_result(struct qbman_swp *p)
+{
+	uint32_t *ret, verb;
+#ifdef QBMAN_CHECKING
+	BUG_ON(p->mc.check != swp_mc_can_poll);
+#endif
+	qbman_cena_invalidate_prefetch(&p->sys,
+				 QBMAN_CENA_SWP_RR(p->mc.valid_bit));
+	ret = qbman_cena_read(&p->sys, QBMAN_CENA_SWP_RR(p->mc.valid_bit));
+	/* Remove the valid-bit - command completed iff the rest is non-zero */
+	verb = ret[0] & ~QB_VALID_BIT;
+	if (!verb)
+		return NULL;
+#ifdef QBMAN_CHECKING
+	p->mc.check = swp_mc_can_start;
+#endif
+	p->mc.valid_bit ^= QB_VALID_BIT;
+	return ret;
+}
+
+/***********/
+/* Enqueue */
+/***********/
+
+/* These should be const, eventually */
+static struct qb_attr_code code_eq_cmd = QB_CODE(0, 0, 2);
+static struct qb_attr_code code_eq_eqdi = QB_CODE(0, 3, 1);
+static struct qb_attr_code code_eq_dca_en = QB_CODE(0, 15, 1);
+static struct qb_attr_code code_eq_dca_pk = QB_CODE(0, 14, 1);
+static struct qb_attr_code code_eq_orp_en = QB_CODE(0, 2, 1);
+/* Can't set code_eq_dca_idx width. Need qman version. Read at runtime */
+static struct qb_attr_code code_eq_orp_is_nesn = QB_CODE(0, 31, 1);
+static struct qb_attr_code code_eq_orp_nlis = QB_CODE(0, 30, 1);
+static struct qb_attr_code code_eq_orp_seqnum = QB_CODE(0, 16, 14);
+static struct qb_attr_code code_eq_opr_id = QB_CODE(1, 0, 16);
+static struct qb_attr_code code_eq_tgt_id = QB_CODE(2, 0, 24);
+/* static struct qb_attr_code code_eq_tag = QB_CODE(3, 0, 32); */
+static struct qb_attr_code code_eq_qd_en = QB_CODE(0, 4, 1);
+static struct qb_attr_code code_eq_qd_bin = QB_CODE(4, 0, 16);
+static struct qb_attr_code code_eq_qd_pri = QB_CODE(4, 16, 4);
+static struct qb_attr_code code_eq_rsp_stash = QB_CODE(5, 16, 1);
+static struct qb_attr_code code_eq_rsp_id = QB_CODE(5, 24, 8);
+static struct qb_attr_code code_eq_rsp_lo = QB_CODE(6, 0, 32);
+
+enum qbman_eq_cmd_e {
+	/* No enqueue, primarily for plugging ORP gaps for dropped frames */
+	qbman_eq_cmd_empty,
+	/* DMA an enqueue response once complete */
+	qbman_eq_cmd_respond,
+	/* DMA an enqueue response only if the enqueue fails */
+	qbman_eq_cmd_respond_reject
+};
+
+void qbman_eq_desc_clear(struct qbman_eq_desc *d)
+{
+	memset(d, 0, sizeof(*d));
+}
+
+void qbman_eq_desc_set_no_orp(struct qbman_eq_desc *d, int respond_success)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_eq_orp_en, cl, 0);
+	qb_attr_code_encode(&code_eq_cmd, cl,
+			    respond_success ? qbman_eq_cmd_respond :
+					      qbman_eq_cmd_respond_reject);
+}
+
+void qbman_eq_desc_set_orp(struct qbman_eq_desc *d, int respond_success,
+			   uint32_t opr_id, uint32_t seqnum, int incomplete)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_eq_orp_en, cl, 1);
+	qb_attr_code_encode(&code_eq_cmd, cl,
+			    respond_success ? qbman_eq_cmd_respond :
+					      qbman_eq_cmd_respond_reject);
+	qb_attr_code_encode(&code_eq_opr_id, cl, opr_id);
+	qb_attr_code_encode(&code_eq_orp_seqnum, cl, seqnum);
+	qb_attr_code_encode(&code_eq_orp_nlis, cl, !!incomplete);
+}
+
+void qbman_eq_desc_set_orp_hole(struct qbman_eq_desc *d, uint32_t opr_id,
+				uint32_t seqnum)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_eq_orp_en, cl, 1);
+	qb_attr_code_encode(&code_eq_cmd, cl, qbman_eq_cmd_empty);
+	qb_attr_code_encode(&code_eq_opr_id, cl, opr_id);
+	qb_attr_code_encode(&code_eq_orp_seqnum, cl, seqnum);
+	qb_attr_code_encode(&code_eq_orp_nlis, cl, 0);
+	qb_attr_code_encode(&code_eq_orp_is_nesn, cl, 0);
+}
+
+void qbman_eq_desc_set_orp_nesn(struct qbman_eq_desc *d, uint32_t opr_id,
+				uint32_t seqnum)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_eq_orp_en, cl, 1);
+	qb_attr_code_encode(&code_eq_cmd, cl, qbman_eq_cmd_empty);
+	qb_attr_code_encode(&code_eq_opr_id, cl, opr_id);
+	qb_attr_code_encode(&code_eq_orp_seqnum, cl, seqnum);
+	qb_attr_code_encode(&code_eq_orp_nlis, cl, 0);
+	qb_attr_code_encode(&code_eq_orp_is_nesn, cl, 1);
+}
+
+void qbman_eq_desc_set_response(struct qbman_eq_desc *d,
+				dma_addr_t storage_phys,
+				int stash)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode_64(&code_eq_rsp_lo, (uint64_t *)cl, storage_phys);
+	qb_attr_code_encode(&code_eq_rsp_stash, cl, !!stash);
+}
+
+void qbman_eq_desc_set_token(struct qbman_eq_desc *d, uint8_t token)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_eq_rsp_id, cl, (uint32_t)token);
+}
+
+void qbman_eq_desc_set_fq(struct qbman_eq_desc *d, uint32_t fqid)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_eq_qd_en, cl, 0);
+	qb_attr_code_encode(&code_eq_tgt_id, cl, fqid);
+}
+
+void qbman_eq_desc_set_qd(struct qbman_eq_desc *d, uint32_t qdid,
+			  uint32_t qd_bin, uint32_t qd_prio)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_eq_qd_en, cl, 1);
+	qb_attr_code_encode(&code_eq_tgt_id, cl, qdid);
+	qb_attr_code_encode(&code_eq_qd_bin, cl, qd_bin);
+	qb_attr_code_encode(&code_eq_qd_pri, cl, qd_prio);
+}
+
+void qbman_eq_desc_set_eqdi(struct qbman_eq_desc *d, int enable)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_eq_eqdi, cl, !!enable);
+}
+
+void qbman_eq_desc_set_dca(struct qbman_eq_desc *d, int enable,
+				uint32_t dqrr_idx, int park)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_eq_dca_en, cl, !!enable);
+	if (enable) {
+		qb_attr_code_encode(&code_eq_dca_pk, cl, !!park);
+		qb_attr_code_encode(&code_eq_dca_idx, cl, dqrr_idx);
+	}
+}
+
+#define EQAR_IDX(eqar)     ((eqar) & 0x7)
+#define EQAR_VB(eqar)      ((eqar) & 0x80)
+#define EQAR_SUCCESS(eqar) ((eqar) & 0x100)
+
+int qbman_swp_enqueue(struct qbman_swp *s, const struct qbman_eq_desc *d,
+		      const struct qbman_fd *fd)
+{
+	uint32_t *p;
+	const uint32_t *cl = qb_cl(d);
+	uint32_t eqar = qbman_cinh_read(&s->sys, QBMAN_CINH_SWP_EQAR);
+
+	pr_debug("EQAR=%08x\n", eqar);
+	if (!EQAR_SUCCESS(eqar))
+		return -EBUSY;
+	p = qbman_cena_write_start(&s->sys,
+				   QBMAN_CENA_SWP_EQCR(EQAR_IDX(eqar)));
+	word_copy(&p[1], &cl[1], 7);
+	word_copy(&p[8], fd, sizeof(*fd) >> 2);
+	/* Set the verb byte, have to substitute in the valid-bit */
+	p[0] = cl[0] | EQAR_VB(eqar);
+	qbman_cena_write_complete(&s->sys,
+				  QBMAN_CENA_SWP_EQCR(EQAR_IDX(eqar)),
+				  p);
+	return 0;
+}
+
+/*************************/
+/* Static (push) dequeue */
+/*************************/
+
+void qbman_swp_push_get(struct qbman_swp *s, uint8_t channel_idx, int *enabled)
+{
+	struct qb_attr_code code = CODE_SDQCR_DQSRC(channel_idx);
+
+	BUG_ON(channel_idx > 15);
+	*enabled = (int)qb_attr_code_decode(&code, &s->sdq);
+}
+
+void qbman_swp_push_set(struct qbman_swp *s, uint8_t channel_idx, int enable)
+{
+	uint16_t dqsrc;
+	struct qb_attr_code code = CODE_SDQCR_DQSRC(channel_idx);
+
+	BUG_ON(channel_idx > 15);
+	qb_attr_code_encode(&code, &s->sdq, !!enable);
+	/* Read make the complete src map.  If no channels are enabled
+	   the SDQCR must be 0 or else QMan will assert errors */
+	dqsrc = (uint16_t)qb_attr_code_decode(&code_sdqcr_dqsrc, &s->sdq);
+	if (dqsrc != 0)
+		qbman_cinh_write(&s->sys, QBMAN_CINH_SWP_SDQCR, s->sdq);
+	else
+		qbman_cinh_write(&s->sys, QBMAN_CINH_SWP_SDQCR, 0);
+}
+
+/***************************/
+/* Volatile (pull) dequeue */
+/***************************/
+
+/* These should be const, eventually */
+static struct qb_attr_code code_pull_dct = QB_CODE(0, 0, 2);
+static struct qb_attr_code code_pull_dt = QB_CODE(0, 2, 2);
+static struct qb_attr_code code_pull_rls = QB_CODE(0, 4, 1);
+static struct qb_attr_code code_pull_stash = QB_CODE(0, 5, 1);
+static struct qb_attr_code code_pull_numframes = QB_CODE(0, 8, 4);
+static struct qb_attr_code code_pull_token = QB_CODE(0, 16, 8);
+static struct qb_attr_code code_pull_dqsource = QB_CODE(1, 0, 24);
+static struct qb_attr_code code_pull_rsp_lo = QB_CODE(2, 0, 32);
+
+enum qb_pull_dt_e {
+	qb_pull_dt_channel,
+	qb_pull_dt_workqueue,
+	qb_pull_dt_framequeue
+};
+
+void qbman_pull_desc_clear(struct qbman_pull_desc *d)
+{
+	memset(d, 0, sizeof(*d));
+}
+
+void qbman_pull_desc_set_storage(struct qbman_pull_desc *d,
+				 struct dpaa2_dq *storage,
+				 dma_addr_t storage_phys,
+				 int stash)
+{
+	uint32_t *cl = qb_cl(d);
+
+	/* Squiggle the pointer 'storage' into the extra 2 words of the
+	 * descriptor (which aren't copied to the hw command) */
+	*(void **)&cl[4] = storage;
+	if (!storage) {
+		qb_attr_code_encode(&code_pull_rls, cl, 0);
+		return;
+	}
+	qb_attr_code_encode(&code_pull_rls, cl, 1);
+	qb_attr_code_encode(&code_pull_stash, cl, !!stash);
+	qb_attr_code_encode_64(&code_pull_rsp_lo, (uint64_t *)cl, storage_phys);
+}
+
+void qbman_pull_desc_set_numframes(struct qbman_pull_desc *d, uint8_t numframes)
+{
+	uint32_t *cl = qb_cl(d);
+
+	BUG_ON(!numframes || (numframes > 16));
+	qb_attr_code_encode(&code_pull_numframes, cl,
+				(uint32_t)(numframes - 1));
+}
+
+void qbman_pull_desc_set_token(struct qbman_pull_desc *d, uint8_t token)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_pull_token, cl, token);
+}
+
+void qbman_pull_desc_set_fq(struct qbman_pull_desc *d, uint32_t fqid)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_pull_dct, cl, 1);
+	qb_attr_code_encode(&code_pull_dt, cl, qb_pull_dt_framequeue);
+	qb_attr_code_encode(&code_pull_dqsource, cl, fqid);
+}
+
+void qbman_pull_desc_set_wq(struct qbman_pull_desc *d, uint32_t wqid,
+			    enum qbman_pull_type_e dct)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_pull_dct, cl, dct);
+	qb_attr_code_encode(&code_pull_dt, cl, qb_pull_dt_workqueue);
+	qb_attr_code_encode(&code_pull_dqsource, cl, wqid);
+}
+
+void qbman_pull_desc_set_channel(struct qbman_pull_desc *d, uint32_t chid,
+				 enum qbman_pull_type_e dct)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_pull_dct, cl, dct);
+	qb_attr_code_encode(&code_pull_dt, cl, qb_pull_dt_channel);
+	qb_attr_code_encode(&code_pull_dqsource, cl, chid);
+}
+
+int qbman_swp_pull(struct qbman_swp *s, struct qbman_pull_desc *d)
+{
+	uint32_t *p;
+	uint32_t *cl = qb_cl(d);
+
+	if (!atomic_dec_and_test(&s->vdq.busy)) {
+		atomic_inc(&s->vdq.busy);
+		return -EBUSY;
+	}
+	s->vdq.storage = *(void **)&cl[4];
+	qb_attr_code_encode(&code_pull_token, cl, 1);
+	p = qbman_cena_write_start(&s->sys, QBMAN_CENA_SWP_VDQCR);
+	word_copy(&p[1], &cl[1], 3);
+	/* Set the verb byte, have to substitute in the valid-bit */
+	p[0] = cl[0] | s->vdq.valid_bit;
+	s->vdq.valid_bit ^= QB_VALID_BIT;
+	qbman_cena_write_complete(&s->sys, QBMAN_CENA_SWP_VDQCR, p);
+	return 0;
+}
+
+/****************/
+/* Polling DQRR */
+/****************/
+
+static struct qb_attr_code code_dqrr_verb = QB_CODE(0, 0, 8);
+static struct qb_attr_code code_dqrr_response = QB_CODE(0, 0, 7);
+static struct qb_attr_code code_dqrr_stat = QB_CODE(0, 8, 8);
+static struct qb_attr_code code_dqrr_seqnum = QB_CODE(0, 16, 14);
+static struct qb_attr_code code_dqrr_odpid = QB_CODE(1, 0, 16);
+/* static struct qb_attr_code code_dqrr_tok = QB_CODE(1, 24, 8); */
+static struct qb_attr_code code_dqrr_fqid = QB_CODE(2, 0, 24);
+static struct qb_attr_code code_dqrr_byte_count = QB_CODE(4, 0, 32);
+static struct qb_attr_code code_dqrr_frame_count = QB_CODE(5, 0, 24);
+static struct qb_attr_code code_dqrr_ctx_lo = QB_CODE(6, 0, 32);
+
+#define QBMAN_RESULT_DQ        0x60
+#define QBMAN_RESULT_FQRN      0x21
+#define QBMAN_RESULT_FQRNI     0x22
+#define QBMAN_RESULT_FQPN      0x24
+#define QBMAN_RESULT_FQDAN     0x25
+#define QBMAN_RESULT_CDAN      0x26
+#define QBMAN_RESULT_CSCN_MEM  0x27
+#define QBMAN_RESULT_CGCU      0x28
+#define QBMAN_RESULT_BPSCN     0x29
+#define QBMAN_RESULT_CSCN_WQ   0x2a
+
+static struct qb_attr_code code_dqpi_pi = QB_CODE(0, 0, 4);
+
+/* NULL return if there are no unconsumed DQRR entries. Returns a DQRR entry
+ * only once, so repeated calls can return a sequence of DQRR entries, without
+ * requiring they be consumed immediately or in any particular order. */
+const struct dpaa2_dq *qbman_swp_dqrr_next(struct qbman_swp *s)
+{
+	uint32_t verb;
+	uint32_t response_verb;
+	uint32_t flags;
+	const struct dpaa2_dq *dq;
+	const uint32_t *p;
+
+	/* Before using valid-bit to detect if something is there, we have to
+	 * handle the case of the DQRR reset bug... */
+#ifdef WORKAROUND_DQRR_RESET_BUG
+	if (unlikely(s->dqrr.reset_bug)) {
+		/* We pick up new entries by cache-inhibited producer index,
+		 * which means that a non-coherent mapping would require us to
+		 * invalidate and read *only* once that PI has indicated that
+		 * there's an entry here. The first trip around the DQRR ring
+		 * will be much less efficient than all subsequent trips around
+		 * it...
+		 */
+		uint32_t dqpi = qbman_cinh_read(&s->sys, QBMAN_CINH_SWP_DQPI);
+		uint32_t pi = qb_attr_code_decode(&code_dqpi_pi, &dqpi);
+		/* there are new entries iff pi != next_idx */
+		if (pi == s->dqrr.next_idx)
+			return NULL;
+		/* if next_idx is/was the last ring index, and 'pi' is
+		 * different, we can disable the workaround as all the ring
+		 * entries have now been DMA'd to so valid-bit checking is
+		 * repaired. Note: this logic needs to be based on next_idx
+		 * (which increments one at a time), rather than on pi (which
+		 * can burst and wrap-around between our snapshots of it).
+		 */
+		if (s->dqrr.next_idx == (s->dqrr.dqrr_size - 1)) {
+			pr_debug("DEBUG: next_idx=%d, pi=%d, clear reset bug\n",
+				s->dqrr.next_idx, pi);
+			s->dqrr.reset_bug = 0;
+		}
+		qbman_cena_invalidate_prefetch(&s->sys,
+					QBMAN_CENA_SWP_DQRR(s->dqrr.next_idx));
+	}
+#endif
+
+	dq = qbman_cena_read(&s->sys, QBMAN_CENA_SWP_DQRR(s->dqrr.next_idx));
+	p = qb_cl(dq);
+	verb = qb_attr_code_decode(&code_dqrr_verb, p);
+
+	/* If the valid-bit isn't of the expected polarity, nothing there. Note,
+	 * in the DQRR reset bug workaround, we shouldn't need to skip these
+	 * check, because we've already determined that a new entry is available
+	 * and we've invalidated the cacheline before reading it, so the
+	 * valid-bit behaviour is repaired and should tell us what we already
+	 * knew from reading PI.
+	 */
+	if ((verb & QB_VALID_BIT) != s->dqrr.valid_bit) {
+		qbman_cena_invalidate_prefetch(&s->sys,
+					QBMAN_CENA_SWP_DQRR(s->dqrr.next_idx));
+		return NULL;
+	}
+	/* There's something there. Move "next_idx" attention to the next ring
+	 * entry (and prefetch it) before returning what we found. */
+	s->dqrr.next_idx++;
+	s->dqrr.next_idx &= s->dqrr.dqrr_size - 1; /* Wrap around */
+	/* TODO: it's possible to do all this without conditionals, optimise it
+	 * later. */
+	if (!s->dqrr.next_idx)
+		s->dqrr.valid_bit ^= QB_VALID_BIT;
+
+	/* If this is the final response to a volatile dequeue command
+	   indicate that the vdq is no longer busy */
+	flags = dpaa2_dq_flags(dq);
+	response_verb = qb_attr_code_decode(&code_dqrr_response, &verb);
+	if ((response_verb == QBMAN_RESULT_DQ) &&
+	    (flags & DPAA2_DQ_STAT_VOLATILE) &&
+	    (flags & DPAA2_DQ_STAT_EXPIRED))
+		atomic_inc(&s->vdq.busy);
+
+	qbman_cena_invalidate_prefetch(&s->sys,
+				       QBMAN_CENA_SWP_DQRR(s->dqrr.next_idx));
+	return dq;
+}
+
+/* Consume DQRR entries previously returned from qbman_swp_dqrr_next(). */
+void qbman_swp_dqrr_consume(struct qbman_swp *s, const struct dpaa2_dq *dq)
+{
+	qbman_cinh_write(&s->sys, QBMAN_CINH_SWP_DCAP, QBMAN_IDX_FROM_DQRR(dq));
+}
+
+/*********************************/
+/* Polling user-provided storage */
+/*********************************/
+
+int qbman_result_has_new_result(struct qbman_swp *s,
+				  const struct dpaa2_dq *dq)
+{
+	/* To avoid converting the little-endian DQ entry to host-endian prior
+	 * to us knowing whether there is a valid entry or not (and run the
+	 * risk of corrupting the incoming hardware LE write), we detect in
+	 * hardware endianness rather than host. This means we need a different
+	 * "code" depending on whether we are BE or LE in software, which is
+	 * where DQRR_TOK_OFFSET comes in... */
+	static struct qb_attr_code code_dqrr_tok_detect =
+					QB_CODE(0, DQRR_TOK_OFFSET, 8);
+	/* The user trying to poll for a result treats "dq" as const. It is
+	 * however the same address that was provided to us non-const in the
+	 * first place, for directing hardware DMA to. So we can cast away the
+	 * const because it is mutable from our perspective. */
+	uint32_t *p = qb_cl((struct dpaa2_dq *)dq);
+	uint32_t token;
+
+	token = qb_attr_code_decode(&code_dqrr_tok_detect, &p[1]);
+	if (token != 1)
+		return 0;
+	qb_attr_code_encode(&code_dqrr_tok_detect, &p[1], 0);
+
+	/* Only now do we convert from hardware to host endianness. Also, as we
+	 * are returning success, the user has promised not to call us again, so
+	 * there's no risk of us converting the endianness twice... */
+	make_le32_n(p, 16);
+
+	/* VDQCR "no longer busy" hook - not quite the same as DQRR, because the
+	 * fact "VDQCR" shows busy doesn't mean that the result we're looking at
+	 * is from the same command. Eg. we may be looking at our 10th dequeue
+	 * result from our first VDQCR command, yet the second dequeue command
+	 * could have been kicked off already, after seeing the 1st result. Ie.
+	 * the result we're looking at is not necessarily proof that we can
+	 * reset "busy".  We instead base the decision on whether the current
+	 * result is sitting at the first 'storage' location of the busy
+	 * command. */
+	if (s->vdq.storage == dq) {
+		s->vdq.storage = NULL;
+		atomic_inc(&s->vdq.busy);
+	}
+	return 1;
+}
+
+/********************************/
+/* Categorising qbman_result */
+/********************************/
+
+static struct qb_attr_code code_result_in_mem =
+			QB_CODE(0, QBMAN_RESULT_VERB_OFFSET_IN_MEM, 7);
+
+static inline int __qbman_result_is_x(const struct dpaa2_dq *dq, uint32_t x)
+{
+	const uint32_t *p = qb_cl(dq);
+	uint32_t response_verb = qb_attr_code_decode(&code_dqrr_response, p);
+
+	return response_verb == x;
+}
+
+static inline int __qbman_result_is_x_in_mem(const struct dpaa2_dq *dq,
+					     uint32_t x)
+{
+	const uint32_t *p = qb_cl(dq);
+	uint32_t response_verb = qb_attr_code_decode(&code_result_in_mem, p);
+
+	return (response_verb == x);
+}
+
+int qbman_result_is_DQ(const struct dpaa2_dq *dq)
+{
+	return __qbman_result_is_x(dq, QBMAN_RESULT_DQ);
+}
+
+int qbman_result_is_FQDAN(const struct dpaa2_dq *dq)
+{
+	return __qbman_result_is_x(dq, QBMAN_RESULT_FQDAN);
+}
+
+int qbman_result_is_CDAN(const struct dpaa2_dq *dq)
+{
+	return __qbman_result_is_x(dq, QBMAN_RESULT_CDAN);
+}
+
+int qbman_result_is_CSCN(const struct dpaa2_dq *dq)
+{
+	return __qbman_result_is_x_in_mem(dq, QBMAN_RESULT_CSCN_MEM) ||
+		__qbman_result_is_x(dq, QBMAN_RESULT_CSCN_WQ);
+}
+
+int qbman_result_is_BPSCN(const struct dpaa2_dq *dq)
+{
+	return __qbman_result_is_x_in_mem(dq, QBMAN_RESULT_BPSCN);
+}
+
+int qbman_result_is_CGCU(const struct dpaa2_dq *dq)
+{
+	return __qbman_result_is_x_in_mem(dq, QBMAN_RESULT_CGCU);
+}
+
+int qbman_result_is_FQRN(const struct dpaa2_dq *dq)
+{
+	return __qbman_result_is_x_in_mem(dq, QBMAN_RESULT_FQRN);
+}
+
+int qbman_result_is_FQRNI(const struct dpaa2_dq *dq)
+{
+	return __qbman_result_is_x_in_mem(dq, QBMAN_RESULT_FQRNI);
+}
+
+int qbman_result_is_FQPN(const struct dpaa2_dq *dq)
+{
+	return __qbman_result_is_x(dq, QBMAN_RESULT_FQPN);
+}
+
+/*********************************/
+/* Parsing frame dequeue results */
+/*********************************/
+
+/* These APIs assume qbman_result_is_DQ() is TRUE */
+
+uint32_t dpaa2_dq_flags(const struct dpaa2_dq *dq)
+{
+	const uint32_t *p = qb_cl(dq);
+
+	return qb_attr_code_decode(&code_dqrr_stat, p);
+}
+
+uint16_t dpaa2_dq_seqnum(const struct dpaa2_dq *dq)
+{
+	const uint32_t *p = qb_cl(dq);
+
+	return (uint16_t)qb_attr_code_decode(&code_dqrr_seqnum, p);
+}
+
+uint16_t dpaa2_dq_odpid(const struct dpaa2_dq *dq)
+{
+	const uint32_t *p = qb_cl(dq);
+
+	return (uint16_t)qb_attr_code_decode(&code_dqrr_odpid, p);
+}
+
+uint32_t dpaa2_dq_fqid(const struct dpaa2_dq *dq)
+{
+	const uint32_t *p = qb_cl(dq);
+
+	return qb_attr_code_decode(&code_dqrr_fqid, p);
+}
+
+uint32_t dpaa2_dq_byte_count(const struct dpaa2_dq *dq)
+{
+	const uint32_t *p = qb_cl(dq);
+
+	return qb_attr_code_decode(&code_dqrr_byte_count, p);
+}
+
+uint32_t dpaa2_dq_frame_count(const struct dpaa2_dq *dq)
+{
+	const uint32_t *p = qb_cl(dq);
+
+	return qb_attr_code_decode(&code_dqrr_frame_count, p);
+}
+
+uint64_t dpaa2_dq_fqd_ctx(const struct dpaa2_dq *dq)
+{
+	const uint64_t *p = (uint64_t *)qb_cl(dq);
+
+	return qb_attr_code_decode_64(&code_dqrr_ctx_lo, p);
+}
+EXPORT_SYMBOL(dpaa2_dq_fqd_ctx);
+
+const struct dpaa2_fd *dpaa2_dq_fd(const struct dpaa2_dq *dq)
+{
+	const uint32_t *p = qb_cl(dq);
+
+	return (const struct dpaa2_fd *)&p[8];
+}
+EXPORT_SYMBOL(dpaa2_dq_fd);
+
+/**************************************/
+/* Parsing state-change notifications */
+/**************************************/
+
+static struct qb_attr_code code_scn_state = QB_CODE(0, 16, 8);
+static struct qb_attr_code code_scn_rid = QB_CODE(1, 0, 24);
+static struct qb_attr_code code_scn_state_in_mem =
+			QB_CODE(0, SCN_STATE_OFFSET_IN_MEM, 8);
+static struct qb_attr_code code_scn_rid_in_mem =
+			QB_CODE(1, SCN_RID_OFFSET_IN_MEM, 24);
+static struct qb_attr_code code_scn_ctx_lo = QB_CODE(2, 0, 32);
+
+uint8_t qbman_result_SCN_state(const struct dpaa2_dq *scn)
+{
+	const uint32_t *p = qb_cl(scn);
+
+	return (uint8_t)qb_attr_code_decode(&code_scn_state, p);
+}
+
+uint32_t qbman_result_SCN_rid(const struct dpaa2_dq *scn)
+{
+	const uint32_t *p = qb_cl(scn);
+
+	return qb_attr_code_decode(&code_scn_rid, p);
+}
+
+uint64_t qbman_result_SCN_ctx(const struct dpaa2_dq *scn)
+{
+	const uint64_t *p = (uint64_t *)qb_cl(scn);
+
+	return qb_attr_code_decode_64(&code_scn_ctx_lo, p);
+}
+
+uint8_t qbman_result_SCN_state_in_mem(const struct dpaa2_dq *scn)
+{
+	const uint32_t *p = qb_cl(scn);
+
+	return (uint8_t)qb_attr_code_decode(&code_scn_state_in_mem, p);
+}
+
+uint32_t qbman_result_SCN_rid_in_mem(const struct dpaa2_dq *scn)
+{
+	const uint32_t *p = qb_cl(scn);
+	uint32_t result_rid;
+
+	result_rid = qb_attr_code_decode(&code_scn_rid_in_mem, p);
+	return make_le24(result_rid);
+}
+
+/*****************/
+/* Parsing BPSCN */
+/*****************/
+uint16_t qbman_result_bpscn_bpid(const struct dpaa2_dq *scn)
+{
+	return (uint16_t)qbman_result_SCN_rid_in_mem(scn) & 0x3FFF;
+}
+
+int qbman_result_bpscn_has_free_bufs(const struct dpaa2_dq *scn)
+{
+	return !(int)(qbman_result_SCN_state_in_mem(scn) & 0x1);
+}
+
+int qbman_result_bpscn_is_depleted(const struct dpaa2_dq *scn)
+{
+	return (int)(qbman_result_SCN_state_in_mem(scn) & 0x2);
+}
+
+int qbman_result_bpscn_is_surplus(const struct dpaa2_dq *scn)
+{
+	return (int)(qbman_result_SCN_state_in_mem(scn) & 0x4);
+}
+
+uint64_t qbman_result_bpscn_ctx(const struct dpaa2_dq *scn)
+{
+	return qbman_result_SCN_ctx(scn);
+}
+
+/*****************/
+/* Parsing CGCU  */
+/*****************/
+uint16_t qbman_result_cgcu_cgid(const struct dpaa2_dq *scn)
+{
+	return (uint16_t)qbman_result_SCN_rid_in_mem(scn) & 0xFFFF;
+}
+
+uint64_t qbman_result_cgcu_icnt(const struct dpaa2_dq *scn)
+{
+	return qbman_result_SCN_ctx(scn) & 0xFFFFFFFFFF;
+}
+
+/******************/
+/* Buffer release */
+/******************/
+
+/* These should be const, eventually */
+/* static struct qb_attr_code code_release_num = QB_CODE(0, 0, 3); */
+static struct qb_attr_code code_release_set_me = QB_CODE(0, 5, 1);
+static struct qb_attr_code code_release_rcdi = QB_CODE(0, 6, 1);
+static struct qb_attr_code code_release_bpid = QB_CODE(0, 16, 16);
+
+void qbman_release_desc_clear(struct qbman_release_desc *d)
+{
+	uint32_t *cl;
+
+	memset(d, 0, sizeof(*d));
+	cl = qb_cl(d);
+	qb_attr_code_encode(&code_release_set_me, cl, 1);
+}
+
+void qbman_release_desc_set_bpid(struct qbman_release_desc *d, uint32_t bpid)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_release_bpid, cl, bpid);
+}
+
+void qbman_release_desc_set_rcdi(struct qbman_release_desc *d, int enable)
+{
+	uint32_t *cl = qb_cl(d);
+
+	qb_attr_code_encode(&code_release_rcdi, cl, !!enable);
+}
+
+#define RAR_IDX(rar)     ((rar) & 0x7)
+#define RAR_VB(rar)      ((rar) & 0x80)
+#define RAR_SUCCESS(rar) ((rar) & 0x100)
+
+int qbman_swp_release(struct qbman_swp *s, const struct qbman_release_desc *d,
+		      const uint64_t *buffers, unsigned int num_buffers)
+{
+	uint32_t *p;
+	const uint32_t *cl = qb_cl(d);
+	uint32_t rar = qbman_cinh_read(&s->sys, QBMAN_CINH_SWP_RAR);
+
+	pr_debug("RAR=%08x\n", rar);
+	if (!RAR_SUCCESS(rar))
+		return -EBUSY;
+	BUG_ON(!num_buffers || (num_buffers > 7));
+	/* Start the release command */
+	p = qbman_cena_write_start(&s->sys,
+				   QBMAN_CENA_SWP_RCR(RAR_IDX(rar)));
+	/* Copy the caller's buffer pointers to the command */
+	u64_to_le32_copy(&p[2], buffers, num_buffers);
+	/* Set the verb byte, have to substitute in the valid-bit and the number
+	 * of buffers. */
+	p[0] = cl[0] | RAR_VB(rar) | num_buffers;
+	qbman_cena_write_complete(&s->sys,
+				  QBMAN_CENA_SWP_RCR(RAR_IDX(rar)),
+				  p);
+	return 0;
+}
+
+/*******************/
+/* Buffer acquires */
+/*******************/
+
+/* These should be const, eventually */
+static struct qb_attr_code code_acquire_bpid = QB_CODE(0, 16, 16);
+static struct qb_attr_code code_acquire_num = QB_CODE(1, 0, 3);
+static struct qb_attr_code code_acquire_r_num = QB_CODE(1, 0, 3);
+
+int qbman_swp_acquire(struct qbman_swp *s, uint32_t bpid, uint64_t *buffers,
+		      unsigned int num_buffers)
+{
+	uint32_t *p;
+	uint32_t verb, rslt, num;
+
+	BUG_ON(!num_buffers || (num_buffers > 7));
+
+	/* Start the management command */
+	p = qbman_swp_mc_start(s);
+
+	if (!p)
+		return -EBUSY;
+
+	/* Encode the caller-provided attributes */
+	qb_attr_code_encode(&code_acquire_bpid, p, bpid);
+	qb_attr_code_encode(&code_acquire_num, p, num_buffers);
+
+	/* Complete the management command */
+	p = qbman_swp_mc_complete(s, p, p[0] | QBMAN_MC_ACQUIRE);
+
+	/* Decode the outcome */
+	verb = qb_attr_code_decode(&code_generic_verb, p);
+	rslt = qb_attr_code_decode(&code_generic_rslt, p);
+	num = qb_attr_code_decode(&code_acquire_r_num, p);
+	BUG_ON(verb != QBMAN_MC_ACQUIRE);
+
+	/* Determine success or failure */
+	if (unlikely(rslt != QBMAN_MC_RSLT_OK)) {
+		pr_err("Acquire buffers from BPID 0x%x failed, code=0x%02x\n",
+								bpid, rslt);
+		return -EIO;
+	}
+	BUG_ON(num > num_buffers);
+	/* Copy the acquired buffers to the caller's array */
+	u64_from_le32_copy(buffers, &p[2], num);
+	return (int)num;
+}
+
+/*****************/
+/* FQ management */
+/*****************/
+
+static struct qb_attr_code code_fqalt_fqid = QB_CODE(1, 0, 32);
+
+static int qbman_swp_alt_fq_state(struct qbman_swp *s, uint32_t fqid,
+				 uint8_t alt_fq_verb)
+{
+	uint32_t *p;
+	uint32_t verb, rslt;
+
+	/* Start the management command */
+	p = qbman_swp_mc_start(s);
+	if (!p)
+		return -EBUSY;
+
+	qb_attr_code_encode(&code_fqalt_fqid, p, fqid);
+	/* Complete the management command */
+	p = qbman_swp_mc_complete(s, p, p[0] | alt_fq_verb);
+
+	/* Decode the outcome */
+	verb = qb_attr_code_decode(&code_generic_verb, p);
+	rslt = qb_attr_code_decode(&code_generic_rslt, p);
+	BUG_ON(verb != alt_fq_verb);
+
+	/* Determine success or failure */
+	if (unlikely(rslt != QBMAN_MC_RSLT_OK)) {
+		pr_err("ALT FQID %d failed: verb = 0x%08x, code = 0x%02x\n",
+		       fqid, alt_fq_verb, rslt);
+		return -EIO;
+	}
+
+	return 0;
+}
+
+int qbman_swp_fq_schedule(struct qbman_swp *s, uint32_t fqid)
+{
+	return qbman_swp_alt_fq_state(s, fqid, QBMAN_FQ_SCHEDULE);
+}
+
+int qbman_swp_fq_force(struct qbman_swp *s, uint32_t fqid)
+{
+	return qbman_swp_alt_fq_state(s, fqid, QBMAN_FQ_FORCE);
+}
+
+int qbman_swp_fq_xon(struct qbman_swp *s, uint32_t fqid)
+{
+	return qbman_swp_alt_fq_state(s, fqid, QBMAN_FQ_XON);
+}
+
+int qbman_swp_fq_xoff(struct qbman_swp *s, uint32_t fqid)
+{
+	return qbman_swp_alt_fq_state(s, fqid, QBMAN_FQ_XOFF);
+}
+
+/**********************/
+/* Channel management */
+/**********************/
+
+static struct qb_attr_code code_cdan_cid = QB_CODE(0, 16, 12);
+static struct qb_attr_code code_cdan_we = QB_CODE(1, 0, 8);
+static struct qb_attr_code code_cdan_en = QB_CODE(1, 8, 1);
+static struct qb_attr_code code_cdan_ctx_lo = QB_CODE(2, 0, 32);
+
+/* Hide "ICD" for now as we don't use it, don't set it, and don't test it, so it
+ * would be irresponsible to expose it. */
+#define CODE_CDAN_WE_EN    0x1
+#define CODE_CDAN_WE_CTX   0x4
+
+static int qbman_swp_CDAN_set(struct qbman_swp *s, uint16_t channelid,
+			      uint8_t we_mask, uint8_t cdan_en,
+			      uint64_t ctx)
+{
+	uint32_t *p;
+	uint32_t verb, rslt;
+
+	/* Start the management command */
+	p = qbman_swp_mc_start(s);
+	if (!p)
+		return -EBUSY;
+
+	/* Encode the caller-provided attributes */
+	qb_attr_code_encode(&code_cdan_cid, p, channelid);
+	qb_attr_code_encode(&code_cdan_we, p, we_mask);
+	qb_attr_code_encode(&code_cdan_en, p, cdan_en);
+	qb_attr_code_encode_64(&code_cdan_ctx_lo, (uint64_t *)p, ctx);
+	/* Complete the management command */
+	p = qbman_swp_mc_complete(s, p, p[0] | QBMAN_WQCHAN_CONFIGURE);
+
+	/* Decode the outcome */
+	verb = qb_attr_code_decode(&code_generic_verb, p);
+	rslt = qb_attr_code_decode(&code_generic_rslt, p);
+	BUG_ON(verb != QBMAN_WQCHAN_CONFIGURE);
+
+	/* Determine success or failure */
+	if (unlikely(rslt != QBMAN_MC_RSLT_OK)) {
+		pr_err("CDAN cQID %d failed: code = 0x%02x\n",
+		       channelid, rslt);
+		return -EIO;
+	}
+
+	return 0;
+}
+
+int qbman_swp_CDAN_set_context(struct qbman_swp *s, uint16_t channelid,
+			       uint64_t ctx)
+{
+	return qbman_swp_CDAN_set(s, channelid,
+				  CODE_CDAN_WE_CTX,
+				  0, ctx);
+}
+
+int qbman_swp_CDAN_enable(struct qbman_swp *s, uint16_t channelid)
+{
+	return qbman_swp_CDAN_set(s, channelid,
+				  CODE_CDAN_WE_EN,
+				  1, 0);
+}
+int qbman_swp_CDAN_disable(struct qbman_swp *s, uint16_t channelid)
+{
+	return qbman_swp_CDAN_set(s, channelid,
+				  CODE_CDAN_WE_EN,
+				  0, 0);
+}
+int qbman_swp_CDAN_set_context_enable(struct qbman_swp *s, uint16_t channelid,
+				      uint64_t ctx)
+{
+	return qbman_swp_CDAN_set(s, channelid,
+				  CODE_CDAN_WE_EN | CODE_CDAN_WE_CTX,
+				  1, ctx);
+}
diff --git a/drivers/staging/fsl-mc/bus/dpio/qbman_portal.h b/drivers/staging/fsl-mc/bus/dpio/qbman_portal.h
new file mode 100644
index 0000000..2db2b05
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/qbman_portal.h
@@ -0,0 +1,260 @@
+/* Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "qbman_private.h"
+#include "fsl_qbman_portal.h"
+#include "../../include/fsl_dpaa2_fd.h"
+
+/* All QBMan command and result structures use this "valid bit" encoding */
+#define QB_VALID_BIT ((uint32_t)0x80)
+
+/* Management command result codes */
+#define QBMAN_MC_RSLT_OK      0xf0
+
+/* QBMan DQRR size is set at runtime in qbman_portal.c */
+
+/* DQRR valid-bit reset bug. See qbman_portal.c::qbman_swp_init(). */
+#define WORKAROUND_DQRR_RESET_BUG
+
+/* --------------------- */
+/* portal data structure */
+/* --------------------- */
+
+struct qbman_swp {
+	const struct qbman_swp_desc *desc;
+	/* The qbman_sys (ie. arch/OS-specific) support code can put anything it
+	 * needs in here. */
+	struct qbman_swp_sys sys;
+	/* Management commands */
+	struct {
+#ifdef QBMAN_CHECKING
+		enum swp_mc_check {
+			swp_mc_can_start, /* call __qbman_swp_mc_start() */
+			swp_mc_can_submit, /* call __qbman_swp_mc_submit() */
+			swp_mc_can_poll, /* call __qbman_swp_mc_result() */
+		} check;
+#endif
+		uint32_t valid_bit; /* 0x00 or 0x80 */
+	} mc;
+	/* Push dequeues */
+	uint32_t sdq;
+	/* Volatile dequeues */
+	struct {
+		/* VDQCR supports a "1 deep pipeline", meaning that if you know
+		 * the last-submitted command is already executing in the
+		 * hardware (as evidenced by at least 1 valid dequeue result),
+		 * you can write another dequeue command to the register, the
+		 * hardware will start executing it as soon as the
+		 * already-executing command terminates. (This minimises latency
+		 * and stalls.) With that in mind, this "busy" variable refers
+		 * to whether or not a command can be submitted, not whether or
+		 * not a previously-submitted command is still executing. In
+		 * other words, once proof is seen that the previously-submitted
+		 * command is executing, "vdq" is no longer "busy".
+		 */
+		atomic_t busy;
+		uint32_t valid_bit; /* 0x00 or 0x80 */
+		/* We need to determine when vdq is no longer busy. This depends
+		 * on whether the "busy" (last-submitted) dequeue command is
+		 * targeting DQRR or main-memory, and detected is based on the
+		 * presence of the dequeue command's "token" showing up in
+		 * dequeue entries in DQRR or main-memory (respectively). */
+		struct dpaa2_dq *storage; /* NULL if DQRR */
+	} vdq;
+	/* DQRR */
+	struct {
+		uint32_t next_idx;
+		uint32_t valid_bit;
+		uint8_t dqrr_size;
+#ifdef WORKAROUND_DQRR_RESET_BUG
+		int reset_bug;
+#endif
+	} dqrr;
+};
+
+/* -------------------------- */
+/* portal management commands */
+/* -------------------------- */
+
+/* Different management commands all use this common base layer of code to issue
+ * commands and poll for results. The first function returns a pointer to where
+ * the caller should fill in their MC command (though they should ignore the
+ * verb byte), the second function commits merges in the caller-supplied command
+ * verb (which should not include the valid-bit) and submits the command to
+ * hardware, and the third function checks for a completed response (returns
+ * non-NULL if only if the response is complete). */
+void *qbman_swp_mc_start(struct qbman_swp *p);
+void qbman_swp_mc_submit(struct qbman_swp *p, void *cmd, uint32_t cmd_verb);
+void *qbman_swp_mc_result(struct qbman_swp *p);
+
+/* Wraps up submit + poll-for-result */
+static inline void *qbman_swp_mc_complete(struct qbman_swp *swp, void *cmd,
+					  uint32_t cmd_verb)
+{
+	int loopvar;
+
+	qbman_swp_mc_submit(swp, cmd, cmd_verb);
+	DBG_POLL_START(loopvar);
+	do {
+		DBG_POLL_CHECK(loopvar);
+		cmd = qbman_swp_mc_result(swp);
+	} while (!cmd);
+	return cmd;
+}
+
+/* ------------ */
+/* qb_attr_code */
+/* ------------ */
+
+/* This struct locates a sub-field within a QBMan portal (CENA) cacheline which
+ * is either serving as a configuration command or a query result. The
+ * representation is inherently little-endian, as the indexing of the words is
+ * itself little-endian in nature and layerscape is little endian for anything
+ * that crosses a word boundary too (64-bit fields are the obvious examples).
+ */
+struct qb_attr_code {
+	unsigned int word; /* which uint32_t[] array member encodes the field */
+	unsigned int lsoffset; /* encoding offset from ls-bit */
+	unsigned int width; /* encoding width. (bool must be 1.) */
+};
+
+/* Some pre-defined codes */
+extern struct qb_attr_code code_generic_verb;
+extern struct qb_attr_code code_generic_rslt;
+
+/* Macros to define codes */
+#define QB_CODE(a, b, c) { a, b, c}
+#define QB_CODE_NULL \
+	QB_CODE((unsigned int)-1, (unsigned int)-1, (unsigned int)-1)
+
+/* Rotate a code "ms", meaning that it moves from less-significant bytes to
+ * more-significant, from less-significant words to more-significant, etc. The
+ * "ls" version does the inverse, from more-significant towards
+ * less-significant.
+ */
+static inline void qb_attr_code_rotate_ms(struct qb_attr_code *code,
+					  unsigned int bits)
+{
+	code->lsoffset += bits;
+	while (code->lsoffset > 31) {
+		code->word++;
+		code->lsoffset -= 32;
+	}
+}
+static inline void qb_attr_code_rotate_ls(struct qb_attr_code *code,
+					  unsigned int bits)
+{
+	/* Don't be fooled, this trick should work because the types are
+	 * unsigned. So the case that interests the while loop (the rotate has
+	 * gone too far and the word count needs to compensate for it), is
+	 * manifested when lsoffset is negative. But that equates to a really
+	 * large unsigned value, starting with lots of "F"s. As such, we can
+	 * continue adding 32 back to it until it wraps back round above zero,
+	 * to a value of 31 or less...
+	 */
+	code->lsoffset -= bits;
+	while (code->lsoffset > 31) {
+		code->word--;
+		code->lsoffset += 32;
+	}
+}
+/* Implement a loop of code rotations until 'expr' evaluates to FALSE (0). */
+#define qb_attr_code_for_ms(code, bits, expr) \
+		for (; expr; qb_attr_code_rotate_ms(code, bits))
+#define qb_attr_code_for_ls(code, bits, expr) \
+		for (; expr; qb_attr_code_rotate_ls(code, bits))
+
+/* decode a field from a cacheline */
+static inline uint32_t qb_attr_code_decode(const struct qb_attr_code *code,
+				      const uint32_t *cacheline)
+{
+	return d32_uint32_t(code->lsoffset, code->width, cacheline[code->word]);
+}
+static inline uint64_t qb_attr_code_decode_64(const struct qb_attr_code *code,
+				      const uint64_t *cacheline)
+{
+	uint64_t res;
+	u64_from_le32_copy(&res, &cacheline[code->word/2], 1);
+	return res;
+}
+
+/* encode a field to a cacheline */
+static inline void qb_attr_code_encode(const struct qb_attr_code *code,
+				       uint32_t *cacheline, uint32_t val)
+{
+	cacheline[code->word] =
+		r32_uint32_t(code->lsoffset, code->width, cacheline[code->word])
+		| e32_uint32_t(code->lsoffset, code->width, val);
+}
+static inline void qb_attr_code_encode_64(const struct qb_attr_code *code,
+				       uint64_t *cacheline, uint64_t val)
+{
+	u64_to_le32_copy(&cacheline[code->word/2], &val, 1);
+}
+
+/* Small-width signed values (two's-complement) will decode into medium-width
+ * positives. (Eg. for an 8-bit signed field, which stores values from -128 to
+ * +127, a setting of -7 would appear to decode to the 32-bit unsigned value
+ * 249. Likewise -120 would decode as 136.) This function allows the caller to
+ * "re-sign" such fields to 32-bit signed. (Eg. -7, which was 249 with an 8-bit
+ * encoding, will become 0xfffffff9 if you cast the return value to uint32_t).
+ */
+static inline int32_t qb_attr_code_makesigned(const struct qb_attr_code *code,
+					  uint32_t val)
+{
+	BUG_ON(val >= (1 << code->width));
+	/* If the high bit was set, it was encoding a negative */
+	if (val >= (1 << (code->width - 1)))
+		return (int32_t)0 - (int32_t)(((uint32_t)1 << code->width) -
+			val);
+	/* Otherwise, it was encoding a positive */
+	return (int32_t)val;
+}
+
+/* ---------------------- */
+/* Descriptors/cachelines */
+/* ---------------------- */
+
+/* To avoid needless dynamic allocation, the driver API often gives the caller
+ * a "descriptor" type that the caller can instantiate however they like.
+ * Ultimately though, it is just a cacheline of binary storage (or something
+ * smaller when it is known that the descriptor doesn't need all 64 bytes) for
+ * holding pre-formatted pieces of hardware commands. The performance-critical
+ * code can then copy these descriptors directly into hardware command
+ * registers more efficiently than trying to construct/format commands
+ * on-the-fly. The API user sees the descriptor as an array of 32-bit words in
+ * order for the compiler to know its size, but the internal details are not
+ * exposed. The following macro is used within the driver for converting *any*
+ * descriptor pointer to a usable array pointer. The use of a macro (instead of
+ * an inline) is necessary to work with different descriptor types and to work
+ * correctly with const and non-const inputs (and similarly-qualified outputs).
+ */
+#define qb_cl(d) (&(d)->dont_manipulate_directly[0])
diff --git a/drivers/staging/fsl-mc/bus/dpio/qbman_private.h b/drivers/staging/fsl-mc/bus/dpio/qbman_private.h
new file mode 100644
index 0000000..042bc22
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/qbman_private.h
@@ -0,0 +1,173 @@
+/* Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*/
+
+/* Perform extra checking */
+#define QBMAN_CHECKING
+
+/* To maximise the amount of logic that is common between the Linux driver and
+ * other targets (such as the embedded MC firmware), we pivot here between the
+ * inclusion of two platform-specific headers.
+ *
+ * The first, qbman_sys_decl.h, includes any and all required system headers as
+ * well as providing any definitions for the purposes of compatibility. The
+ * second, qbman_sys.h, is where platform-specific routines go.
+ *
+ * The point of the split is that the platform-independent code (including this
+ * header) may depend on platform-specific declarations, yet other
+ * platform-specific routines may depend on platform-independent definitions.
+ */
+
+#include "qbman_sys_decl.h"
+
+#define QMAN_REV_4000   0x04000000
+#define QMAN_REV_4100   0x04010000
+#define QMAN_REV_4101   0x04010001
+
+/* When things go wrong, it is a convenient trick to insert a few FOO()
+ * statements in the code to trace progress. TODO: remove this once we are
+ * hacking the code less actively.
+ */
+#define FOO() fsl_os_print("FOO: %s:%d\n", __FILE__, __LINE__)
+
+/* Any time there is a register interface which we poll on, this provides a
+ * "break after x iterations" scheme for it. It's handy for debugging, eg.
+ * where you don't want millions of lines of log output from a polling loop
+ * that won't, because such things tend to drown out the earlier log output
+ * that might explain what caused the problem. (NB: put ";" after each macro!)
+ * TODO: we should probably remove this once we're done sanitising the
+ * simulator...
+ */
+#define DBG_POLL_START(loopvar) (loopvar = 1000)
+#define DBG_POLL_CHECK(loopvar) \
+	do {if (!(loopvar--)) BUG_ON(1); } while (0)
+
+/* For CCSR or portal-CINH registers that contain fields at arbitrary offsets
+ * and widths, these macro-generated encode/decode/isolate/remove inlines can
+ * be used.
+ *
+ * Eg. to "d"ecode a 14-bit field out of a register (into a "uint16_t" type),
+ * where the field is located 3 bits "up" from the least-significant bit of the
+ * register (ie. the field location within the 32-bit register corresponds to a
+ * mask of 0x0001fff8), you would do;
+ *                uint16_t field = d32_uint16_t(3, 14, reg_value);
+ *
+ * Or to "e"ncode a 1-bit boolean value (input type is "int", zero is FALSE,
+ * non-zero is TRUE, so must convert all non-zero inputs to 1, hence the "!!"
+ * operator) into a register at bit location 0x00080000 (19 bits "in" from the
+ * LS bit), do;
+ *                reg_value |= e32_int(19, 1, !!field);
+ *
+ * If you wish to read-modify-write a register, such that you leave the 14-bit
+ * field as-is but have all other fields set to zero, then "i"solate the 14-bit
+ * value using;
+ *                reg_value = i32_uint16_t(3, 14, reg_value);
+ *
+ * Alternatively, you could "r"emove the 1-bit boolean field (setting it to
+ * zero) but leaving all other fields as-is;
+ *                reg_val = r32_int(19, 1, reg_value);
+ *
+ */
+#define MAKE_MASK32(width) (width == 32 ? 0xffffffff : \
+				 (uint32_t)((1 << width) - 1))
+#define DECLARE_CODEC32(t) \
+static inline uint32_t e32_##t(uint32_t lsoffset, uint32_t width, t val) \
+{ \
+	BUG_ON(width > (sizeof(t) * 8)); \
+	return ((uint32_t)val & MAKE_MASK32(width)) << lsoffset; \
+} \
+static inline t d32_##t(uint32_t lsoffset, uint32_t width, uint32_t val) \
+{ \
+	BUG_ON(width > (sizeof(t) * 8)); \
+	return (t)((val >> lsoffset) & MAKE_MASK32(width)); \
+} \
+static inline uint32_t i32_##t(uint32_t lsoffset, uint32_t width, \
+				uint32_t val) \
+{ \
+	BUG_ON(width > (sizeof(t) * 8)); \
+	return e32_##t(lsoffset, width, d32_##t(lsoffset, width, val)); \
+} \
+static inline uint32_t r32_##t(uint32_t lsoffset, uint32_t width, \
+				uint32_t val) \
+{ \
+	BUG_ON(width > (sizeof(t) * 8)); \
+	return ~(MAKE_MASK32(width) << lsoffset) & val; \
+}
+DECLARE_CODEC32(uint32_t)
+DECLARE_CODEC32(uint16_t)
+DECLARE_CODEC32(uint8_t)
+DECLARE_CODEC32(int)
+
+	/*********************/
+	/* Debugging assists */
+	/*********************/
+
+static inline void __hexdump(unsigned long start, unsigned long end,
+			unsigned long p, size_t sz, const unsigned char *c)
+{
+	while (start < end) {
+		unsigned int pos = 0;
+		char buf[64];
+		int nl = 0;
+
+		pos += sprintf(buf + pos, "%08lx: ", start);
+		do {
+			if ((start < p) || (start >= (p + sz)))
+				pos += sprintf(buf + pos, "..");
+			else
+				pos += sprintf(buf + pos, "%02x", *(c++));
+			if (!(++start & 15)) {
+				buf[pos++] = '\n';
+				nl = 1;
+			} else {
+				nl = 0;
+				if (!(start & 1))
+					buf[pos++] = ' ';
+				if (!(start & 3))
+					buf[pos++] = ' ';
+			}
+		} while (start & 15);
+		if (!nl)
+			buf[pos++] = '\n';
+		buf[pos] = '\0';
+		pr_info("%s", buf);
+	}
+}
+static inline void hexdump(const void *ptr, size_t sz)
+{
+	unsigned long p = (unsigned long)ptr;
+	unsigned long start = p & ~(unsigned long)15;
+	unsigned long end = (p + sz + 15) & ~(unsigned long)15;
+	const unsigned char *c = ptr;
+
+	__hexdump(start, end, p, sz, c);
+}
+
+#include "qbman_sys.h"
diff --git a/drivers/staging/fsl-mc/bus/dpio/qbman_sys.h b/drivers/staging/fsl-mc/bus/dpio/qbman_sys.h
new file mode 100644
index 0000000..4849212
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/qbman_sys.h
@@ -0,0 +1,307 @@
+/* Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+/* qbman_sys_decl.h and qbman_sys.h are the two platform-specific files in the
+ * driver. They are only included via qbman_private.h, which is itself a
+ * platform-independent file and is included by all the other driver source.
+ *
+ * qbman_sys_decl.h is included prior to all other declarations and logic, and
+ * it exists to provide compatibility with any linux interfaces our
+ * single-source driver code is dependent on (eg. kmalloc). Ie. this file
+ * provides linux compatibility.
+ *
+ * This qbman_sys.h header, on the other hand, is included *after* any common
+ * and platform-neutral declarations and logic in qbman_private.h, and exists to
+ * implement any platform-specific logic of the qbman driver itself. Ie. it is
+ * *not* to provide linux compatibility.
+ */
+
+/* Trace the 3 different classes of read/write access to QBMan. #undef as
+ * required. */
+#undef QBMAN_CCSR_TRACE
+#undef QBMAN_CINH_TRACE
+#undef QBMAN_CENA_TRACE
+
+static inline void word_copy(void *d, const void *s, unsigned int cnt)
+{
+	uint32_t *dd = d;
+	const uint32_t *ss = s;
+
+	while (cnt--)
+		*(dd++) = *(ss++);
+}
+
+/* Currently, the CENA support code expects each 32-bit word to be written in
+ * host order, and these are converted to hardware (little-endian) order on
+ * command submission. However, 64-bit quantities are must be written (and read)
+ * as two 32-bit words with the least-significant word first, irrespective of
+ * host endianness. */
+static inline void u64_to_le32_copy(void *d, const uint64_t *s,
+					unsigned int cnt)
+{
+	uint32_t *dd = d;
+	const uint32_t *ss = (const uint32_t *)s;
+
+	while (cnt--) {
+		/* TBD: the toolchain was choking on the use of 64-bit types up
+		 * until recently so this works entirely with 32-bit variables.
+		 * When 64-bit types become usable again, investigate better
+		 * ways of doing this. */
+#if defined(__BIG_ENDIAN)
+		*(dd++) = ss[1];
+		*(dd++) = ss[0];
+		ss += 2;
+#else
+		*(dd++) = *(ss++);
+		*(dd++) = *(ss++);
+#endif
+	}
+}
+static inline void u64_from_le32_copy(uint64_t *d, const void *s,
+					unsigned int cnt)
+{
+	const uint32_t *ss = s;
+	uint32_t *dd = (uint32_t *)d;
+
+	while (cnt--) {
+#if defined(__BIG_ENDIAN)
+		dd[1] = *(ss++);
+		dd[0] = *(ss++);
+		dd += 2;
+#else
+		*(dd++) = *(ss++);
+		*(dd++) = *(ss++);
+#endif
+	}
+}
+
+/* Convert a host-native 32bit value into little endian */
+#if defined(__BIG_ENDIAN)
+static inline uint32_t make_le32(uint32_t val)
+{
+	return ((val & 0xff) << 24) | ((val & 0xff00) << 8) |
+		((val & 0xff0000) >> 8) | ((val & 0xff000000) >> 24);
+}
+static inline uint32_t make_le24(uint32_t val)
+{
+	return (((val & 0xff) << 16) | (val & 0xff00) |
+		((val & 0xff0000) >> 16));
+}
+#else
+#define make_le32(val) (val)
+#define make_le24(val) (val)
+#endif
+static inline void make_le32_n(uint32_t *val, unsigned int num)
+{
+	while (num--) {
+		*val = make_le32(*val);
+		val++;
+	}
+}
+
+	/******************/
+	/* Portal access  */
+	/******************/
+struct qbman_swp_sys {
+	/* On GPP, the sys support for qbman_swp is here. The CENA region isi
+	 * not an mmap() of the real portal registers, but an allocated
+	 * place-holder, because the actual writes/reads to/from the portal are
+	 * marshalled from these allocated areas using QBMan's "MC access
+	 * registers". CINH accesses are atomic so there's no need for a
+	 * place-holder. */
+	void *cena;
+	void __iomem *addr_cena;
+	void __iomem *addr_cinh;
+};
+
+/* P_OFFSET is (ACCESS_CMD,0,12) - offset within the portal
+ * C is (ACCESS_CMD,12,1) - is inhibited? (0==CENA, 1==CINH)
+ * SWP_IDX is (ACCESS_CMD,16,10) - Software portal index
+ * P is (ACCESS_CMD,28,1) - (0==special portal, 1==any portal)
+ * T is (ACCESS_CMD,29,1) - Command type (0==READ, 1==WRITE)
+ * E is (ACCESS_CMD,31,1) - Command execute (1 to issue, poll for 0==complete)
+ */
+
+static inline void qbman_cinh_write(struct qbman_swp_sys *s, uint32_t offset,
+				    uint32_t val)
+{
+
+	writel_relaxed(val, s->addr_cinh + offset);
+#ifdef QBMAN_CINH_TRACE
+	pr_info("qbman_cinh_write(%p:0x%03x) 0x%08x\n",
+		s->addr_cinh, offset, val);
+#endif
+}
+
+static inline uint32_t qbman_cinh_read(struct qbman_swp_sys *s, uint32_t offset)
+{
+	uint32_t reg = readl_relaxed(s->addr_cinh + offset);
+
+#ifdef QBMAN_CINH_TRACE
+	pr_info("qbman_cinh_read(%p:0x%03x) 0x%08x\n",
+		s->addr_cinh, offset, reg);
+#endif
+	return reg;
+}
+
+static inline void *qbman_cena_write_start(struct qbman_swp_sys *s,
+						uint32_t offset)
+{
+	void *shadow = s->cena + offset;
+
+#ifdef QBMAN_CENA_TRACE
+	pr_info("qbman_cena_write_start(%p:0x%03x) %p\n",
+		s->addr_cena, offset, shadow);
+#endif
+	BUG_ON(offset & 63);
+	dcbz(shadow);
+	return shadow;
+}
+
+static inline void qbman_cena_write_complete(struct qbman_swp_sys *s,
+						uint32_t offset, void *cmd)
+{
+	const uint32_t *shadow = cmd;
+	int loop;
+
+#ifdef QBMAN_CENA_TRACE
+	pr_info("qbman_cena_write_complete(%p:0x%03x) %p\n",
+		s->addr_cena, offset, shadow);
+	hexdump(cmd, 64);
+#endif
+	for (loop = 15; loop >= 1; loop--)
+		writel_relaxed(shadow[loop], s->addr_cena +
+					 offset + loop * 4);
+	lwsync();
+	writel_relaxed(shadow[0], s->addr_cena + offset);
+	dcbf(s->addr_cena + offset);
+}
+
+static inline void *qbman_cena_read(struct qbman_swp_sys *s, uint32_t offset)
+{
+	uint32_t *shadow = s->cena + offset;
+	unsigned int loop;
+
+#ifdef QBMAN_CENA_TRACE
+	pr_info("qbman_cena_read(%p:0x%03x) %p\n",
+		s->addr_cena, offset, shadow);
+#endif
+
+	for (loop = 0; loop < 16; loop++)
+		shadow[loop] = readl_relaxed(s->addr_cena + offset
+					+ loop * 4);
+#ifdef QBMAN_CENA_TRACE
+	hexdump(shadow, 64);
+#endif
+	return shadow;
+}
+
+static inline void qbman_cena_invalidate_prefetch(struct qbman_swp_sys *s,
+						  uint32_t offset)
+{
+	dcivac(s->addr_cena + offset);
+	prefetch_for_load(s->addr_cena + offset);
+}
+
+	/******************/
+	/* Portal support */
+	/******************/
+
+/* The SWP_CFG portal register is special, in that it is used by the
+ * platform-specific code rather than the platform-independent code in
+ * qbman_portal.c. So use of it is declared locally here. */
+#define QBMAN_CINH_SWP_CFG   0xd00
+
+/* For MC portal use, we always configure with
+ * DQRR_MF is (SWP_CFG,20,3) - DQRR max fill (<- 0x4)
+ * EST is (SWP_CFG,16,3) - EQCR_CI stashing threshold (<- 0x0)
+ * RPM is (SWP_CFG,12,2) - RCR production notification mode (<- 0x3)
+ * DCM is (SWP_CFG,10,2) - DQRR consumption notification mode (<- 0x2)
+ * EPM is (SWP_CFG,8,2) - EQCR production notification mode (<- 0x3)
+ * SD is (SWP_CFG,5,1) - memory stashing drop enable (<- FALSE)
+ * SP is (SWP_CFG,4,1) - memory stashing priority (<- TRUE)
+ * SE is (SWP_CFG,3,1) - memory stashing enable (<- 0x0)
+ * DP is (SWP_CFG,2,1) - dequeue stashing priority (<- TRUE)
+ * DE is (SWP_CFG,1,1) - dequeue stashing enable (<- 0x0)
+ * EP is (SWP_CFG,0,1) - EQCR_CI stashing priority (<- FALSE)
+ */
+static inline uint32_t qbman_set_swp_cfg(uint8_t max_fill, uint8_t wn,
+					uint8_t est, uint8_t rpm, uint8_t dcm,
+					uint8_t epm, int sd, int sp, int se,
+					int dp, int de, int ep)
+{
+	uint32_t reg;
+
+	reg = e32_uint8_t(20, (uint32_t)(3 + (max_fill >> 3)), max_fill) |
+		e32_uint8_t(16, 3, est) | e32_uint8_t(12, 2, rpm) |
+		e32_uint8_t(10, 2, dcm) | e32_uint8_t(8, 2, epm) |
+		e32_int(5, 1, sd) | e32_int(4, 1, sp) | e32_int(3, 1, se) |
+		e32_int(2, 1, dp) | e32_int(1, 1, de) | e32_int(0, 1, ep) |
+		e32_uint8_t(14, 1, wn);
+	return reg;
+}
+
+static inline int qbman_swp_sys_init(struct qbman_swp_sys *s,
+				     const struct qbman_swp_desc *d,
+				     uint8_t dqrr_size)
+{
+	uint32_t reg;
+
+	s->addr_cena = d->cena_bar;
+	s->addr_cinh = d->cinh_bar;
+	s->cena = (void *)get_zeroed_page(GFP_KERNEL);
+	if (!s->cena) {
+		pr_err("Could not allocate page for cena shadow\n");
+		return -1;
+	}
+
+#ifdef QBMAN_CHECKING
+	/* We should never be asked to initialise for a portal that isn't in
+	 * the power-on state. (Ie. don't forget to reset portals when they are
+	 * decommissioned!)
+	 */
+	reg = qbman_cinh_read(s, QBMAN_CINH_SWP_CFG);
+	BUG_ON(reg);
+#endif
+	reg = qbman_set_swp_cfg(dqrr_size, 0, 0, 3, 2, 3, 0, 1, 0, 1, 0, 0);
+	qbman_cinh_write(s, QBMAN_CINH_SWP_CFG, reg);
+	reg = qbman_cinh_read(s, QBMAN_CINH_SWP_CFG);
+	if (!reg) {
+		pr_err("The portal is not enabled!\n");
+		kfree(s->cena);
+		return -1;
+	}
+	return 0;
+}
+
+static inline void qbman_swp_sys_finish(struct qbman_swp_sys *s)
+{
+	free_page((unsigned long)s->cena);
+}
diff --git a/drivers/staging/fsl-mc/bus/dpio/qbman_sys_decl.h b/drivers/staging/fsl-mc/bus/dpio/qbman_sys_decl.h
new file mode 100644
index 0000000..5b3a224
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/qbman_sys_decl.h
@@ -0,0 +1,86 @@
+/* Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/io.h>
+#include <linux/dma-mapping.h>
+#include <linux/bootmem.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/memblock.h>
+#include <linux/completion.h>
+#include <linux/log2.h>
+#include <linux/types.h>
+#include <linux/ioctl.h>
+#include <linux/device.h>
+#include <linux/smp.h>
+#include <linux/vmalloc.h>
+#include "fsl_qbman_base.h"
+
+/* The platform-independent code shouldn't need endianness, except for
+ * weird/fast-path cases like qbman_result_has_token(), which needs to
+ * perform a passive and endianness-specific test on a read-only data structure
+ * very quickly. It's an exception, and this symbol is used for that case. */
+#if defined(__BIG_ENDIAN)
+#define DQRR_TOK_OFFSET 0
+#define QBMAN_RESULT_VERB_OFFSET_IN_MEM 24
+#define SCN_STATE_OFFSET_IN_MEM 8
+#define SCN_RID_OFFSET_IN_MEM 8
+#else
+#define DQRR_TOK_OFFSET 24
+#define QBMAN_RESULT_VERB_OFFSET_IN_MEM 0
+#define SCN_STATE_OFFSET_IN_MEM 16
+#define SCN_RID_OFFSET_IN_MEM 0
+#endif
+
+/* Similarly-named functions */
+#define upper32(a) upper_32_bits(a)
+#define lower32(a) lower_32_bits(a)
+
+	/****************/
+	/* arch assists */
+	/****************/
+
+#define dcbz(p) { asm volatile("dc zva, %0" : : "r" (p) : "memory"); }
+#define lwsync() { asm volatile("dmb st" : : : "memory"); }
+#define dcbf(p) { asm volatile("dc cvac, %0;" : : "r" (p) : "memory"); }
+#define dcivac(p) { asm volatile("dc ivac, %0" : : "r"(p) : "memory"); }
+static inline void prefetch_for_load(void *p)
+{
+	asm volatile("prfm pldl1keep, [%0, #64]" : : "r" (p));
+}
+static inline void prefetch_for_store(void *p)
+{
+	asm volatile("prfm pstl1keep, [%0, #64]" : : "r" (p));
+}
diff --git a/drivers/staging/fsl-mc/bus/dpio/qbman_test.c b/drivers/staging/fsl-mc/bus/dpio/qbman_test.c
new file mode 100644
index 0000000..28396e7
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/dpio/qbman_test.c
@@ -0,0 +1,664 @@
+/* Copyright (C) 2014 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <linux/kernel.h>
+#include <linux/io.h>
+#include <linux/module.h>
+
+#include "qbman_private.h"
+#include "fsl_qbman_portal.h"
+#include "qbman_debug.h"
+#include "../../include/fsl_dpaa2_fd.h"
+
+#define QBMAN_SWP_CENA_BASE 0x818000000
+#define QBMAN_SWP_CINH_BASE 0x81c000000
+
+#define QBMAN_PORTAL_IDX 2
+#define QBMAN_TEST_FQID 19
+#define QBMAN_TEST_BPID 23
+#define QBMAN_USE_QD
+#ifdef QBMAN_USE_QD
+#define QBMAN_TEST_QDID 1
+#endif
+#define QBMAN_TEST_LFQID 0xf00010
+
+#define NUM_EQ_FRAME 10
+#define NUM_DQ_FRAME 10
+#define NUM_DQ_IN_DQRR 5
+#define NUM_DQ_IN_MEM   (NUM_DQ_FRAME - NUM_DQ_IN_DQRR)
+
+static struct qbman_swp *swp;
+static struct qbman_eq_desc eqdesc;
+static struct qbman_pull_desc pulldesc;
+static struct qbman_release_desc releasedesc;
+static struct qbman_eq_response eq_storage[1];
+static struct dpaa2_dq dq_storage[NUM_DQ_IN_MEM] __aligned(64);
+static dma_addr_t eq_storage_phys;
+static dma_addr_t dq_storage_phys;
+
+/* FQ ctx attribute values for the test code. */
+#define FQCTX_HI 0xabbaf00d
+#define FQCTX_LO 0x98765432
+#define FQ_VFQID 0x123456
+
+/* Sample frame descriptor */
+static struct qbman_fd_simple fd = {
+	.addr_lo = 0xbabaf33d,
+	.addr_hi = 0x01234567,
+	.len = 0x7777,
+	.frc = 0xdeadbeef,
+	.flc_lo = 0xcafecafe,
+	.flc_hi = 0xbeadabba
+};
+
+static void fd_inc(struct qbman_fd_simple *_fd)
+{
+	_fd->addr_lo += _fd->len;
+	_fd->flc_lo += 0x100;
+	_fd->frc += 0x10;
+}
+
+static int fd_cmp(struct qbman_fd *fda, struct qbman_fd *fdb)
+{
+	int i;
+
+	for (i = 0; i < 8; i++)
+		if (fda->words[i] - fdb->words[i])
+			return 1;
+	return 0;
+}
+
+struct qbman_fd fd_eq[NUM_EQ_FRAME];
+struct qbman_fd fd_dq[NUM_DQ_FRAME];
+
+/* "Buffers" to be released (and storage for buffers to be acquired) */
+static uint64_t rbufs[320];
+static uint64_t abufs[320];
+
+static void do_enqueue(struct qbman_swp *swp)
+{
+	int i, j, ret;
+
+#ifdef QBMAN_USE_QD
+	pr_info("*****QBMan_test: Enqueue %d frames to QD %d\n",
+					NUM_EQ_FRAME, QBMAN_TEST_QDID);
+#else
+	pr_info("*****QBMan_test: Enqueue %d frames to FQ %d\n",
+					NUM_EQ_FRAME, QBMAN_TEST_FQID);
+#endif
+	for (i = 0; i < NUM_EQ_FRAME; i++) {
+		/*********************************/
+		/* Prepare a enqueue descriptor */
+		/*********************************/
+		memset(eq_storage, 0, sizeof(eq_storage));
+		eq_storage_phys = virt_to_phys(eq_storage);
+		qbman_eq_desc_clear(&eqdesc);
+		qbman_eq_desc_set_no_orp(&eqdesc, 0);
+		qbman_eq_desc_set_response(&eqdesc, eq_storage_phys, 0);
+		qbman_eq_desc_set_token(&eqdesc, 0x99);
+#ifdef QBMAN_USE_QD
+		/**********************************/
+		/* Prepare a Queueing Destination */
+		/**********************************/
+		qbman_eq_desc_set_qd(&eqdesc, QBMAN_TEST_QDID, 0, 3);
+#else
+		qbman_eq_desc_set_fq(&eqdesc, QBMAN_TEST_FQID);
+#endif
+
+		/******************/
+		/* Try an enqueue */
+		/******************/
+		ret = qbman_swp_enqueue(swp, &eqdesc,
+					(const struct qbman_fd *)&fd);
+		BUG_ON(ret);
+		for (j = 0; j < 8; j++)
+			fd_eq[i].words[j] = *((uint32_t *)&fd + j);
+		fd_inc(&fd);
+	}
+}
+
+static void do_push_dequeue(struct qbman_swp *swp)
+{
+	int i, j;
+	const struct dpaa2_dq *dq_storage1;
+	const struct qbman_fd *__fd;
+	int loopvar;
+
+	pr_info("*****QBMan_test: Start push dequeue\n");
+	for (i = 0; i < NUM_DQ_FRAME; i++) {
+		DBG_POLL_START(loopvar);
+		do {
+			DBG_POLL_CHECK(loopvar);
+			dq_storage1 = qbman_swp_dqrr_next(swp);
+		} while (!dq_storage1);
+		if (dq_storage1) {
+			__fd = (const struct qbman_fd *)
+					dpaa2_dq_fd(dq_storage1);
+			for (j = 0; j < 8; j++)
+				fd_dq[i].words[j] = __fd->words[j];
+			if (fd_cmp(&fd_eq[i], &fd_dq[i])) {
+				pr_info("enqueue FD is\n");
+				hexdump(&fd_eq[i], 32);
+				pr_info("dequeue FD is\n");
+				hexdump(&fd_dq[i], 32);
+			}
+			qbman_swp_dqrr_consume(swp, dq_storage1);
+		} else {
+			pr_info("The push dequeue fails\n");
+		}
+	}
+}
+
+static void do_pull_dequeue(struct qbman_swp *swp)
+{
+	int i, j, ret;
+	const struct dpaa2_dq *dq_storage1;
+	const struct qbman_fd *__fd;
+	int loopvar;
+
+	pr_info("*****QBMan_test: Dequeue %d frames with dq entry in DQRR\n",
+							NUM_DQ_IN_DQRR);
+	for (i = 0; i < NUM_DQ_IN_DQRR; i++) {
+		qbman_pull_desc_clear(&pulldesc);
+		qbman_pull_desc_set_storage(&pulldesc, NULL, 0, 0);
+		qbman_pull_desc_set_numframes(&pulldesc, 1);
+		qbman_pull_desc_set_fq(&pulldesc, QBMAN_TEST_FQID);
+
+		ret = qbman_swp_pull(swp, &pulldesc);
+		BUG_ON(ret);
+		DBG_POLL_START(loopvar);
+		do {
+			DBG_POLL_CHECK(loopvar);
+			dq_storage1 = qbman_swp_dqrr_next(swp);
+		} while (!dq_storage1);
+
+		if (dq_storage1) {
+			__fd = (const struct qbman_fd *)
+					dpaa2_dq_fd(dq_storage1);
+			for (j = 0; j < 8; j++)
+				fd_dq[i].words[j] = __fd->words[j];
+			if (fd_cmp(&fd_eq[i], &fd_dq[i])) {
+				pr_info("enqueue FD is\n");
+				hexdump(&fd_eq[i], 32);
+				pr_info("dequeue FD is\n");
+				hexdump(&fd_dq[i], 32);
+			}
+			qbman_swp_dqrr_consume(swp, dq_storage1);
+		} else {
+			pr_info("Dequeue with dq entry in DQRR fails\n");
+		}
+	}
+
+	pr_info("*****QBMan_test: Dequeue %d frames with dq entry in memory\n",
+								NUM_DQ_IN_MEM);
+	for (i = 0; i < NUM_DQ_IN_MEM; i++) {
+		dq_storage_phys = virt_to_phys(&dq_storage[i]);
+		qbman_pull_desc_clear(&pulldesc);
+		qbman_pull_desc_set_storage(&pulldesc, &dq_storage[i],
+						dq_storage_phys, 1);
+		qbman_pull_desc_set_numframes(&pulldesc, 1);
+		qbman_pull_desc_set_fq(&pulldesc, QBMAN_TEST_FQID);
+		ret = qbman_swp_pull(swp, &pulldesc);
+		BUG_ON(ret);
+
+		DBG_POLL_START(loopvar);
+		do {
+			DBG_POLL_CHECK(loopvar);
+			ret = qbman_result_has_new_result(swp,
+							    &dq_storage[i]);
+		} while (!ret);
+
+		if (ret) {
+			for (j = 0; j < 8; j++)
+				fd_dq[i + NUM_DQ_IN_DQRR].words[j] =
+				dq_storage[i].dont_manipulate_directly[j + 8];
+			j = i + NUM_DQ_IN_DQRR;
+			if (fd_cmp(&fd_eq[j], &fd_dq[j])) {
+				pr_info("enqueue FD is\n");
+				hexdump(&fd_eq[i + NUM_DQ_IN_DQRR], 32);
+				pr_info("dequeue FD is\n");
+				hexdump(&fd_dq[i + NUM_DQ_IN_DQRR], 32);
+				hexdump(&dq_storage[i], 64);
+			}
+		} else {
+			pr_info("Dequeue with dq entry in memory fails\n");
+		}
+	}
+}
+
+static void release_buffer(struct qbman_swp *swp, unsigned int num)
+{
+	int ret;
+	unsigned int i, j;
+
+	qbman_release_desc_clear(&releasedesc);
+	qbman_release_desc_set_bpid(&releasedesc, QBMAN_TEST_BPID);
+	pr_info("*****QBMan_test: Release %d buffers to BP %d\n",
+					num, QBMAN_TEST_BPID);
+	for (i = 0; i < (num / 7 + 1); i++) {
+		j = ((num - i * 7) > 7) ? 7 : (num - i * 7);
+		ret = qbman_swp_release(swp, &releasedesc, &rbufs[i * 7], j);
+		BUG_ON(ret);
+	}
+}
+
+static void acquire_buffer(struct qbman_swp *swp, unsigned int num)
+{
+	int ret;
+	unsigned int i, j;
+
+	pr_info("*****QBMan_test: Acquire %d buffers from BP %d\n",
+					num, QBMAN_TEST_BPID);
+
+	for (i = 0; i < (num / 7 + 1); i++) {
+		j = ((num - i * 7) > 7) ? 7 : (num - i * 7);
+		ret = qbman_swp_acquire(swp, QBMAN_TEST_BPID, &abufs[i * 7], j);
+		BUG_ON(ret != j);
+	}
+}
+
+static void buffer_pool_test(struct qbman_swp *swp)
+{
+	struct qbman_attr info;
+	struct dpaa2_dq *bpscn_message;
+	dma_addr_t bpscn_phys;
+	uint64_t bpscn_ctx;
+	uint64_t ctx = 0xbbccddaadeadbeefull;
+	int i, ret;
+	uint32_t hw_targ;
+
+	pr_info("*****QBMan_test: test buffer pool management\n");
+	ret = qbman_bp_query(swp, QBMAN_TEST_BPID, &info);
+	qbman_bp_attr_get_bpscn_addr(&info, &bpscn_phys);
+	pr_info("The bpscn is %llx, info_phys is %llx\n", bpscn_phys,
+			virt_to_phys(&info));
+	bpscn_message = phys_to_virt(bpscn_phys);
+
+	for (i = 0; i < 320; i++)
+		rbufs[i] = 0xf00dabba01234567ull + i * 0x40;
+
+	release_buffer(swp, 320);
+
+	pr_info("QBMan_test: query the buffer pool\n");
+	qbman_bp_query(swp, QBMAN_TEST_BPID, &info);
+	hexdump(&info, 64);
+	qbman_bp_attr_get_hw_targ(&info, &hw_targ);
+	pr_info("hw_targ is %d\n", hw_targ);
+
+	/* Acquire buffers to trigger BPSCN */
+	acquire_buffer(swp, 300);
+	/* BPSCN should be written to the memory */
+	qbman_bp_query(swp, QBMAN_TEST_BPID, &info);
+	hexdump(&info, 64);
+	hexdump(bpscn_message, 64);
+	BUG_ON(!qbman_result_is_BPSCN(bpscn_message));
+	/* There should be free buffers in the pool */
+	BUG_ON(!(qbman_result_bpscn_has_free_bufs(bpscn_message)));
+	/* Buffer pool is depleted */
+	BUG_ON(!qbman_result_bpscn_is_depleted(bpscn_message));
+	/* The ctx should match */
+	bpscn_ctx = qbman_result_bpscn_ctx(bpscn_message);
+	pr_info("BPSCN test: ctx %llx, bpscn_ctx %llx\n", ctx, bpscn_ctx);
+	BUG_ON(ctx != bpscn_ctx);
+	memset(bpscn_message, 0, sizeof(struct dpaa2_dq));
+
+	/* Re-seed the buffer pool to trigger BPSCN */
+	release_buffer(swp, 240);
+	/* BPSCN should be written to the memory */
+	BUG_ON(!qbman_result_is_BPSCN(bpscn_message));
+	/* There should be free buffers in the pool */
+	BUG_ON(!(qbman_result_bpscn_has_free_bufs(bpscn_message)));
+	/* Buffer pool is not depleted */
+	BUG_ON(qbman_result_bpscn_is_depleted(bpscn_message));
+	memset(bpscn_message, 0, sizeof(struct dpaa2_dq));
+
+	acquire_buffer(swp, 260);
+	/* BPSCN should be written to the memory */
+	BUG_ON(!qbman_result_is_BPSCN(bpscn_message));
+	/* There should be free buffers in the pool while BPSCN generated */
+	BUG_ON(!(qbman_result_bpscn_has_free_bufs(bpscn_message)));
+	/* Buffer pool is depletion */
+	BUG_ON(!qbman_result_bpscn_is_depleted(bpscn_message));
+}
+
+static void ceetm_test(struct qbman_swp *swp)
+{
+	int i, j, ret;
+
+	qbman_eq_desc_clear(&eqdesc);
+	qbman_eq_desc_set_no_orp(&eqdesc, 0);
+	qbman_eq_desc_set_fq(&eqdesc, QBMAN_TEST_LFQID);
+	pr_info("*****QBMan_test: Enqueue to LFQID %x\n",
+						QBMAN_TEST_LFQID);
+	for (i = 0; i < NUM_EQ_FRAME; i++) {
+		ret = qbman_swp_enqueue(swp, &eqdesc,
+					(const struct qbman_fd *)&fd);
+		BUG_ON(ret);
+		for (j = 0; j < 8; j++)
+			fd_eq[i].words[j] = *((uint32_t *)&fd + j);
+		fd_inc(&fd);
+	}
+}
+
+int qbman_test(void)
+{
+	struct qbman_swp_desc pd;
+	uint32_t reg;
+
+	pd.cena_bar = ioremap_cache_ns(QBMAN_SWP_CENA_BASE +
+				QBMAN_PORTAL_IDX * 0x10000, 0x10000);
+	pd.cinh_bar = ioremap(QBMAN_SWP_CINH_BASE +
+				QBMAN_PORTAL_IDX * 0x10000, 0x10000);
+
+	/* Detect whether the mc image is the test image with GPP setup */
+	reg = readl_relaxed(pd.cena_bar + 0x4);
+	if (reg != 0xdeadbeef) {
+		pr_err("The MC image doesn't have GPP test setup, stop!\n");
+		iounmap(pd.cena_bar);
+		iounmap(pd.cinh_bar);
+		return -1;
+	}
+
+	pr_info("*****QBMan_test: Init QBMan SWP %d\n", QBMAN_PORTAL_IDX);
+	swp = qbman_swp_init(&pd);
+	if (!swp) {
+		iounmap(pd.cena_bar);
+		iounmap(pd.cinh_bar);
+		return -1;
+	}
+
+	/*******************/
+	/* Enqueue frames  */
+	/*******************/
+	do_enqueue(swp);
+
+	/*******************/
+	/* Do pull dequeue */
+	/*******************/
+	do_pull_dequeue(swp);
+
+	/*******************/
+	/* Enqueue frames  */
+	/*******************/
+	qbman_swp_push_set(swp, 0, 1);
+	qbman_swp_fq_schedule(swp, QBMAN_TEST_FQID);
+	do_enqueue(swp);
+
+	/*******************/
+	/* Do push dequeue */
+	/*******************/
+	do_push_dequeue(swp);
+
+	/**************************/
+	/* Test buffer pool funcs */
+	/**************************/
+	buffer_pool_test(swp);
+
+	/******************/
+	/* CEETM test     */
+	/******************/
+	ceetm_test(swp);
+
+	qbman_swp_finish(swp);
+	pr_info("*****QBMan_test: Kernel test Passed\n");
+	return 0;
+}
+
+/* user-space test-case, definitions:
+ *
+ * 1 portal only, using portal index 3.
+ */
+
+#include <linux/uaccess.h>
+#include <linux/ioctl.h>
+#include <linux/miscdevice.h>
+#include <linux/fs.h>
+#include <linux/cdev.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+
+#define QBMAN_TEST_US_SWP 3 /* portal index for user space */
+
+#define QBMAN_TEST_MAGIC 'q'
+struct qbman_test_swp_ioctl {
+	unsigned long portal1_cinh;
+	unsigned long portal1_cena;
+};
+struct qbman_test_dma_ioctl {
+	unsigned long ptr;
+	uint64_t phys_addr;
+};
+
+struct qbman_test_priv {
+	int has_swp_map;
+	int has_dma_map;
+	unsigned long pgoff;
+};
+
+#define QBMAN_TEST_SWP_MAP \
+	_IOR(QBMAN_TEST_MAGIC, 0x01, struct qbman_test_swp_ioctl)
+#define QBMAN_TEST_SWP_UNMAP \
+	_IOR(QBMAN_TEST_MAGIC, 0x02, struct qbman_test_swp_ioctl)
+#define QBMAN_TEST_DMA_MAP \
+	_IOR(QBMAN_TEST_MAGIC, 0x03, struct qbman_test_dma_ioctl)
+#define QBMAN_TEST_DMA_UNMAP \
+	_IOR(QBMAN_TEST_MAGIC, 0x04, struct qbman_test_dma_ioctl)
+
+#define TEST_PORTAL1_CENA_PGOFF ((QBMAN_SWP_CENA_BASE + QBMAN_TEST_US_SWP * \
+						0x10000) >> PAGE_SHIFT)
+#define TEST_PORTAL1_CINH_PGOFF ((QBMAN_SWP_CINH_BASE + QBMAN_TEST_US_SWP * \
+						0x10000) >> PAGE_SHIFT)
+
+static int qbman_test_open(struct inode *inode, struct file *filp)
+{
+	struct qbman_test_priv *priv;
+
+	priv = kmalloc(sizeof(struct qbman_test_priv), GFP_KERNEL);
+	if (!priv)
+		return -EIO;
+	filp->private_data = priv;
+	priv->has_swp_map = 0;
+	priv->has_dma_map = 0;
+	priv->pgoff = 0;
+	return 0;
+}
+
+static int qbman_test_mmap(struct file *filp, struct vm_area_struct *vma)
+{
+	int ret;
+	struct qbman_test_priv *priv = filp->private_data;
+
+	BUG_ON(!priv);
+
+	if (vma->vm_pgoff == TEST_PORTAL1_CINH_PGOFF)
+		vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
+	else if (vma->vm_pgoff == TEST_PORTAL1_CENA_PGOFF)
+		vma->vm_page_prot = pgprot_cached_ns(vma->vm_page_prot);
+	else if (vma->vm_pgoff == priv->pgoff)
+		vma->vm_page_prot = pgprot_cached(vma->vm_page_prot);
+	else {
+		pr_err("Damn, unrecognised pg_off!!\n");
+		return -EINVAL;
+	}
+	ret = remap_pfn_range(vma, vma->vm_start, vma->vm_pgoff,
+				      vma->vm_end - vma->vm_start,
+				      vma->vm_page_prot);
+	return ret;
+}
+
+static long qbman_test_ioctl(struct file *fp, unsigned int cmd,
+				unsigned long arg)
+{
+	void __user *a = (void __user *)arg;
+	unsigned long longret, populate;
+	int ret = 0;
+	struct qbman_test_priv *priv = fp->private_data;
+
+	BUG_ON(!priv);
+
+	switch (cmd) {
+	case QBMAN_TEST_SWP_MAP:
+	{
+		struct qbman_test_swp_ioctl params;
+
+		if (priv->has_swp_map)
+			return -EINVAL;
+		down_write(&current->mm->mmap_sem);
+		/* Map portal1 CINH */
+		longret = do_mmap_pgoff(fp, PAGE_SIZE, 0x10000,
+				PROT_READ | PROT_WRITE, MAP_SHARED,
+				TEST_PORTAL1_CINH_PGOFF, &populate);
+		if (longret & ~PAGE_MASK) {
+			ret = (int)longret;
+			goto out;
+		}
+		params.portal1_cinh = longret;
+		/* Map portal1 CENA */
+		longret = do_mmap_pgoff(fp, PAGE_SIZE, 0x10000,
+				PROT_READ | PROT_WRITE, MAP_SHARED,
+				TEST_PORTAL1_CENA_PGOFF, &populate);
+		if (longret & ~PAGE_MASK) {
+			ret = (int)longret;
+			goto out;
+		}
+		params.portal1_cena = longret;
+		priv->has_swp_map = 1;
+out:
+		up_write(&current->mm->mmap_sem);
+		if (!ret && copy_to_user(a, &params, sizeof(params)))
+			return -EFAULT;
+		return ret;
+	}
+	case QBMAN_TEST_SWP_UNMAP:
+	{
+		struct qbman_test_swp_ioctl params;
+
+		if (!priv->has_swp_map)
+			return -EINVAL;
+
+		if (copy_from_user(&params, a, sizeof(params)))
+			return -EFAULT;
+		down_write(&current->mm->mmap_sem);
+		do_munmap(current->mm, params.portal1_cena, 0x10000);
+		do_munmap(current->mm, params.portal1_cinh, 0x10000);
+		up_write(&current->mm->mmap_sem);
+		priv->has_swp_map = 0;
+		return 0;
+	}
+	case QBMAN_TEST_DMA_MAP:
+	{
+		struct qbman_test_dma_ioctl params;
+		void *vaddr;
+
+		if (priv->has_dma_map)
+			return -EINVAL;
+		vaddr = (void *)get_zeroed_page(GFP_KERNEL);
+		params.phys_addr = virt_to_phys(vaddr);
+		priv->pgoff = (unsigned long)params.phys_addr >> PAGE_SHIFT;
+		down_write(&current->mm->mmap_sem);
+		longret = do_mmap_pgoff(fp, PAGE_SIZE, PAGE_SIZE,
+				PROT_READ | PROT_WRITE, MAP_SHARED,
+				priv->pgoff, &populate);
+		if (longret & ~PAGE_MASK) {
+			ret = (int)longret;
+			return ret;
+		}
+		params.ptr = longret;
+		priv->has_dma_map = 1;
+		up_write(&current->mm->mmap_sem);
+		if (copy_to_user(a, &params, sizeof(params)))
+			return -EFAULT;
+		return 0;
+	}
+	case QBMAN_TEST_DMA_UNMAP:
+	{
+		struct qbman_test_dma_ioctl params;
+
+		if (!priv->has_dma_map)
+			return -EINVAL;
+		if (copy_from_user(&params, a, sizeof(params)))
+			return -EFAULT;
+		down_write(&current->mm->mmap_sem);
+		do_munmap(current->mm, params.ptr, PAGE_SIZE);
+		up_write(&current->mm->mmap_sem);
+		free_page((unsigned long)phys_to_virt(params.phys_addr));
+		priv->has_dma_map = 0;
+		return 0;
+	}
+	default:
+		pr_err("Bad ioctl cmd!\n");
+	}
+	return -EINVAL;
+}
+
+static const struct file_operations qbman_fops = {
+	.open		   = qbman_test_open,
+	.mmap		   = qbman_test_mmap,
+	.unlocked_ioctl	   = qbman_test_ioctl
+};
+
+static struct miscdevice qbman_miscdev = {
+	.name = "qbman-test",
+	.fops = &qbman_fops,
+	.minor = MISC_DYNAMIC_MINOR,
+};
+
+static int qbman_miscdev_init;
+
+static int test_init(void)
+{
+	int ret = qbman_test();
+
+	if (!ret) {
+		/* MC image supports the test cases, so instantiate the
+		 * character devic that the user-space test case will use to do
+		 * its memory mappings. */
+		ret = misc_register(&qbman_miscdev);
+		if (ret) {
+			pr_err("qbman-test: failed to register misc device\n");
+			return ret;
+		}
+		pr_info("qbman-test: misc device registered!\n");
+		qbman_miscdev_init = 1;
+	}
+	return 0;
+}
+
+static void test_exit(void)
+{
+	if (qbman_miscdev_init) {
+		misc_deregister(&qbman_miscdev);
+		qbman_miscdev_init = 0;
+	}
+}
+
+module_init(test_init);
+module_exit(test_exit);
diff --git a/drivers/staging/fsl-mc/bus/dpmcp-cmd.h b/drivers/staging/fsl-mc/bus/dpmcp-cmd.h
index 57f326b..77cf084 100644
--- a/drivers/staging/fsl-mc/bus/dpmcp-cmd.h
+++ b/drivers/staging/fsl-mc/bus/dpmcp-cmd.h
@@ -1,4 +1,4 @@
-/* Copyright 2013-2015 Freescale Semiconductor Inc.
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -32,105 +32,28 @@
 #ifndef _FSL_DPMCP_CMD_H
 #define _FSL_DPMCP_CMD_H
 
-/* DPMCP Version */
-#define DPMCP_VER_MAJOR				2
-#define DPMCP_VER_MINOR				0
+/* Minimal supported DPMCP Version */
+#define DPMCP_MIN_VER_MAJOR				3
+#define DPMCP_MIN_VER_MINOR				0
+#define DPMCP_CMD_BASE_VERSION				1
+#define DPMCP_CMD_ID_OFFSET				4
 
 /* Command IDs */
-#define DPMCP_CMDID_CLOSE				0x800
-#define DPMCP_CMDID_OPEN				0x80b
-#define DPMCP_CMDID_CREATE				0x90b
-#define DPMCP_CMDID_DESTROY				0x900
-
-#define DPMCP_CMDID_GET_ATTR				0x004
-#define DPMCP_CMDID_RESET				0x005
-
-#define DPMCP_CMDID_SET_IRQ				0x010
-#define DPMCP_CMDID_GET_IRQ				0x011
-#define DPMCP_CMDID_SET_IRQ_ENABLE			0x012
-#define DPMCP_CMDID_GET_IRQ_ENABLE			0x013
-#define DPMCP_CMDID_SET_IRQ_MASK			0x014
-#define DPMCP_CMDID_GET_IRQ_MASK			0x015
-#define DPMCP_CMDID_GET_IRQ_STATUS			0x016
-#define DPMCP_CMDID_CLEAR_IRQ_STATUS			0x017
-
-/*                cmd, param, offset, width, type, arg_name */
-#define DPMCP_CMD_CREATE(cmd, cfg) \
-	MC_CMD_OP(cmd, 0, 0,  32, int,      cfg->portal_id)
-
-/*                cmd, param, offset, width, type, arg_name */
-#define DPMCP_CMD_SET_IRQ(cmd, irq_index, irq_addr, irq_val, user_irq_id) \
-do { \
-	MC_CMD_OP(cmd, 0, 0,  8,  uint8_t,  irq_index);\
-	MC_CMD_OP(cmd, 0, 32, 32, uint32_t, irq_val);\
-	MC_CMD_OP(cmd, 1, 0,  64, uint64_t, irq_addr); \
-	MC_CMD_OP(cmd, 2, 0,  32, int,	    user_irq_id); \
-} while (0)
-
-/*                cmd, param, offset, width, type, arg_name */
-#define DPMCP_CMD_GET_IRQ(cmd, irq_index) \
-	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index)
-
-/*                cmd, param, offset, width, type, arg_name */
-#define DPMCP_RSP_GET_IRQ(cmd, type, irq_addr, irq_val, user_irq_id) \
-do { \
-	MC_RSP_OP(cmd, 0, 0,  32, uint32_t, irq_val); \
-	MC_RSP_OP(cmd, 1, 0,  64, uint64_t, irq_addr); \
-	MC_RSP_OP(cmd, 2, 0,  32, int,	    user_irq_id); \
-	MC_RSP_OP(cmd, 2, 32, 32, int,	    type); \
-} while (0)
-
-/*                cmd, param, offset, width, type, arg_name */
-#define DPMCP_CMD_SET_IRQ_ENABLE(cmd, irq_index, en) \
-do { \
-	MC_CMD_OP(cmd, 0, 0,  8,  uint8_t,  en); \
-	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index);\
-} while (0)
-
-/*                cmd, param, offset, width, type, arg_name */
-#define DPMCP_CMD_GET_IRQ_ENABLE(cmd, irq_index) \
-	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index)
-
-/*                cmd, param, offset, width, type, arg_name */
-#define DPMCP_RSP_GET_IRQ_ENABLE(cmd, en) \
-	MC_RSP_OP(cmd, 0, 0,  8,  uint8_t,  en)
-
-/*                cmd, param, offset, width, type, arg_name */
-#define DPMCP_CMD_SET_IRQ_MASK(cmd, irq_index, mask) \
-do { \
-	MC_CMD_OP(cmd, 0, 0,  32, uint32_t, mask);\
-	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index);\
-} while (0)
-
-/*                cmd, param, offset, width, type, arg_name */
-#define DPMCP_CMD_GET_IRQ_MASK(cmd, irq_index) \
-	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index)
-
-/*                cmd, param, offset, width, type, arg_name */
-#define DPMCP_RSP_GET_IRQ_MASK(cmd, mask) \
-	MC_RSP_OP(cmd, 0, 0,  32, uint32_t, mask)
-
-/*                cmd, param, offset, width, type, arg_name */
-#define DPMCP_CMD_GET_IRQ_STATUS(cmd, irq_index) \
-	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index)
-
-/*                cmd, param, offset, width, type, arg_name */
-#define DPMCP_RSP_GET_IRQ_STATUS(cmd, status) \
-	MC_RSP_OP(cmd, 0, 0,  32, uint32_t, status)
-
-/*                cmd, param, offset, width, type, arg_name */
-#define DPMCP_CMD_CLEAR_IRQ_STATUS(cmd, irq_index, status) \
-do { \
-	MC_CMD_OP(cmd, 0, 0,  32, uint32_t, status); \
-	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index);\
-} while (0)
-
-/*                cmd, param, offset, width, type,	arg_name */
-#define DPMCP_RSP_GET_ATTRIBUTES(cmd, attr) \
-do { \
-	MC_RSP_OP(cmd, 0, 32, 32, int,	    attr->id);\
-	MC_RSP_OP(cmd, 1, 0,  16, uint16_t, attr->version.major);\
-	MC_RSP_OP(cmd, 1, 16, 16, uint16_t, attr->version.minor);\
-} while (0)
+#define DPMCP_CMDID_CLOSE                               ((0x800 << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
+#define DPMCP_CMDID_OPEN                                ((0x80b << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
+#define DPMCP_CMDID_CREATE                              ((0x90b << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
+#define DPMCP_CMDID_DESTROY                             ((0x98b << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
+#define DPMCP_CMDID_GET_API_VERSION                     ((0xa0b << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
+
+#define DPMCP_CMDID_GET_ATTR                            ((0x004 << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
+#define DPMCP_CMDID_RESET                               ((0x005 << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
+
+#define DPMCP_CMDID_SET_IRQ                             ((0x010 << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
+#define DPMCP_CMDID_GET_IRQ                             ((0x011 << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
+#define DPMCP_CMDID_SET_IRQ_ENABLE                      ((0x012 << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
+#define DPMCP_CMDID_GET_IRQ_ENABLE                      ((0x013 << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
+#define DPMCP_CMDID_SET_IRQ_MASK                        ((0x014 << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
+#define DPMCP_CMDID_GET_IRQ_MASK                        ((0x015 << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
+#define DPMCP_CMDID_GET_IRQ_STATUS                      ((0x016 << DPMCP_CMD_ID_OFFSET) | DPMCP_CMD_BASE_VERSION)
 
 #endif /* _FSL_DPMCP_CMD_H */
diff --git a/drivers/staging/fsl-mc/bus/dpmcp.c b/drivers/staging/fsl-mc/bus/dpmcp.c
index 6b9da5b..28beb29 100644
--- a/drivers/staging/fsl-mc/bus/dpmcp.c
+++ b/drivers/staging/fsl-mc/bus/dpmcp.c
@@ -1,4 +1,4 @@
-/* Copyright 2013-2015 Freescale Semiconductor Inc.
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -34,14 +34,18 @@
 #include "dpmcp.h"
 #include "dpmcp-cmd.h"
 
-int dpmcp_open(struct fsl_mc_io *mc_io, int dpmcp_id, uint16_t *token)
+int dpmcp_open(struct fsl_mc_io *mc_io,
+	       uint32_t cmd_flags,
+	       int dpmcp_id,
+	       uint16_t *token)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_OPEN,
-					  MC_CMD_PRI_LOW, 0);
+					  cmd_flags,
+					  0);
 	cmd.params[0] |= mc_enc(0, 32, dpmcp_id);
 
 	/* send command to mc*/
@@ -50,17 +54,20 @@ int dpmcp_open(struct fsl_mc_io *mc_io, int dpmcp_id, uint16_t *token)
 		return err;
 
 	/* retrieve response parameters */
-	*token = MC_CMD_HDR_READ_TOKEN(cmd.header);
+	*token = get_mc_cmd_hdr_token(cmd.header);
 
 	return err;
 }
 
-int dpmcp_close(struct fsl_mc_io *mc_io, uint16_t token)
+int dpmcp_close(struct fsl_mc_io *mc_io,
+		uint32_t cmd_flags,
+		uint16_t token)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
-	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_CLOSE, MC_CMD_PRI_HIGH,
+	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_CLOSE,
+					  cmd_flags,
 					  token);
 
 	/* send command to mc*/
@@ -68,15 +75,17 @@ int dpmcp_close(struct fsl_mc_io *mc_io, uint16_t token)
 }
 
 int dpmcp_create(struct fsl_mc_io *mc_io,
+		 uint16_t dprc_token,
+		 uint32_t cmd_flags,
 		 const struct dpmcp_cfg *cfg,
-		uint16_t *token)
+		 uint32_t *object_id)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_CREATE,
-					  MC_CMD_PRI_LOW, 0);
+					cmd_flags, dprc_token);
 	cmd.params[0] |= mc_enc(0, 32, cfg->portal_id);
 
 	/* send command to mc*/
@@ -85,70 +94,78 @@ int dpmcp_create(struct fsl_mc_io *mc_io,
 		return err;
 
 	/* retrieve response parameters */
-	*token = MC_CMD_HDR_READ_TOKEN(cmd.header);
+	*object_id = get_mc_cmd_create_object_id(&cmd);
 
 	return 0;
 }
 
-int dpmcp_destroy(struct fsl_mc_io *mc_io, uint16_t token)
+int dpmcp_destroy(struct fsl_mc_io *mc_io,
+		  uint16_t dprc_token,
+		  uint32_t cmd_flags,
+		  uint32_t object_id)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_DESTROY,
-					  MC_CMD_PRI_LOW, token);
-
+					cmd_flags,
+					dprc_token);
+	/* set object id to destroy */
+	set_mc_cmd_destroy_object_id(&cmd, object_id);
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
 
-int dpmcp_reset(struct fsl_mc_io *mc_io, uint16_t token)
+int dpmcp_reset(struct fsl_mc_io *mc_io,
+		uint32_t cmd_flags,
+		uint16_t token)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_RESET,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
 
 int dpmcp_set_irq(struct fsl_mc_io *mc_io,
+		  uint32_t cmd_flags,
 		  uint16_t token,
-		 uint8_t irq_index,
-		 uint64_t irq_addr,
-		 uint32_t irq_val,
-		 int user_irq_id)
+		  uint8_t irq_index,
+		  struct dpmcp_irq_cfg	*irq_cfg)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_SET_IRQ,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(0, 8, irq_index);
-	cmd.params[0] |= mc_enc(32, 32, irq_val);
-	cmd.params[1] |= mc_enc(0, 64, irq_addr);
-	cmd.params[2] |= mc_enc(0, 32, user_irq_id);
+	cmd.params[0] |= mc_enc(32, 32, irq_cfg->val);
+	cmd.params[1] |= mc_enc(0, 64, irq_cfg->paddr);
+	cmd.params[2] |= mc_enc(0, 32, irq_cfg->user_irq_id);
 
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
 
 int dpmcp_get_irq(struct fsl_mc_io *mc_io,
+		  uint32_t cmd_flags,
 		  uint16_t token,
-		 uint8_t irq_index,
-		 int *type,
-		 uint64_t *irq_addr,
-		 uint32_t *irq_val,
-		 int *user_irq_id)
+		  uint8_t irq_index,
+		  int *type,
+		  struct dpmcp_irq_cfg	*irq_cfg)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_GET_IRQ,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
@@ -157,23 +174,25 @@ int dpmcp_get_irq(struct fsl_mc_io *mc_io,
 		return err;
 
 	/* retrieve response parameters */
-	*irq_val = (uint32_t)mc_dec(cmd.params[0], 0, 32);
-	*irq_addr = (uint64_t)mc_dec(cmd.params[1], 0, 64);
-	*user_irq_id = (int)mc_dec(cmd.params[2], 0, 32);
+	irq_cfg->val = (uint32_t)mc_dec(cmd.params[0], 0, 32);
+	irq_cfg->paddr = (uint64_t)mc_dec(cmd.params[1], 0, 64);
+	irq_cfg->user_irq_id = (int)mc_dec(cmd.params[2], 0, 32);
 	*type = (int)mc_dec(cmd.params[2], 32, 32);
 	return 0;
 }
 
 int dpmcp_set_irq_enable(struct fsl_mc_io *mc_io,
+			 uint32_t cmd_flags,
 			 uint16_t token,
-			uint8_t irq_index,
-			uint8_t en)
+			 uint8_t irq_index,
+			 uint8_t en)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_SET_IRQ_ENABLE,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(0, 8, en);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
@@ -182,16 +201,18 @@ int dpmcp_set_irq_enable(struct fsl_mc_io *mc_io,
 }
 
 int dpmcp_get_irq_enable(struct fsl_mc_io *mc_io,
+			 uint32_t cmd_flags,
 			 uint16_t token,
-			uint8_t irq_index,
-			uint8_t *en)
+			 uint8_t irq_index,
+			 uint8_t *en)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_GET_IRQ_ENABLE,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
@@ -205,15 +226,17 @@ int dpmcp_get_irq_enable(struct fsl_mc_io *mc_io,
 }
 
 int dpmcp_set_irq_mask(struct fsl_mc_io *mc_io,
+		       uint32_t cmd_flags,
 		       uint16_t token,
-		      uint8_t irq_index,
-		      uint32_t mask)
+		       uint8_t irq_index,
+		       uint32_t mask)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_SET_IRQ_MASK,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(0, 32, mask);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
@@ -222,16 +245,18 @@ int dpmcp_set_irq_mask(struct fsl_mc_io *mc_io,
 }
 
 int dpmcp_get_irq_mask(struct fsl_mc_io *mc_io,
+		       uint32_t cmd_flags,
 		       uint16_t token,
-		      uint8_t irq_index,
-		      uint32_t *mask)
+		       uint8_t irq_index,
+		       uint32_t *mask)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_GET_IRQ_MASK,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
@@ -245,16 +270,18 @@ int dpmcp_get_irq_mask(struct fsl_mc_io *mc_io,
 }
 
 int dpmcp_get_irq_status(struct fsl_mc_io *mc_io,
+			 uint32_t cmd_flags,
 			 uint16_t token,
-			uint8_t irq_index,
-			uint32_t *status)
+			 uint8_t irq_index,
+			 uint32_t *status)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_GET_IRQ_STATUS,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
@@ -267,42 +294,47 @@ int dpmcp_get_irq_status(struct fsl_mc_io *mc_io,
 	return 0;
 }
 
-int dpmcp_clear_irq_status(struct fsl_mc_io *mc_io,
-			   uint16_t token,
-			  uint8_t irq_index,
-			  uint32_t status)
+int dpmcp_get_attributes(struct fsl_mc_io *mc_io,
+			 uint32_t cmd_flags,
+			 uint16_t token,
+			 struct dpmcp_attr *attr)
 {
 	struct mc_command cmd = { 0 };
+	int err;
 
 	/* prepare command */
-	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_CLEAR_IRQ_STATUS,
-					  MC_CMD_PRI_LOW, token);
-	cmd.params[0] |= mc_enc(0, 32, status);
-	cmd.params[0] |= mc_enc(32, 8, irq_index);
+	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_GET_ATTR,
+					  cmd_flags,
+					  token);
 
 	/* send command to mc*/
-	return mc_send_command(mc_io, &cmd);
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	attr->id = (int)mc_dec(cmd.params[0], 32, 32);
+
+	return 0;
 }
 
-int dpmcp_get_attributes(struct fsl_mc_io *mc_io,
-			 uint16_t token,
-			struct dpmcp_attr *attr)
+int dpmcp_get_api_version(struct fsl_mc_io *mc_io,
+			   uint32_t cmd_flags,
+			   uint16_t *major_ver,
+			   uint16_t *minor_ver)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
-	/* prepare command */
-	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_GET_ATTR,
-					  MC_CMD_PRI_LOW, token);
+	cmd.header = mc_encode_cmd_header(DPMCP_CMDID_GET_API_VERSION,
+					cmd_flags,
+					0);
 
-	/* send command to mc*/
 	err = mc_send_command(mc_io, &cmd);
 	if (err)
 		return err;
 
-	/* retrieve response parameters */
-	attr->id = (int)mc_dec(cmd.params[0], 32, 32);
-	attr->version.major = (uint16_t)mc_dec(cmd.params[1], 0, 16);
-	attr->version.minor = (uint16_t)mc_dec(cmd.params[1], 16, 16);
+	get_mc_cmd_object_api_ver(&cmd, major_ver, minor_ver);
+
 	return 0;
 }
diff --git a/drivers/staging/fsl-mc/bus/dpmcp.h b/drivers/staging/fsl-mc/bus/dpmcp.h
index 5e7c219..13cc1b9 100644
--- a/drivers/staging/fsl-mc/bus/dpmcp.h
+++ b/drivers/staging/fsl-mc/bus/dpmcp.h
@@ -1,4 +1,4 @@
-/* Copyright 2013-2015 Freescale Semiconductor Inc.
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -41,6 +41,7 @@ struct fsl_mc_io;
 /**
  * dpmcp_open() - Open a control session for the specified object.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @dpmcp_id:	DPMCP unique ID
  * @token:	Returned token; use in subsequent API calls
  *
@@ -54,7 +55,10 @@ struct fsl_mc_io;
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dpmcp_open(struct fsl_mc_io *mc_io, int dpmcp_id, uint16_t *token);
+int dpmcp_open(struct fsl_mc_io	*mc_io,
+	       uint32_t		cmd_flags,
+	       int			dpmcp_id,
+	       uint16_t		*token);
 
 /* Get portal ID from pool */
 #define DPMCP_GET_PORTAL_ID_FROM_POOL (-1)
@@ -62,6 +66,7 @@ int dpmcp_open(struct fsl_mc_io *mc_io, int dpmcp_id, uint16_t *token);
 /**
  * dpmcp_close() - Close the control session of the object
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPMCP object
  *
  * After this function is called, no further operations are
@@ -69,12 +74,14 @@ int dpmcp_open(struct fsl_mc_io *mc_io, int dpmcp_id, uint16_t *token);
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dpmcp_close(struct fsl_mc_io *mc_io, uint16_t token);
+int dpmcp_close(struct fsl_mc_io	*mc_io,
+		uint32_t		cmd_flags,
+		uint16_t		token);
 
 /**
- * struct dpmcp_cfg() - Structure representing DPMCP configuration
+ * struct dpmcp_cfg - Structure representing DPMCP configuration
  * @portal_id:	Portal ID; 'DPMCP_GET_PORTAL_ID_FROM_POOL' to get the portal ID
- *		from pool
+ *				from pool
  */
 struct dpmcp_cfg {
 	int portal_id;
@@ -82,100 +89,123 @@ struct dpmcp_cfg {
 
 /**
  * dpmcp_create() - Create the DPMCP object.
+ *
  * @mc_io:	Pointer to MC portal's I/O object
+ * @dprc_token: parent container token; '0' for default container
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @cfg:	Configuration structure
- * @token:	Returned token; use in subsequent API calls
+ * @obj_id: returns the object id or portal id.
  *
  * Create the DPMCP object, allocate required resources and
  * perform required initialization.
  *
  * The object can be created either by declaring it in the
  * DPL file, or by calling this function.
- * This function returns a unique authentication token,
- * associated with the specific object ID and the specific MC
- * portal; this token must be used in all subsequent calls to
- * this specific object. For objects that are created using the
- * DPL file, call dpmcp_open function to get an authentication
- * token first.
+ *
+ * The function accepts an authentication token of a parent
+ * container that this object should be assigned to. The token
+ * can be '0' so the object will be assigned to the default container.
+ * The newly created object can be opened with the returned
+ * object id and using the container's associated tokens and MC portals.
  *
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpmcp_create(struct fsl_mc_io	*mc_io,
-		 const struct dpmcp_cfg	*cfg,
-		uint16_t		*token);
+		uint16_t	dprc_token,
+		uint32_t	cmd_flags,
+		const struct dpmcp_cfg	*cfg,
+		uint32_t	*obj_id);
 
 /**
  * dpmcp_destroy() - Destroy the DPMCP object and release all its resources.
+ *
  * @mc_io:	Pointer to MC portal's I/O object
- * @token:	Token of DPMCP object
+ * @dprc_token: MC v10.x - parent container token; '0' for default container
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @object_id:  Object id or portal id; it must be a valid id
+ *              within the container that created this object.
+ *
+ * The function accepts the authentication token of the parent
+ * container that created the object (not the one that currently owns
+ * the object). The object is searched within parent using the provided
+ * object_id. All tokens to the object must be closed before calling destroy.
  *
  * Return:	'0' on Success; error code otherwise.
  */
-int dpmcp_destroy(struct fsl_mc_io *mc_io, uint16_t token);
+int dpmcp_destroy(struct fsl_mc_io	*mc_io,
+		uint16_t	dprc_token,
+		uint32_t	cmd_flags,
+		uint32_t	object_id);
 
 /**
  * dpmcp_reset() - Reset the DPMCP, returns the object to initial state.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPMCP object
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dpmcp_reset(struct fsl_mc_io *mc_io, uint16_t token);
+int dpmcp_reset(struct fsl_mc_io	*mc_io,
+		uint32_t		cmd_flags,
+		uint16_t			token);
 
 /* IRQ */
-/*!
- * @name dpmcp IRQ Index and Events
- */
+/* IRQ Index */
 #define DPMCP_IRQ_INDEX                             0
-/*!< Irq index */
+/* irq event - Indicates that the link state changed */
 #define DPMCP_IRQ_EVENT_CMD_DONE                    0x00000001
-/*!< irq event - Indicates that the link state changed */
-/* @} */
+
+/**
+ * struct dpmcp_irq_cfg - IRQ configuration
+ * @paddr:	Address that must be written to signal a message-based interrupt
+ * @val:	Value to write into irq_addr address
+ * @user_irq_id: A user defined number associated with this IRQ
+ */
+struct dpmcp_irq_cfg {
+	     uint64_t		paddr;
+	     uint32_t		val;
+	     int		user_irq_id;
+};
 
 /**
  * dpmcp_set_irq() - Set IRQ information for the DPMCP to trigger an interrupt.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPMCP object
  * @irq_index:	Identifies the interrupt index to configure
- * @irq_addr:	Address that must be written to
- *				signal a message-based interrupt
- * @irq_val:	Value to write into irq_addr address
- * @user_irq_id: A user defined number associated with this IRQ
+ * @irq_cfg:	IRQ configuration
  *
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpmcp_set_irq(struct fsl_mc_io	*mc_io,
+		  uint32_t		cmd_flags,
 		  uint16_t		token,
-		 uint8_t		irq_index,
-		 uint64_t		irq_addr,
-		 uint32_t		irq_val,
-		 int			user_irq_id);
+		  uint8_t		irq_index,
+		  struct dpmcp_irq_cfg	*irq_cfg);
 
 /**
  * dpmcp_get_irq() - Get IRQ information from the DPMCP.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPMCP object
  * @irq_index:	The interrupt index to configure
  * @type:	Interrupt type: 0 represents message interrupt
- *				type (both irq_addr and irq_val are valid)
- * @irq_addr:	Returned address that must be written to
- *				signal the message-based interrupt
- * @irq_val:	Value to write into irq_addr address
- * @user_irq_id: A user defined number associated with this IRQ
+ *		type (both irq_addr and irq_val are valid)
+ * @irq_cfg:	IRQ attributes
  *
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpmcp_get_irq(struct fsl_mc_io	*mc_io,
+		  uint32_t		cmd_flags,
 		  uint16_t		token,
-		 uint8_t		irq_index,
-		 int			*type,
-		 uint64_t		*irq_addr,
-		 uint32_t		*irq_val,
-		 int			*user_irq_id);
+		  uint8_t		irq_index,
+		  int			*type,
+		  struct dpmcp_irq_cfg	*irq_cfg);
 
 /**
  * dpmcp_set_irq_enable() - Set overall interrupt state.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPMCP object
  * @irq_index:	The interrupt index to configure
  * @en:	Interrupt state - enable = 1, disable = 0
@@ -188,13 +218,15 @@ int dpmcp_get_irq(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpmcp_set_irq_enable(struct fsl_mc_io	*mc_io,
+			 uint32_t		cmd_flags,
 			 uint16_t		token,
-			uint8_t			irq_index,
-			uint8_t			en);
+			 uint8_t		irq_index,
+			 uint8_t		en);
 
 /**
  * dpmcp_get_irq_enable() - Get overall interrupt state
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPMCP object
  * @irq_index:	The interrupt index to configure
  * @en:		Returned interrupt state - enable = 1, disable = 0
@@ -202,13 +234,15 @@ int dpmcp_set_irq_enable(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpmcp_get_irq_enable(struct fsl_mc_io	*mc_io,
+			 uint32_t		cmd_flags,
 			 uint16_t		token,
-			uint8_t			irq_index,
-			uint8_t			*en);
+			 uint8_t		irq_index,
+			 uint8_t		*en);
 
 /**
  * dpmcp_set_irq_mask() - Set interrupt mask.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPMCP object
  * @irq_index:	The interrupt index to configure
  * @mask:	Event mask to trigger interrupt;
@@ -221,14 +255,16 @@ int dpmcp_get_irq_enable(struct fsl_mc_io	*mc_io,
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dpmcp_set_irq_mask(struct fsl_mc_io	*mc_io,
+int dpmcp_set_irq_mask(struct fsl_mc_io *mc_io,
+		       uint32_t	cmd_flags,
 		       uint16_t		token,
-		      uint8_t		irq_index,
-		      uint32_t		mask);
+		       uint8_t		irq_index,
+		       uint32_t		mask);
 
 /**
  * dpmcp_get_irq_mask() - Get interrupt mask.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPMCP object
  * @irq_index:	The interrupt index to configure
  * @mask:	Returned event mask to trigger interrupt
@@ -238,15 +274,17 @@ int dpmcp_set_irq_mask(struct fsl_mc_io	*mc_io,
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dpmcp_get_irq_mask(struct fsl_mc_io	*mc_io,
+int dpmcp_get_irq_mask(struct fsl_mc_io *mc_io,
+		       uint32_t	cmd_flags,
 		       uint16_t		token,
-		      uint8_t		irq_index,
-		      uint32_t		*mask);
+		       uint8_t		irq_index,
+		       uint32_t		*mask);
 
 /**
  * dpmcp_get_irq_status() - Get the current status of any pending interrupts.
  *
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPMCP object
  * @irq_index:	The interrupt index to configure
  * @status:	Returned interrupts status - one bit per cause:
@@ -256,56 +294,45 @@ int dpmcp_get_irq_mask(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpmcp_get_irq_status(struct fsl_mc_io	*mc_io,
+			 uint32_t		cmd_flags,
 			 uint16_t		token,
-			uint8_t			irq_index,
-			uint32_t		*status);
-
-/**
- * dpmcp_clear_irq_status() - Clear a pending interrupt's status
- *
- * @mc_io:	Pointer to MC portal's I/O object
- * @token:	Token of DPMCP object
- * @irq_index:	The interrupt index to configure
- * @status:	Bits to clear (W1C) - one bit per cause:
- *					0 = don't change
- *					1 = clear status bit
- *
- * Return:	'0' on Success; Error code otherwise.
- */
-int dpmcp_clear_irq_status(struct fsl_mc_io	*mc_io,
-			   uint16_t		token,
-			  uint8_t		irq_index,
-			  uint32_t		status);
+			 uint8_t		irq_index,
+			 uint32_t		*status);
 
 /**
  * struct dpmcp_attr - Structure representing DPMCP attributes
  * @id:		DPMCP object ID
- * @version:	DPMCP version
  */
 struct dpmcp_attr {
 	int id;
-	/**
-	 * struct version - Structure representing DPMCP version
-	 * @major:	DPMCP major version
-	 * @minor:	DPMCP minor version
-	 */
-	struct {
-		uint16_t major;
-		uint16_t minor;
-	} version;
 };
 
 /**
  * dpmcp_get_attributes - Retrieve DPMCP attributes.
  *
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPMCP object
  * @attr:	Returned object's attributes
  *
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpmcp_get_attributes(struct fsl_mc_io	*mc_io,
+			 uint32_t		cmd_flags,
 			 uint16_t		token,
-			struct dpmcp_attr	*attr);
+			 struct dpmcp_attr	*attr);
 
+/**
+ * dpmcp_get_api_version() - Get Data Path Management Command Portal API version
+ * @mc_io:  Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @majorVer: 	Major version of data path management command portal API
+ * @minorVer: 	Minor version of data path management command portal API
+ *
+ * Return:  '0' on Success; Error code otherwise.
+ */
+int dpmcp_get_api_version(struct fsl_mc_io *mc_io,
+			   uint32_t cmd_flags,
+			   uint16_t *major_ver,
+			   uint16_t *minor_ver);
 #endif /* __FSL_DPMCP_H */
diff --git a/drivers/staging/fsl-mc/bus/dpmng-cmd.h b/drivers/staging/fsl-mc/bus/dpmng-cmd.h
index ba8cfa9..01d477b 100644
--- a/drivers/staging/fsl-mc/bus/dpmng-cmd.h
+++ b/drivers/staging/fsl-mc/bus/dpmng-cmd.h
@@ -1,4 +1,4 @@
-/* Copyright 2013-2014 Freescale Semiconductor Inc.
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -40,8 +40,10 @@
 #ifndef __FSL_DPMNG_CMD_H
 #define __FSL_DPMNG_CMD_H
 
+#define DPMNG_CMD_BASE_VERSION		1
+#define DPMNG_CMD_ID_OFFSET		4
+
 /* Command IDs */
-#define DPMNG_CMDID_GET_CONT_ID			0x830
-#define DPMNG_CMDID_GET_VERSION			0x831
+#define DPMNG_CMDID_GET_VERSION			((0x831 << DPMNG_CMD_ID_OFFSET) | DPMNG_CMD_BASE_VERSION)
 
 #endif /* __FSL_DPMNG_CMD_H */
diff --git a/drivers/staging/fsl-mc/bus/dpmng.c b/drivers/staging/fsl-mc/bus/dpmng.c
index 58328e8..2c05536 100644
--- a/drivers/staging/fsl-mc/bus/dpmng.c
+++ b/drivers/staging/fsl-mc/bus/dpmng.c
@@ -1,4 +1,4 @@
-/* Copyright 2013-2014 Freescale Semiconductor Inc.
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
@@ -34,14 +34,17 @@
 #include "../include/dpmng.h"
 #include "dpmng-cmd.h"
 
-int mc_get_version(struct fsl_mc_io *mc_io, struct mc_version *mc_ver_info)
+int mc_get_version(struct fsl_mc_io *mc_io,
+		   uint32_t cmd_flags,
+		   struct mc_version *mc_ver_info)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPMNG_CMDID_GET_VERSION,
-					  MC_CMD_PRI_LOW, 0);
+					  cmd_flags,
+					  0);
 
 	/* send command to mc*/
 	err = mc_send_command(mc_io, &cmd);
@@ -55,24 +58,6 @@ int mc_get_version(struct fsl_mc_io *mc_io, struct mc_version *mc_ver_info)
 
 	return 0;
 }
+EXPORT_SYMBOL(mc_get_version);
 
-int dpmng_get_container_id(struct fsl_mc_io *mc_io, int *container_id)
-{
-	struct mc_command cmd = { 0 };
-	int err;
-
-	/* prepare command */
-	cmd.header = mc_encode_cmd_header(DPMNG_CMDID_GET_CONT_ID,
-					  MC_CMD_PRI_LOW, 0);
-
-	/* send command to mc*/
-	err = mc_send_command(mc_io, &cmd);
-	if (err)
-		return err;
-
-	/* retrieve response parameters */
-	*container_id = mc_dec(cmd.params[0], 0, 32);
-
-	return 0;
-}
 
diff --git a/drivers/staging/fsl-mc/bus/dprc-cmd.h b/drivers/staging/fsl-mc/bus/dprc-cmd.h
index 0920248..6f80e21 100644
--- a/drivers/staging/fsl-mc/bus/dprc-cmd.h
+++ b/drivers/staging/fsl-mc/bus/dprc-cmd.h
@@ -1,4 +1,4 @@
-/* Copyright 2013-2014 Freescale Semiconductor Inc.
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -40,45 +40,52 @@
 #ifndef _FSL_DPRC_CMD_H
 #define _FSL_DPRC_CMD_H
 
-/* DPRC Version */
-#define DPRC_VER_MAJOR				3
-#define DPRC_VER_MINOR				0
+/* Minimal supported DPRC Version */
+#define DPRC_MIN_VER_MAJOR			6
+#define DPRC_MIN_VER_MINOR			0
+#define DPRC_CMD_BASE_VERSION			1
+#define DPRC_CMD_ID_OFFSET			4
 
 /* Command IDs */
-#define DPRC_CMDID_CLOSE			0x800
-#define DPRC_CMDID_OPEN				0x805
-#define DPRC_CMDID_CREATE			0x905
+#define DPRC_CMDID_CLOSE                        ((0x800 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_OPEN                         ((0x805 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_CREATE                       ((0x905 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_VERSION                  ((0xa05 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
 
-#define DPRC_CMDID_GET_ATTR			0x004
-#define DPRC_CMDID_RESET_CONT			0x005
+#define DPRC_CMDID_GET_ATTR                     ((0x004 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_RESET_CONT                   ((0x005 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
 
-#define DPRC_CMDID_SET_IRQ			0x010
-#define DPRC_CMDID_GET_IRQ			0x011
-#define DPRC_CMDID_SET_IRQ_ENABLE		0x012
-#define DPRC_CMDID_GET_IRQ_ENABLE		0x013
-#define DPRC_CMDID_SET_IRQ_MASK			0x014
-#define DPRC_CMDID_GET_IRQ_MASK			0x015
-#define DPRC_CMDID_GET_IRQ_STATUS		0x016
-#define DPRC_CMDID_CLEAR_IRQ_STATUS		0x017
+#define DPRC_CMDID_SET_IRQ                      ((0x010 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_IRQ                      ((0x011 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_SET_IRQ_ENABLE               ((0x012 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_IRQ_ENABLE               ((0x013 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_SET_IRQ_MASK                 ((0x014 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_IRQ_MASK                 ((0x015 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_IRQ_STATUS               ((0x016 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_CLEAR_IRQ_STATUS             ((0x017 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
 
-#define DPRC_CMDID_CREATE_CONT			0x151
-#define DPRC_CMDID_DESTROY_CONT			0x152
-#define DPRC_CMDID_SET_RES_QUOTA		0x155
-#define DPRC_CMDID_GET_RES_QUOTA		0x156
-#define DPRC_CMDID_ASSIGN			0x157
-#define DPRC_CMDID_UNASSIGN			0x158
-#define DPRC_CMDID_GET_OBJ_COUNT		0x159
-#define DPRC_CMDID_GET_OBJ			0x15A
-#define DPRC_CMDID_GET_RES_COUNT		0x15B
-#define DPRC_CMDID_GET_RES_IDS			0x15C
-#define DPRC_CMDID_GET_OBJ_REG			0x15E
+#define DPRC_CMDID_CREATE_CONT                  ((0x151 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_DESTROY_CONT                 ((0x152 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_CONT_ID                  ((0x830 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_SET_RES_QUOTA                ((0x155 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_RES_QUOTA                ((0x156 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_ASSIGN                       ((0x157 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_UNASSIGN                     ((0x158 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_OBJ_COUNT                ((0x159 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_OBJ                      ((0x15A << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_RES_COUNT                ((0x15B << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_RES_IDS                  ((0x15C << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_OBJ_REG                  ((0x15E << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_SET_OBJ_IRQ                  ((0x15F << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_OBJ_IRQ                  ((0x160 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_SET_OBJ_LABEL                ((0x161 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_OBJ_DESC                 ((0x162 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
 
-#define DPRC_CMDID_CONNECT			0x167
-#define DPRC_CMDID_DISCONNECT			0x168
-#define DPRC_CMDID_GET_POOL			0x169
-#define DPRC_CMDID_GET_POOL_COUNT		0x16A
-#define DPRC_CMDID_GET_PORTAL_PADDR		0x16B
+#define DPRC_CMDID_CONNECT                      ((0x167 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_DISCONNECT                   ((0x168 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_POOL                     ((0x169 << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
+#define DPRC_CMDID_GET_POOL_COUNT               ((0x16A << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
 
-#define DPRC_CMDID_GET_CONNECTION		0x16C
+#define DPRC_CMDID_GET_CONNECTION               ((0x16C << DPRC_CMD_ID_OFFSET) | DPRC_CMD_BASE_VERSION)
 
 #endif /* _FSL_DPRC_CMD_H */
diff --git a/drivers/staging/fsl-mc/bus/dprc-driver.c b/drivers/staging/fsl-mc/bus/dprc-driver.c
index 35c06cf..0ef2bd1 100644
--- a/drivers/staging/fsl-mc/bus/dprc-driver.c
+++ b/drivers/staging/fsl-mc/bus/dprc-driver.c
@@ -1,7 +1,7 @@
 /*
  * Freescale data path resource container (DPRC) driver
  *
- * Copyright (C) 2014 Freescale Semiconductor, Inc.
+ * Copyright (C) 2014-2016 Freescale Semiconductor, Inc.
  * Author: German Rivera <German.Rivera@freescale.com>
  *
  * This file is licensed under the terms of the GNU General Public
@@ -13,7 +13,9 @@
 #include "../include/mc-sys.h"
 #include <linux/module.h>
 #include <linux/slab.h>
+#include <linux/interrupt.h>
 #include "dprc-cmd.h"
+#include "dpmcp.h"
 
 struct dprc_child_objs {
 	int child_count;
@@ -150,6 +152,8 @@ static void check_plugged_state_change(struct fsl_mc_device *mc_dev,
  * dprc_add_new_devices - Adds devices to the logical bus for a DPRC
  *
  * @mc_bus_dev: pointer to the fsl-mc device that represents a DPRC object
+ * @driver_override: driver override to apply to new objects found in the DPRC,
+ * or NULL, if none.
  * @obj_desc_array: array of device descriptors for child devices currently
  * present in the physical DPRC.
  * @num_child_objects_in_mc: number of entries in obj_desc_array
@@ -159,6 +163,7 @@ static void check_plugged_state_change(struct fsl_mc_device *mc_dev,
  * in the physical DPRC.
  */
 static void dprc_add_new_devices(struct fsl_mc_device *mc_bus_dev,
+				 const char *driver_override,
 				 struct dprc_obj_desc *obj_desc_array,
 				 int num_child_objects_in_mc)
 {
@@ -182,13 +187,13 @@ static void dprc_add_new_devices(struct fsl_mc_device *mc_bus_dev,
 		}
 
 		error = fsl_mc_device_add(obj_desc, NULL, &mc_bus_dev->dev,
-					  &child_dev);
+					  driver_override, &child_dev);
 		if (error < 0)
 			continue;
 	}
 }
 
-static void dprc_init_all_resource_pools(struct fsl_mc_device *mc_bus_dev)
+void dprc_init_all_resource_pools(struct fsl_mc_device *mc_bus_dev)
 {
 	int pool_type;
 	struct fsl_mc_bus *mc_bus = to_fsl_mc_bus(mc_bus_dev);
@@ -229,18 +234,29 @@ static void dprc_cleanup_resource_pool(struct fsl_mc_device *mc_bus_dev,
 	WARN_ON(free_count != res_pool->free_count);
 }
 
-static void dprc_cleanup_all_resource_pools(struct fsl_mc_device *mc_bus_dev)
+/*
+ * Clean up all resource pools other than the IRQ pool
+ */
+void dprc_cleanup_all_resource_pools(struct fsl_mc_device *mc_bus_dev)
 {
 	int pool_type;
 
-	for (pool_type = 0; pool_type < FSL_MC_NUM_POOL_TYPES; pool_type++)
-		dprc_cleanup_resource_pool(mc_bus_dev, pool_type);
+	for (pool_type = 0; pool_type < FSL_MC_NUM_POOL_TYPES; pool_type++) {
+		if (pool_type != FSL_MC_POOL_IRQ)
+			dprc_cleanup_resource_pool(mc_bus_dev, pool_type);
+	}
 }
 
 /**
  * dprc_scan_objects - Discover objects in a DPRC
  *
  * @mc_bus_dev: pointer to the fsl-mc device that represents a DPRC object
+ * @driver_override: driver override to apply to new objects found in the DPRC,
+ * or NULL, if none.
+ * @total_irq_count: total number of IRQs needed by objects in the DPRC.
+ * @scan_options: options regarding object discovery. Current options include:
+ *  - FSL_MC_SCAN_DPRC_POPULATE_IRQ_POOL: initialize IRQ pool before adding
+ *  new objects; the option is ignored if the IRQ pool was already initialized.
  *
  * Detects objects added and removed from a DPRC and synchronizes the
  * state of the Linux bus driver, MC by adding and removing
@@ -254,14 +270,25 @@ static void dprc_cleanup_all_resource_pools(struct fsl_mc_device *mc_bus_dev)
  * populated before they can get allocation requests from probe callbacks
  * of the device drivers for the non-allocatable devices.
  */
-int dprc_scan_objects(struct fsl_mc_device *mc_bus_dev)
+int dprc_scan_objects(struct fsl_mc_device *mc_bus_dev,
+		      const char *driver_override,
+		      unsigned int *total_irq_count,
+		      unsigned int scan_options)
 {
 	int num_child_objects;
 	int dprc_get_obj_failures;
 	int error;
+	unsigned int irq_count = mc_bus_dev->obj_desc.irq_count;
 	struct dprc_obj_desc *child_obj_desc_array = NULL;
+	struct fsl_mc_bus *mc_bus;
+
+	if (WARN_ON(!total_irq_count)) {
+		dev_err(&mc_bus_dev->dev, "invalid input parameter: irq count\n");
+		return -EINVAL;
+	}
 
 	error = dprc_get_obj_count(mc_bus_dev->mc_io,
+				   0,
 				   mc_bus_dev->mc_handle,
 				   &num_child_objects);
 	if (error < 0) {
@@ -289,8 +316,19 @@ int dprc_scan_objects(struct fsl_mc_device *mc_bus_dev)
 			    &child_obj_desc_array[i];
 
 			error = dprc_get_obj(mc_bus_dev->mc_io,
+					     0,
 					     mc_bus_dev->mc_handle,
 					     i, obj_desc);
+
+			/*
+			 * -ENXIO means object index was invalid.
+			 *  This is caused when the DPRC was changed at
+			 *  the MC during the scan.  In this case,
+			 *  abort the current scan.
+			 */
+			if (error == -ENXIO)
+				goto error;
+
 			if (error < 0) {
 				dev_err(&mc_bus_dev->dev,
 					"dprc_get_obj(i=%d) failed: %d\n",
@@ -305,6 +343,17 @@ int dprc_scan_objects(struct fsl_mc_device *mc_bus_dev)
 				continue;
 			}
 
+			/*
+			 * for DPRC versions that do not support the
+			 * shareability attribute, make simplifying assumption
+			 * that only SEC is not shareable.
+			 */
+			if ((strcmp(obj_desc->type, "dpseci") == 0) &&
+			    (obj_desc->ver_major < 4))
+				obj_desc->flags |=
+					DPRC_OBJ_FLAG_NO_MEM_SHAREABILITY;
+
+			irq_count += obj_desc->irq_count;
 			dev_dbg(&mc_bus_dev->dev,
 				"Discovered object: type %s, id %d\n",
 				obj_desc->type, obj_desc->id);
@@ -317,16 +366,35 @@ int dprc_scan_objects(struct fsl_mc_device *mc_bus_dev)
 		}
 	}
 
+	*total_irq_count = irq_count;
 	dprc_remove_devices(mc_bus_dev, child_obj_desc_array,
 			    num_child_objects);
-
-	dprc_add_new_devices(mc_bus_dev, child_obj_desc_array,
+	/* populate the irq pool before adding new devices */
+	if ((scan_options & FSL_MC_SCAN_DPRC_POPULATE_IRQ_POOL) != 0 &&
+		fsl_mc_interrupts_supported()) {
+		mc_bus = to_fsl_mc_bus(mc_bus_dev);
+		/* check if the irq resources were not already initialized */
+		if (!mc_bus->irq_resources) {
+			error = fsl_mc_populate_irq_pool(mc_bus, irq_count);
+			if (error < 0) {
+				dev_err(&mc_bus_dev->dev,
+						"%s: Failed to populate irq-pool\n",
+						__func__);
+				goto error;
+			}
+		}
+	}
+	dprc_add_new_devices(mc_bus_dev, driver_override, child_obj_desc_array,
 			     num_child_objects);
 
 	if (child_obj_desc_array)
 		devm_kfree(&mc_bus_dev->dev, child_obj_desc_array);
 
 	return 0;
+error:
+	if (child_obj_desc_array)
+		devm_kfree(&mc_bus_dev->dev, child_obj_desc_array);
+	return error;
 }
 EXPORT_SYMBOL_GPL(dprc_scan_objects);
 
@@ -339,9 +407,10 @@ EXPORT_SYMBOL_GPL(dprc_scan_objects);
  * bus driver with the actual state of the MC by adding and removing
  * devices as appropriate.
  */
-int dprc_scan_container(struct fsl_mc_device *mc_bus_dev)
+static int dprc_scan_container(struct fsl_mc_device *mc_bus_dev)
 {
 	int error;
+	unsigned int irq_count;
 	struct fsl_mc_bus *mc_bus = to_fsl_mc_bus(mc_bus_dev);
 
 	dprc_init_all_resource_pools(mc_bus_dev);
@@ -350,17 +419,405 @@ int dprc_scan_container(struct fsl_mc_device *mc_bus_dev)
 	 * Discover objects in the DPRC:
 	 */
 	mutex_lock(&mc_bus->scan_mutex);
-	error = dprc_scan_objects(mc_bus_dev);
+	error = dprc_scan_objects(mc_bus_dev, NULL, &irq_count, 0);
 	mutex_unlock(&mc_bus->scan_mutex);
 	if (error < 0)
 		goto error;
 
+	if (fsl_mc_interrupts_supported() && !mc_bus->irq_resources) {
+		irq_count += FSL_MC_IRQ_POOL_MAX_EXTRA_IRQS;
+		error = fsl_mc_populate_irq_pool(mc_bus, irq_count);
+		if (error < 0)
+			goto error;
+	}
+
 	return 0;
 error:
+	device_for_each_child(&mc_bus_dev->dev, NULL, __fsl_mc_device_remove);
 	dprc_cleanup_all_resource_pools(mc_bus_dev);
 	return error;
 }
-EXPORT_SYMBOL_GPL(dprc_scan_container);
+
+/**
+ * dprc_irq0_handler - Regular ISR for DPRC interrupt 0
+ *
+ * @irq: IRQ number of the interrupt being handled
+ * @arg: Pointer to device structure
+ */
+static irqreturn_t dprc_irq0_handler(int irq_num, void *arg)
+{
+	return IRQ_WAKE_THREAD;
+}
+
+/**
+ * dprc_irq0_handler_thread - Handler thread function for DPRC interrupt 0
+ *
+ * @irq: IRQ number of the interrupt being handled
+ * @arg: Pointer to device structure
+ */
+static irqreturn_t dprc_irq0_handler_thread(int irq_num, void *arg)
+{
+	int error;
+	uint32_t status;
+	struct device *dev = (struct device *)arg;
+	struct fsl_mc_device *mc_dev = to_fsl_mc_device(dev);
+	struct fsl_mc_bus *mc_bus = to_fsl_mc_bus(mc_dev);
+	struct fsl_mc_io *mc_io = mc_dev->mc_io;
+	int irq_index = 0;
+
+	dev_dbg(dev, "DPRC IRQ %d triggered on CPU %u\n",
+		irq_num, smp_processor_id());
+	if (WARN_ON(!(mc_dev->flags & FSL_MC_IS_DPRC)))
+		return IRQ_HANDLED;
+
+	mutex_lock(&mc_bus->scan_mutex);
+	if (WARN_ON(mc_dev->irqs[irq_index]->irq_number != (uint32_t)irq_num))
+		goto out;
+
+	status = 0;
+	error = dprc_get_irq_status(mc_io, 0, mc_dev->mc_handle, irq_index,
+				    &status);
+	if (error < 0) {
+		dev_err(dev,
+			"dprc_get_irq_status() failed: %d\n", error);
+		goto out;
+	}
+
+	error = dprc_clear_irq_status(mc_io, 0, mc_dev->mc_handle, irq_index,
+				      status);
+	if (error < 0) {
+		dev_err(dev,
+			"dprc_clear_irq_status() failed: %d\n", error);
+		goto out;
+	}
+
+	if (status & (DPRC_IRQ_EVENT_OBJ_ADDED |
+		      DPRC_IRQ_EVENT_OBJ_REMOVED |
+		      DPRC_IRQ_EVENT_CONTAINER_DESTROYED |
+		      DPRC_IRQ_EVENT_OBJ_DESTROYED |
+		      DPRC_IRQ_EVENT_OBJ_CREATED)) {
+		unsigned int irq_count;
+
+		error = dprc_scan_objects(mc_dev, NULL, &irq_count, 0);
+		if (error < 0) {
+			if (error != -ENXIO) /* don't need to report aborted scan */
+				dev_err(dev, "dprc_scan_objects() failed: %d\n", error);
+			goto out;
+		}
+
+		WARN_ON((int16_t)irq_count < 0);
+
+		if ((int16_t)irq_count >
+			mc_bus->resource_pools[FSL_MC_POOL_IRQ].max_count) {
+			dev_warn(dev,
+				 "IRQs needed (%u) exceed IRQs preallocated (%u)\n",
+				 irq_count,
+				 mc_bus->resource_pools[FSL_MC_POOL_IRQ].
+								max_count);
+		}
+	}
+
+out:
+	mutex_unlock(&mc_bus->scan_mutex);
+	return IRQ_HANDLED;
+}
+
+/*
+ * Disable and clear interrupts for a given DPRC object
+ */
+static int disable_dprc_irqs(struct fsl_mc_device *mc_dev)
+{
+	int i;
+	int error;
+	struct fsl_mc_io *mc_io = mc_dev->mc_io;
+	int irq_count = mc_dev->obj_desc.irq_count;
+
+	if (WARN_ON(irq_count == 0))
+		return -EINVAL;
+
+	for (i = 0; i < irq_count; i++) {
+		/*
+		 * Disable generation of interrupt i, while we configure it:
+		 */
+		error = dprc_set_irq_enable(mc_io, 0, mc_dev->mc_handle, i, 0);
+		if (error < 0) {
+			dev_err(&mc_dev->dev,
+				"Disabling DPRC IRQ %d failed: dprc_set_irq_enable() failed: %d\n",
+				i, error);
+
+			return error;
+		}
+
+		/*
+		 * Disable all interrupt causes for interrupt i:
+		 */
+		error = dprc_set_irq_mask(mc_io, 0, mc_dev->mc_handle, i, 0x0);
+		if (error < 0) {
+			dev_err(&mc_dev->dev,
+				"Disabling DPRC IRQ %d failed: dprc_set_irq_mask() failed: %d\n",
+				i, error);
+
+			return error;
+		}
+
+		/*
+		 * Clear any leftover interrupt i:
+		 */
+		error = dprc_clear_irq_status(mc_io, 0, mc_dev->mc_handle, i,
+					      ~0x0U);
+		if (error < 0) {
+			dev_err(&mc_dev->dev,
+				"Disabling DPRC IRQ %d failed: dprc_clear_irq_status() failed: %d\n",
+				i, error);
+
+			return error;
+		}
+	}
+
+	return 0;
+}
+
+static void unregister_dprc_irq_handlers(struct fsl_mc_device *mc_dev)
+{
+	int i;
+	struct fsl_mc_device_irq *irq;
+	int irq_count = mc_dev->obj_desc.irq_count;
+
+	for (i = 0; i < irq_count; i++) {
+		irq = mc_dev->irqs[i];
+		devm_free_irq(&mc_dev->dev, irq->irq_number,
+			      &mc_dev->dev);
+	}
+}
+
+static int register_dprc_irq_handlers(struct fsl_mc_device *mc_dev)
+{
+	static const struct irq_handler {
+		irq_handler_t irq_handler;
+		irq_handler_t irq_handler_thread;
+		const char *irq_name;
+	} irq_handlers[] = {
+		[0] = {
+			.irq_handler = dprc_irq0_handler,
+			.irq_handler_thread = dprc_irq0_handler_thread,
+			.irq_name = "FSL MC DPRC irq0",
+		},
+	};
+
+	unsigned int i;
+	int error;
+	struct fsl_mc_device_irq *irq;
+	unsigned int num_irq_handlers_registered = 0;
+	int irq_count = mc_dev->obj_desc.irq_count;
+
+	if (WARN_ON(irq_count != ARRAY_SIZE(irq_handlers)))
+		return -EINVAL;
+
+	for (i = 0; i < ARRAY_SIZE(irq_handlers); i++) {
+		irq = mc_dev->irqs[i];
+
+		/*
+		 * NOTE: devm_request_threaded_irq() invokes the device-specific
+		 * function that programs the MSI physically in the device
+		 */
+		error = devm_request_threaded_irq(&mc_dev->dev,
+						  irq->irq_number,
+						  irq_handlers[i].irq_handler,
+						  irq_handlers[i].
+							irq_handler_thread,
+						  IRQF_NO_SUSPEND |
+							IRQF_ONESHOT,
+						  irq_handlers[i].irq_name,
+						  &mc_dev->dev);
+		if (error < 0) {
+			dev_err(&mc_dev->dev,
+				"devm_request_threaded_irq() failed: %d\n",
+				error);
+			goto error_unregister_irq_handlers;
+		}
+
+		num_irq_handlers_registered++;
+	}
+
+	return 0;
+
+error_unregister_irq_handlers:
+	for (i = 0; i < num_irq_handlers_registered; i++) {
+		irq = mc_dev->irqs[i];
+		devm_free_irq(&mc_dev->dev, irq->irq_number,
+			      &mc_dev->dev);
+	}
+
+	return error;
+}
+
+static int enable_dprc_irqs(struct fsl_mc_device *mc_dev)
+{
+	int i;
+	int error;
+	int irq_count = mc_dev->obj_desc.irq_count;
+
+	for (i = 0; i < irq_count; i++) {
+		/*
+		 * Enable all interrupt causes for the interrupt:
+		 */
+		error = dprc_set_irq_mask(mc_dev->mc_io,
+					  0,
+					  mc_dev->mc_handle,
+					  i,
+					  ~0x0u);
+		if (error < 0) {
+			dev_err(&mc_dev->dev,
+				"Enabling DPRC IRQ %d failed: dprc_set_irq_mask() failed: %d\n",
+				i, error);
+
+			return error;
+		}
+
+		/*
+		 * Enable generation of the interrupt:
+		 */
+		error = dprc_set_irq_enable(mc_dev->mc_io,
+					    0,
+					    mc_dev->mc_handle,
+					    i, 1);
+		if (error < 0) {
+			dev_err(&mc_dev->dev,
+				"Enabling DPRC IRQ %d failed: dprc_set_irq_enable() failed: %d\n",
+				i, error);
+
+			return error;
+		}
+	}
+
+	return 0;
+}
+
+/*
+ * Setup interrupts for a given DPRC device
+ */
+static int dprc_setup_irqs(struct fsl_mc_device *mc_dev)
+{
+	int error;
+
+	error = fsl_mc_allocate_irqs(mc_dev);
+	if (error < 0)
+		return error;
+
+	error = disable_dprc_irqs(mc_dev);
+	if (error < 0)
+		goto error_free_irqs;
+
+	error = register_dprc_irq_handlers(mc_dev);
+	if (error < 0)
+		goto error_free_irqs;
+
+	error = enable_dprc_irqs(mc_dev);
+	if (error < 0)
+		goto error_unregister_irq_handlers;
+
+	return 0;
+
+error_unregister_irq_handlers:
+	unregister_dprc_irq_handlers(mc_dev);
+
+error_free_irqs:
+	fsl_mc_free_irqs(mc_dev);
+	return error;
+}
+
+/*
+ * Creates a DPMCP for a DPRC's built-in MC portal
+ */
+static int dprc_create_dpmcp(struct fsl_mc_device *dprc_dev)
+{
+	int error;
+	struct dpmcp_cfg dpmcp_cfg;
+	uint32_t dpmcp_obj_id;
+	struct dprc_res_req res_req;
+	struct fsl_mc_bus *mc_bus = to_fsl_mc_bus(dprc_dev);
+
+	dpmcp_cfg.portal_id = mc_bus->dprc_attr.portal_id;
+	error = dpmcp_create(dprc_dev->mc_io,
+			     dprc_dev->mc_handle,
+			     MC_CMD_FLAG_INTR_DIS,
+			     &dpmcp_cfg,
+			     &dpmcp_obj_id);
+	if (error < 0) {
+		dev_err(&dprc_dev->dev,
+				"dpmcp_create() failed, portal id: %u, error: %d\n",
+				dpmcp_cfg.portal_id,
+				error);
+		return error;
+	}
+
+	/*
+	 * Set the state of the newly created DPMCP object to be "plugged":
+	 */
+
+	if (WARN_ON(dpmcp_obj_id != mc_bus->dprc_attr.portal_id)) {
+		error = -EINVAL;
+		dev_warn(&dprc_dev->dev,
+				"dpmcp_create() failed, expected id: %u, actual id: %u\n",
+				mc_bus->dprc_attr.portal_id,
+				dpmcp_obj_id);
+		goto error_destroy_dpmcp;
+	}
+
+	strcpy(res_req.type, "dpmcp");
+	res_req.num = 1;
+	res_req.options =
+			(DPRC_RES_REQ_OPT_EXPLICIT | DPRC_RES_REQ_OPT_PLUGGED);
+	res_req.id_base_align = dpmcp_obj_id;
+
+	error = dprc_assign(dprc_dev->mc_io,
+			    MC_CMD_FLAG_INTR_DIS,
+			    dprc_dev->mc_handle,
+			    dprc_dev->obj_desc.id,
+			    &res_req);
+
+	if (error < 0) {
+		dev_err(&dprc_dev->dev,
+			"dprc_assign() failed, dpmcp id: %u, container: %u, error: %d\n",
+			dpmcp_obj_id,
+			dprc_dev->obj_desc.id,
+			error);
+		goto error_destroy_dpmcp;
+	}
+
+	return 0;
+
+error_destroy_dpmcp:
+	(void)dpmcp_destroy(dprc_dev->mc_io,
+			    dprc_dev->mc_handle,
+			    MC_CMD_FLAG_INTR_DIS,
+				dpmcp_obj_id);
+	return error;
+}
+
+/*
+ * Destroys the DPMCP for a DPRC's built-in MC portal
+ */
+static void dprc_destroy_dpmcp(struct fsl_mc_device *dprc_dev)
+{
+	int error;
+	struct fsl_mc_bus *mc_bus = to_fsl_mc_bus(dprc_dev);
+
+	if (WARN_ON(!dprc_dev->mc_io || dprc_dev->mc_io->dpmcp_dev))
+		return;
+
+	error = dpmcp_destroy(dprc_dev->mc_io,
+			      dprc_dev->mc_handle,
+			      MC_CMD_FLAG_INTR_DIS,
+				  mc_bus->dprc_attr.portal_id);
+	if (error < 0) {
+		dev_err(&dprc_dev->dev,
+				"dpmcp_destroy() failed, object id: %u, error: %d\n",
+				mc_bus->dprc_attr.portal_id,
+				error);
+		return;
+	}
+}
 
 /**
  * dprc_probe - callback invoked when a DPRC is being bound to this driver
@@ -377,14 +834,30 @@ static int dprc_probe(struct fsl_mc_device *mc_dev)
 	int error;
 	size_t region_size;
 	struct fsl_mc_bus *mc_bus = to_fsl_mc_bus(mc_dev);
+	bool mc_io_created = false;
+	bool dev_root_set = false;
+	uint16_t dprc_version_major;
+	uint16_t dprc_version_minor;
 
 	if (WARN_ON(strcmp(mc_dev->obj_desc.type, "dprc") != 0))
 		return -EINVAL;
 
-	if (!mc_dev->mc_io) {
+	if (mc_dev->mc_io) {
+		/*
+		 * This is the root DPRC
+		 */
+		if (WARN_ON(fsl_mc_bus_type.dev_root))
+			return -EINVAL;
+
+		fsl_mc_bus_type.dev_root = &mc_dev->dev;
+		dev_root_set = true;
+	} else {
 		/*
-		 * This is a child DPRC:
+		 * This is a child DPRC
 		 */
+		if (WARN_ON(!fsl_mc_bus_type.dev_root))
+			return -EINVAL;
+
 		if (WARN_ON(mc_dev->obj_desc.region_count == 0))
 			return -EINVAL;
 
@@ -397,35 +870,165 @@ static int dprc_probe(struct fsl_mc_device *mc_dev)
 					 NULL, 0, &mc_dev->mc_io);
 		if (error < 0)
 			return error;
+
+		mc_io_created = true;
 	}
 
-	error = dprc_open(mc_dev->mc_io, mc_dev->obj_desc.id,
+	error = dprc_open(mc_dev->mc_io, 0, mc_dev->obj_desc.id,
 			  &mc_dev->mc_handle);
 	if (error < 0) {
 		dev_err(&mc_dev->dev, "dprc_open() failed: %d\n", error);
 		goto error_cleanup_mc_io;
 	}
 
+	/* check if MC supports compatible DPRC type version */
+	error = dprc_get_api_version(mc_dev->mc_io, 0,
+			&dprc_version_major, &dprc_version_minor);
+	if (error < 0) {
+		dev_err(&mc_dev->dev, "dprc_get_api_version() failed: %d\n",
+			error);
+		goto error_cleanup_open;
+	}
+
+	if (dprc_version_major < DPRC_MIN_VER_MAJOR ||
+	   (dprc_version_major == DPRC_MIN_VER_MAJOR &&
+		dprc_version_minor < DPRC_MIN_VER_MINOR)) {
+		dev_err(&mc_dev->dev,
+			"ERROR: DPRC version %d.%d not supported\n",
+			dprc_version_major,
+			dprc_version_minor);
+		error = -ENOTSUPP;
+		goto error_cleanup_open;
+	}
+
+	/* get container portal id */
+	error = dprc_get_attributes(mc_dev->mc_io, 0, mc_dev->mc_handle,
+				    &mc_bus->dprc_attr);
+	if (error < 0) {
+		dev_err(&mc_dev->dev, "dprc_get_attributes() failed: %d\n",
+			error);
+		goto error_cleanup_open;
+	}
+
+	if (fsl_mc_interrupts_supported()) {
+		/*
+		 * Create DPMCP for the DPRC's built-in portal:
+		 */
+		error = dprc_create_dpmcp(mc_dev);
+		if (error < 0)
+			goto error_cleanup_open;
+	}
+
 	mutex_init(&mc_bus->scan_mutex);
 
 	/*
-	 * Discover MC objects in DPRC object:
+	 * Discover MC objects in the DPRC object:
 	 */
 	error = dprc_scan_container(mc_dev);
 	if (error < 0)
-		goto error_cleanup_open;
+		goto error_destroy_dpmcp;
+
+	if (fsl_mc_interrupts_supported()) {
+		/*
+		 * The fsl_mc_device object associated with the DPMCP object
+		 * created above was created as part of the
+		 * dprc_scan_container() call above:
+		 */
+		if (WARN_ON(!mc_dev->mc_io->dpmcp_dev)) {
+			error = -EINVAL;
+			goto error_cleanup_dprc_scan;
+		}
+
+		/*
+		 * Allocate MC portal to be used in atomic context
+		 * (e.g., to program MSIs from program_msi_at_mc())
+		 */
+		error = fsl_mc_portal_allocate(NULL,
+					       FSL_MC_IO_ATOMIC_CONTEXT_PORTAL,
+					       &mc_bus->atomic_mc_io);
+		if (error < 0)
+			goto error_cleanup_dprc_scan;
+
+		pr_info("fsl-mc: Allocated dpmcp.%d to dprc.%d for atomic MC I/O\n",
+			mc_bus->atomic_mc_io->dpmcp_dev->obj_desc.id,
+			mc_dev->obj_desc.id);
+
+		/*
+		 * Open DPRC handle to be used with mc_bus->atomic_mc_io:
+		 */
+		error = dprc_open(mc_bus->atomic_mc_io, 0, mc_dev->obj_desc.id,
+				  &mc_bus->atomic_dprc_handle);
+		if (error < 0) {
+			dev_err(&mc_dev->dev, "dprc_open() failed: %d\n",
+				error);
+			goto error_cleanup_atomic_mc_io;
+		}
+
+		/*
+		 * Configure interrupt for the DPMCP object associated with the
+		 * DPRC object's built-in portal:
+		 *
+		 * NOTE: We have to do this after calling dprc_scan_container(),
+		 * since dprc_scan_container() populates the IRQ pool for
+		 * this DPRC.
+		 */
+		error = fsl_mc_io_setup_dpmcp_irq(mc_dev->mc_io);
+		if (error < 0)
+			goto error_cleanup_atomic_dprc_handle;
+
+		/*
+		 * Configure interrupts for the DPRC object associated with
+		 * this MC bus:
+		 */
+		error = dprc_setup_irqs(mc_dev);
+		if (error < 0)
+			goto error_cleanup_atomic_dprc_handle;
+	}
 
 	dev_info(&mc_dev->dev, "DPRC device bound to driver");
 	return 0;
 
+error_cleanup_atomic_dprc_handle:
+	(void)dprc_close(mc_bus->atomic_mc_io, 0, mc_bus->atomic_dprc_handle);
+
+error_cleanup_atomic_mc_io:
+	fsl_mc_portal_free(mc_bus->atomic_mc_io);
+
+error_cleanup_dprc_scan:
+	fsl_mc_io_unset_dpmcp(mc_dev->mc_io);
+	device_for_each_child(&mc_dev->dev, NULL, __fsl_mc_device_remove);
+	dprc_cleanup_all_resource_pools(mc_dev);
+	if (fsl_mc_interrupts_supported())
+		fsl_mc_cleanup_irq_pool(mc_bus);
+
+error_destroy_dpmcp:
+	dprc_destroy_dpmcp(mc_dev);
+
 error_cleanup_open:
-	(void)dprc_close(mc_dev->mc_io, mc_dev->mc_handle);
+	(void)dprc_close(mc_dev->mc_io, 0, mc_dev->mc_handle);
 
 error_cleanup_mc_io:
-	fsl_destroy_mc_io(mc_dev->mc_io);
+	if (mc_io_created) {
+		fsl_destroy_mc_io(mc_dev->mc_io);
+		mc_dev->mc_io = NULL;
+	}
+
+	if (dev_root_set)
+		fsl_mc_bus_type.dev_root = NULL;
+
 	return error;
 }
 
+/*
+ * Tear down interrupts for a given DPRC object
+ */
+static void dprc_teardown_irqs(struct fsl_mc_device *mc_dev)
+{
+	(void)disable_dprc_irqs(mc_dev);
+	unregister_dprc_irq_handlers(mc_dev);
+	fsl_mc_free_irqs(mc_dev);
+}
+
 /**
  * dprc_remove - callback invoked when a DPRC is being unbound from this driver
  *
@@ -439,18 +1042,45 @@ error_cleanup_mc_io:
 static int dprc_remove(struct fsl_mc_device *mc_dev)
 {
 	int error;
+	struct fsl_mc_bus *mc_bus = to_fsl_mc_bus(mc_dev);
 
 	if (WARN_ON(strcmp(mc_dev->obj_desc.type, "dprc") != 0))
 		return -EINVAL;
 	if (WARN_ON(!mc_dev->mc_io))
 		return -EINVAL;
 
+	if (WARN_ON(!mc_bus->irq_resources))
+		return -EINVAL;
+
+	if (fsl_mc_interrupts_supported()) {
+		dprc_teardown_irqs(mc_dev);
+		error = dprc_close(mc_bus->atomic_mc_io, 0,
+				   mc_bus->atomic_dprc_handle);
+		if (error < 0) {
+			dev_err(&mc_dev->dev, "dprc_close() failed: %d\n",
+				error);
+		}
+
+		fsl_mc_portal_free(mc_bus->atomic_mc_io);
+	}
+
+	fsl_mc_io_unset_dpmcp(mc_dev->mc_io);
 	device_for_each_child(&mc_dev->dev, NULL, __fsl_mc_device_remove);
 	dprc_cleanup_all_resource_pools(mc_dev);
-	error = dprc_close(mc_dev->mc_io, mc_dev->mc_handle);
+	dprc_destroy_dpmcp(mc_dev);
+	error = dprc_close(mc_dev->mc_io, 0, mc_dev->mc_handle);
 	if (error < 0)
 		dev_err(&mc_dev->dev, "dprc_close() failed: %d\n", error);
 
+	if (fsl_mc_interrupts_supported())
+		fsl_mc_cleanup_irq_pool(mc_bus);
+
+	fsl_destroy_mc_io(mc_dev->mc_io);
+	mc_dev->mc_io = NULL;
+
+	if (&mc_dev->dev == fsl_mc_bus_type.dev_root)
+		fsl_mc_bus_type.dev_root = NULL;
+
 	dev_info(&mc_dev->dev, "DPRC device unbound from driver");
 	return 0;
 }
@@ -458,9 +1088,7 @@ static int dprc_remove(struct fsl_mc_device *mc_dev)
 static const struct fsl_mc_device_match_id match_id_table[] = {
 	{
 	 .vendor = FSL_MC_VENDOR_FREESCALE,
-	 .obj_type = "dprc",
-	 .ver_major = DPRC_VER_MAJOR,
-	 .ver_minor = DPRC_VER_MINOR},
+	 .obj_type = "dprc"},
 	{.vendor = 0x0},
 };
 
diff --git a/drivers/staging/fsl-mc/bus/dprc.c b/drivers/staging/fsl-mc/bus/dprc.c
index 19b26e6..63be171 100644
--- a/drivers/staging/fsl-mc/bus/dprc.c
+++ b/drivers/staging/fsl-mc/bus/dprc.c
@@ -1,4 +1,4 @@
-/* Copyright 2013-2014 Freescale Semiconductor Inc.
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
@@ -34,13 +34,39 @@
 #include "../include/dprc.h"
 #include "dprc-cmd.h"
 
-int dprc_open(struct fsl_mc_io *mc_io, int container_id, uint16_t *token)
+int dprc_get_container_id(struct fsl_mc_io *mc_io,
+			  uint32_t cmd_flags,
+			  int *container_id)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
 	/* prepare command */
-	cmd.header = mc_encode_cmd_header(DPRC_CMDID_OPEN, MC_CMD_PRI_LOW,
+	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_CONT_ID,
+					  cmd_flags,
+					  0);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	*container_id = (int)get_mc_cmd_create_object_id(&cmd);
+
+	return 0;
+}
+EXPORT_SYMBOL(dprc_get_container_id);
+int dprc_open(struct fsl_mc_io *mc_io,
+	      uint32_t cmd_flags,
+	      int container_id,
+	      uint16_t *token)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPRC_CMDID_OPEN, cmd_flags,
 					  0);
 	cmd.params[0] |= mc_enc(0, 32, container_id);
 
@@ -50,18 +76,20 @@ int dprc_open(struct fsl_mc_io *mc_io, int container_id, uint16_t *token)
 		return err;
 
 	/* retrieve response parameters */
-	*token = MC_CMD_HDR_READ_TOKEN(cmd.header);
+	*token = get_mc_cmd_hdr_token(cmd.header);
 
 	return 0;
 }
 EXPORT_SYMBOL(dprc_open);
 
-int dprc_close(struct fsl_mc_io *mc_io, uint16_t token)
+int dprc_close(struct fsl_mc_io *mc_io,
+	       uint32_t cmd_flags,
+	       uint16_t token)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
-	cmd.header = mc_encode_cmd_header(DPRC_CMDID_CLOSE, MC_CMD_PRI_HIGH,
+	cmd.header = mc_encode_cmd_header(DPRC_CMDID_CLOSE, cmd_flags,
 					  token);
 
 	/* send command to mc*/
@@ -70,10 +98,11 @@ int dprc_close(struct fsl_mc_io *mc_io, uint16_t token)
 EXPORT_SYMBOL(dprc_close);
 
 int dprc_create_container(struct fsl_mc_io *mc_io,
+			  uint32_t cmd_flags,
 			  uint16_t token,
 			  struct dprc_cfg *cfg,
 			  int *child_container_id,
-			  uint64_t *child_portal_paddr)
+			  uint64_t *child_portal_offset)
 {
 	struct mc_command cmd = { 0 };
 	int err;
@@ -82,9 +111,26 @@ int dprc_create_container(struct fsl_mc_io *mc_io,
 	cmd.params[0] |= mc_enc(32, 16, cfg->icid);
 	cmd.params[0] |= mc_enc(0, 32, cfg->options);
 	cmd.params[1] |= mc_enc(32, 32, cfg->portal_id);
+	cmd.params[2] |= mc_enc(0, 8, cfg->label[0]);
+	cmd.params[2] |= mc_enc(8, 8, cfg->label[1]);
+	cmd.params[2] |= mc_enc(16, 8, cfg->label[2]);
+	cmd.params[2] |= mc_enc(24, 8, cfg->label[3]);
+	cmd.params[2] |= mc_enc(32, 8, cfg->label[4]);
+	cmd.params[2] |= mc_enc(40, 8, cfg->label[5]);
+	cmd.params[2] |= mc_enc(48, 8, cfg->label[6]);
+	cmd.params[2] |= mc_enc(56, 8, cfg->label[7]);
+	cmd.params[3] |= mc_enc(0, 8, cfg->label[8]);
+	cmd.params[3] |= mc_enc(8, 8, cfg->label[9]);
+	cmd.params[3] |= mc_enc(16, 8, cfg->label[10]);
+	cmd.params[3] |= mc_enc(24, 8, cfg->label[11]);
+	cmd.params[3] |= mc_enc(32, 8, cfg->label[12]);
+	cmd.params[3] |= mc_enc(40, 8, cfg->label[13]);
+	cmd.params[3] |= mc_enc(48, 8, cfg->label[14]);
+	cmd.params[3] |= mc_enc(56, 8, cfg->label[15]);
 
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_CREATE_CONT,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 
 	/* send command to mc*/
 	err = mc_send_command(mc_io, &cmd);
@@ -93,12 +139,14 @@ int dprc_create_container(struct fsl_mc_io *mc_io,
 
 	/* retrieve response parameters */
 	*child_container_id = mc_dec(cmd.params[1], 0, 32);
-	*child_portal_paddr = mc_dec(cmd.params[2], 0, 64);
+	*child_portal_offset = mc_dec(cmd.params[2], 0, 64);
 
 	return 0;
 }
+EXPORT_SYMBOL(dprc_create_container);
 
 int dprc_destroy_container(struct fsl_mc_io *mc_io,
+			   uint32_t cmd_flags,
 			   uint16_t token,
 			   int child_container_id)
 {
@@ -106,14 +154,17 @@ int dprc_destroy_container(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_DESTROY_CONT,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(0, 32, child_container_id);
 
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
+EXPORT_SYMBOL(dprc_destroy_container);
 
 int dprc_reset_container(struct fsl_mc_io *mc_io,
+			 uint32_t cmd_flags,
 			 uint16_t token,
 			 int child_container_id)
 {
@@ -121,27 +172,28 @@ int dprc_reset_container(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_RESET_CONT,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(0, 32, child_container_id);
 
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
+EXPORT_SYMBOL(dprc_reset_container);
 
 int dprc_get_irq(struct fsl_mc_io *mc_io,
+		 uint32_t cmd_flags,
 		 uint16_t token,
 		 uint8_t irq_index,
 		 int *type,
-		 uint64_t *irq_paddr,
-		 uint32_t *irq_val,
-		 int *user_irq_id)
+		 struct dprc_irq_cfg *irq_cfg)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_IRQ,
-					  MC_CMD_PRI_LOW,
+					  cmd_flags,
 					  token);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
@@ -151,37 +203,39 @@ int dprc_get_irq(struct fsl_mc_io *mc_io,
 		return err;
 
 	/* retrieve response parameters */
-	*irq_val = mc_dec(cmd.params[0], 0, 32);
-	*irq_paddr = mc_dec(cmd.params[1], 0, 64);
-	*user_irq_id = mc_dec(cmd.params[2], 0, 32);
+	irq_cfg->val = mc_dec(cmd.params[0], 0, 32);
+	irq_cfg->paddr = mc_dec(cmd.params[1], 0, 64);
+	irq_cfg->irq_num = mc_dec(cmd.params[2], 0, 32);
 	*type = mc_dec(cmd.params[2], 32, 32);
 
 	return 0;
 }
+EXPORT_SYMBOL(dprc_get_irq);
 
 int dprc_set_irq(struct fsl_mc_io *mc_io,
+		 uint32_t cmd_flags,
 		 uint16_t token,
 		 uint8_t irq_index,
-		 uint64_t irq_paddr,
-		 uint32_t irq_val,
-		 int user_irq_id)
+		 struct dprc_irq_cfg *irq_cfg)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_SET_IRQ,
-					  MC_CMD_PRI_LOW,
+					  cmd_flags,
 					  token);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
-	cmd.params[0] |= mc_enc(0, 32, irq_val);
-	cmd.params[1] |= mc_enc(0, 64, irq_paddr);
-	cmd.params[2] |= mc_enc(0, 32, user_irq_id);
+	cmd.params[0] |= mc_enc(0, 32, irq_cfg->val);
+	cmd.params[1] |= mc_enc(0, 64, irq_cfg->paddr);
+	cmd.params[2] |= mc_enc(0, 32, irq_cfg->irq_num);
 
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
+EXPORT_SYMBOL(dprc_set_irq);
 
 int dprc_get_irq_enable(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
 			uint16_t token,
 			uint8_t irq_index,
 			uint8_t *en)
@@ -191,7 +245,8 @@ int dprc_get_irq_enable(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_IRQ_ENABLE,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
@@ -204,8 +259,10 @@ int dprc_get_irq_enable(struct fsl_mc_io *mc_io,
 
 	return 0;
 }
+EXPORT_SYMBOL(dprc_get_irq_enable);
 
 int dprc_set_irq_enable(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
 			uint16_t token,
 			uint8_t irq_index,
 			uint8_t en)
@@ -214,15 +271,18 @@ int dprc_set_irq_enable(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_SET_IRQ_ENABLE,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(0, 8, en);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
+EXPORT_SYMBOL(dprc_set_irq_enable);
 
 int dprc_get_irq_mask(struct fsl_mc_io *mc_io,
+		      uint32_t cmd_flags,
 		      uint16_t token,
 		      uint8_t irq_index,
 		      uint32_t *mask)
@@ -232,7 +292,8 @@ int dprc_get_irq_mask(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_IRQ_MASK,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
@@ -245,8 +306,10 @@ int dprc_get_irq_mask(struct fsl_mc_io *mc_io,
 
 	return 0;
 }
+EXPORT_SYMBOL(dprc_get_irq_mask);
 
 int dprc_set_irq_mask(struct fsl_mc_io *mc_io,
+		      uint32_t cmd_flags,
 		      uint16_t token,
 		      uint8_t irq_index,
 		      uint32_t mask)
@@ -255,15 +318,18 @@ int dprc_set_irq_mask(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_SET_IRQ_MASK,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(0, 32, mask);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
+EXPORT_SYMBOL(dprc_set_irq_mask);
 
 int dprc_get_irq_status(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
 			uint16_t token,
 			uint8_t irq_index,
 			uint32_t *status)
@@ -273,7 +339,9 @@ int dprc_get_irq_status(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_IRQ_STATUS,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
+	cmd.params[0] |= mc_enc(0, 32, *status);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
@@ -286,8 +354,10 @@ int dprc_get_irq_status(struct fsl_mc_io *mc_io,
 
 	return 0;
 }
+EXPORT_SYMBOL(dprc_get_irq_status);
 
 int dprc_clear_irq_status(struct fsl_mc_io *mc_io,
+			  uint32_t cmd_flags,
 			  uint16_t token,
 			  uint8_t irq_index,
 			  uint32_t status)
@@ -296,15 +366,18 @@ int dprc_clear_irq_status(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_CLEAR_IRQ_STATUS,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(0, 32, status);
 	cmd.params[0] |= mc_enc(32, 8, irq_index);
 
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
+EXPORT_SYMBOL(dprc_clear_irq_status);
 
 int dprc_get_attributes(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
 			uint16_t token,
 			struct dprc_attributes *attr)
 {
@@ -313,7 +386,7 @@ int dprc_get_attributes(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_ATTR,
-					  MC_CMD_PRI_LOW,
+					  cmd_flags,
 					  token);
 
 	/* send command to mc*/
@@ -326,13 +399,13 @@ int dprc_get_attributes(struct fsl_mc_io *mc_io,
 	attr->icid = mc_dec(cmd.params[0], 32, 16);
 	attr->options = mc_dec(cmd.params[1], 0, 32);
 	attr->portal_id = mc_dec(cmd.params[1], 32, 32);
-	attr->version.major = mc_dec(cmd.params[2], 0, 16);
-	attr->version.minor = mc_dec(cmd.params[2], 16, 16);
 
 	return 0;
 }
+EXPORT_SYMBOL(dprc_get_attributes);
 
 int dprc_set_res_quota(struct fsl_mc_io *mc_io,
+		       uint32_t cmd_flags,
 		       uint16_t token,
 		       int child_container_id,
 		       char *type,
@@ -342,7 +415,8 @@ int dprc_set_res_quota(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_SET_RES_QUOTA,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(0, 32, child_container_id);
 	cmd.params[0] |= mc_enc(32, 16, quota);
 	cmd.params[1] |= mc_enc(0, 8, type[0]);
@@ -365,8 +439,10 @@ int dprc_set_res_quota(struct fsl_mc_io *mc_io,
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
+EXPORT_SYMBOL(dprc_set_res_quota);
 
 int dprc_get_res_quota(struct fsl_mc_io *mc_io,
+		       uint32_t cmd_flags,
 		       uint16_t token,
 		       int child_container_id,
 		       char *type,
@@ -377,7 +453,8 @@ int dprc_get_res_quota(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_RES_QUOTA,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(0, 32, child_container_id);
 	cmd.params[1] |= mc_enc(0, 8, type[0]);
 	cmd.params[1] |= mc_enc(8, 8, type[1]);
@@ -406,8 +483,10 @@ int dprc_get_res_quota(struct fsl_mc_io *mc_io,
 
 	return 0;
 }
+EXPORT_SYMBOL(dprc_get_res_quota);
 
 int dprc_assign(struct fsl_mc_io *mc_io,
+		uint32_t cmd_flags,
 		uint16_t token,
 		int container_id,
 		struct dprc_res_req *res_req)
@@ -416,7 +495,8 @@ int dprc_assign(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_ASSIGN,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(0, 32, container_id);
 	cmd.params[0] |= mc_enc(32, 32, res_req->options);
 	cmd.params[1] |= mc_enc(0, 32, res_req->num);
@@ -441,8 +521,10 @@ int dprc_assign(struct fsl_mc_io *mc_io,
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
+EXPORT_SYMBOL(dprc_assign);
 
 int dprc_unassign(struct fsl_mc_io *mc_io,
+		  uint32_t cmd_flags,
 		  uint16_t token,
 		  int child_container_id,
 		  struct dprc_res_req *res_req)
@@ -451,7 +533,7 @@ int dprc_unassign(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_UNASSIGN,
-					  MC_CMD_PRI_LOW,
+					  cmd_flags,
 					  token);
 	cmd.params[0] |= mc_enc(0, 32, child_container_id);
 	cmd.params[0] |= mc_enc(32, 32, res_req->options);
@@ -477,8 +559,10 @@ int dprc_unassign(struct fsl_mc_io *mc_io,
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
+EXPORT_SYMBOL(dprc_unassign);
 
 int dprc_get_pool_count(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
 			uint16_t token,
 			int *pool_count)
 {
@@ -487,7 +571,8 @@ int dprc_get_pool_count(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_POOL_COUNT,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 
 	/* send command to mc*/
 	err = mc_send_command(mc_io, &cmd);
@@ -499,8 +584,10 @@ int dprc_get_pool_count(struct fsl_mc_io *mc_io,
 
 	return 0;
 }
+EXPORT_SYMBOL(dprc_get_pool_count);
 
 int dprc_get_pool(struct fsl_mc_io *mc_io,
+		  uint32_t cmd_flags,
 		  uint16_t token,
 		  int pool_index,
 		  char *type)
@@ -510,7 +597,7 @@ int dprc_get_pool(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_POOL,
-					  MC_CMD_PRI_LOW,
+					  cmd_flags,
 					  token);
 	cmd.params[0] |= mc_enc(0, 32, pool_index);
 
@@ -539,15 +626,20 @@ int dprc_get_pool(struct fsl_mc_io *mc_io,
 
 	return 0;
 }
+EXPORT_SYMBOL(dprc_get_pool);
 
-int dprc_get_obj_count(struct fsl_mc_io *mc_io, uint16_t token, int *obj_count)
+int dprc_get_obj_count(struct fsl_mc_io *mc_io,
+		       uint32_t cmd_flags,
+		       uint16_t token,
+		       int *obj_count)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_OBJ_COUNT,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 
 	/* send command to mc*/
 	err = mc_send_command(mc_io, &cmd);
@@ -562,6 +654,7 @@ int dprc_get_obj_count(struct fsl_mc_io *mc_io, uint16_t token, int *obj_count)
 EXPORT_SYMBOL(dprc_get_obj_count);
 
 int dprc_get_obj(struct fsl_mc_io *mc_io,
+		 uint32_t cmd_flags,
 		 uint16_t token,
 		 int obj_index,
 		 struct dprc_obj_desc *obj_desc)
@@ -571,7 +664,7 @@ int dprc_get_obj(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_OBJ,
-					  MC_CMD_PRI_LOW,
+					  cmd_flags,
 					  token);
 	cmd.params[0] |= mc_enc(0, 32, obj_index);
 
@@ -588,6 +681,7 @@ int dprc_get_obj(struct fsl_mc_io *mc_io,
 	obj_desc->state = mc_dec(cmd.params[1], 32, 32);
 	obj_desc->ver_major = mc_dec(cmd.params[2], 0, 16);
 	obj_desc->ver_minor = mc_dec(cmd.params[2], 16, 16);
+	obj_desc->flags = mc_dec(cmd.params[2], 32, 16);
 	obj_desc->type[0] = mc_dec(cmd.params[3], 0, 8);
 	obj_desc->type[1] = mc_dec(cmd.params[3], 8, 8);
 	obj_desc->type[2] = mc_dec(cmd.params[3], 16, 8);
@@ -604,12 +698,202 @@ int dprc_get_obj(struct fsl_mc_io *mc_io,
 	obj_desc->type[13] = mc_dec(cmd.params[4], 40, 8);
 	obj_desc->type[14] = mc_dec(cmd.params[4], 48, 8);
 	obj_desc->type[15] = '\0';
-
+	obj_desc->label[0] = mc_dec(cmd.params[5], 0, 8);
+	obj_desc->label[1] = mc_dec(cmd.params[5], 8, 8);
+	obj_desc->label[2] = mc_dec(cmd.params[5], 16, 8);
+	obj_desc->label[3] = mc_dec(cmd.params[5], 24, 8);
+	obj_desc->label[4] = mc_dec(cmd.params[5], 32, 8);
+	obj_desc->label[5] = mc_dec(cmd.params[5], 40, 8);
+	obj_desc->label[6] = mc_dec(cmd.params[5], 48, 8);
+	obj_desc->label[7] = mc_dec(cmd.params[5], 56, 8);
+	obj_desc->label[8] = mc_dec(cmd.params[6], 0, 8);
+	obj_desc->label[9] = mc_dec(cmd.params[6], 8, 8);
+	obj_desc->label[10] = mc_dec(cmd.params[6], 16, 8);
+	obj_desc->label[11] = mc_dec(cmd.params[6], 24, 8);
+	obj_desc->label[12] = mc_dec(cmd.params[6], 32, 8);
+	obj_desc->label[13] = mc_dec(cmd.params[6], 40, 8);
+	obj_desc->label[14] = mc_dec(cmd.params[6], 48, 8);
+	obj_desc->label[15] = '\0';
 	return 0;
 }
 EXPORT_SYMBOL(dprc_get_obj);
 
+int dprc_get_obj_desc(struct fsl_mc_io *mc_io,
+		      uint32_t cmd_flags,
+		      uint16_t token,
+		      char *obj_type,
+		      int obj_id,
+		      struct dprc_obj_desc *obj_desc)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_OBJ_DESC,
+					  cmd_flags,
+					  token);
+	cmd.params[0] |= mc_enc(0, 32, obj_id);
+	cmd.params[1] |= mc_enc(0, 8, obj_type[0]);
+	cmd.params[1] |= mc_enc(8, 8, obj_type[1]);
+	cmd.params[1] |= mc_enc(16, 8, obj_type[2]);
+	cmd.params[1] |= mc_enc(24, 8, obj_type[3]);
+	cmd.params[1] |= mc_enc(32, 8, obj_type[4]);
+	cmd.params[1] |= mc_enc(40, 8, obj_type[5]);
+	cmd.params[1] |= mc_enc(48, 8, obj_type[6]);
+	cmd.params[1] |= mc_enc(56, 8, obj_type[7]);
+	cmd.params[2] |= mc_enc(0, 8, obj_type[8]);
+	cmd.params[2] |= mc_enc(8, 8, obj_type[9]);
+	cmd.params[2] |= mc_enc(16, 8, obj_type[10]);
+	cmd.params[2] |= mc_enc(24, 8, obj_type[11]);
+	cmd.params[2] |= mc_enc(32, 8, obj_type[12]);
+	cmd.params[2] |= mc_enc(40, 8, obj_type[13]);
+	cmd.params[2] |= mc_enc(48, 8, obj_type[14]);
+	cmd.params[2] |= mc_enc(56, 8, obj_type[15]);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	obj_desc->id = (int)mc_dec(cmd.params[0], 32, 32);
+	obj_desc->vendor = (uint16_t)mc_dec(cmd.params[1], 0, 16);
+	obj_desc->vendor = (uint8_t)mc_dec(cmd.params[1], 16, 8);
+	obj_desc->region_count = (uint8_t)mc_dec(cmd.params[1], 24, 8);
+	obj_desc->state = (uint32_t)mc_dec(cmd.params[1], 32, 32);
+	obj_desc->ver_major = (uint16_t)mc_dec(cmd.params[2], 0, 16);
+	obj_desc->ver_minor = (uint16_t)mc_dec(cmd.params[2], 16, 16);
+	obj_desc->flags = mc_dec(cmd.params[2], 32, 16);
+	obj_desc->type[0] = (char)mc_dec(cmd.params[3], 0, 8);
+	obj_desc->type[1] = (char)mc_dec(cmd.params[3], 8, 8);
+	obj_desc->type[2] = (char)mc_dec(cmd.params[3], 16, 8);
+	obj_desc->type[3] = (char)mc_dec(cmd.params[3], 24, 8);
+	obj_desc->type[4] = (char)mc_dec(cmd.params[3], 32, 8);
+	obj_desc->type[5] = (char)mc_dec(cmd.params[3], 40, 8);
+	obj_desc->type[6] = (char)mc_dec(cmd.params[3], 48, 8);
+	obj_desc->type[7] = (char)mc_dec(cmd.params[3], 56, 8);
+	obj_desc->type[8] = (char)mc_dec(cmd.params[4], 0, 8);
+	obj_desc->type[9] = (char)mc_dec(cmd.params[4], 8, 8);
+	obj_desc->type[10] = (char)mc_dec(cmd.params[4], 16, 8);
+	obj_desc->type[11] = (char)mc_dec(cmd.params[4], 24, 8);
+	obj_desc->type[12] = (char)mc_dec(cmd.params[4], 32, 8);
+	obj_desc->type[13] = (char)mc_dec(cmd.params[4], 40, 8);
+	obj_desc->type[14] = (char)mc_dec(cmd.params[4], 48, 8);
+	obj_desc->type[15] = (char)mc_dec(cmd.params[4], 56, 8);
+	obj_desc->label[0] = (char)mc_dec(cmd.params[5], 0, 8);
+	obj_desc->label[1] = (char)mc_dec(cmd.params[5], 8, 8);
+	obj_desc->label[2] = (char)mc_dec(cmd.params[5], 16, 8);
+	obj_desc->label[3] = (char)mc_dec(cmd.params[5], 24, 8);
+	obj_desc->label[4] = (char)mc_dec(cmd.params[5], 32, 8);
+	obj_desc->label[5] = (char)mc_dec(cmd.params[5], 40, 8);
+	obj_desc->label[6] = (char)mc_dec(cmd.params[5], 48, 8);
+	obj_desc->label[7] = (char)mc_dec(cmd.params[5], 56, 8);
+	obj_desc->label[8] = (char)mc_dec(cmd.params[6], 0, 8);
+	obj_desc->label[9] = (char)mc_dec(cmd.params[6], 8, 8);
+	obj_desc->label[10] = (char)mc_dec(cmd.params[6], 16, 8);
+	obj_desc->label[11] = (char)mc_dec(cmd.params[6], 24, 8);
+	obj_desc->label[12] = (char)mc_dec(cmd.params[6], 32, 8);
+	obj_desc->label[13] = (char)mc_dec(cmd.params[6], 40, 8);
+	obj_desc->label[14] = (char)mc_dec(cmd.params[6], 48, 8);
+	obj_desc->label[15] = (char)mc_dec(cmd.params[6], 56, 8);
+
+	return 0;
+}
+EXPORT_SYMBOL(dprc_get_obj_desc);
+
+int dprc_set_obj_irq(struct fsl_mc_io *mc_io,
+		     uint32_t cmd_flags,
+		     uint16_t token,
+		     char *obj_type,
+		     int obj_id,
+		     uint8_t irq_index,
+		     struct dprc_irq_cfg *irq_cfg)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPRC_CMDID_SET_OBJ_IRQ,
+					  cmd_flags,
+					  token);
+	cmd.params[0] |= mc_enc(32, 8, irq_index);
+	cmd.params[0] |= mc_enc(0, 32, irq_cfg->val);
+	cmd.params[1] |= mc_enc(0, 64, irq_cfg->paddr);
+	cmd.params[2] |= mc_enc(0, 32, irq_cfg->irq_num);
+	cmd.params[2] |= mc_enc(32, 32, obj_id);
+	cmd.params[3] |= mc_enc(0, 8, obj_type[0]);
+	cmd.params[3] |= mc_enc(8, 8, obj_type[1]);
+	cmd.params[3] |= mc_enc(16, 8, obj_type[2]);
+	cmd.params[3] |= mc_enc(24, 8, obj_type[3]);
+	cmd.params[3] |= mc_enc(32, 8, obj_type[4]);
+	cmd.params[3] |= mc_enc(40, 8, obj_type[5]);
+	cmd.params[3] |= mc_enc(48, 8, obj_type[6]);
+	cmd.params[3] |= mc_enc(56, 8, obj_type[7]);
+	cmd.params[4] |= mc_enc(0, 8, obj_type[8]);
+	cmd.params[4] |= mc_enc(8, 8, obj_type[9]);
+	cmd.params[4] |= mc_enc(16, 8, obj_type[10]);
+	cmd.params[4] |= mc_enc(24, 8, obj_type[11]);
+	cmd.params[4] |= mc_enc(32, 8, obj_type[12]);
+	cmd.params[4] |= mc_enc(40, 8, obj_type[13]);
+	cmd.params[4] |= mc_enc(48, 8, obj_type[14]);
+	cmd.params[4] |= mc_enc(56, 8, obj_type[15]);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+EXPORT_SYMBOL(dprc_set_obj_irq);
+
+int dprc_get_obj_irq(struct fsl_mc_io *mc_io,
+		     uint32_t cmd_flags,
+		     uint16_t token,
+		     char *obj_type,
+		     int obj_id,
+		     uint8_t irq_index,
+		     int *type,
+		     struct dprc_irq_cfg *irq_cfg)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_OBJ_IRQ,
+					  cmd_flags,
+					  token);
+	cmd.params[0] |= mc_enc(0, 32, obj_id);
+	cmd.params[0] |= mc_enc(32, 8, irq_index);
+	cmd.params[1] |= mc_enc(0, 8, obj_type[0]);
+	cmd.params[1] |= mc_enc(8, 8, obj_type[1]);
+	cmd.params[1] |= mc_enc(16, 8, obj_type[2]);
+	cmd.params[1] |= mc_enc(24, 8, obj_type[3]);
+	cmd.params[1] |= mc_enc(32, 8, obj_type[4]);
+	cmd.params[1] |= mc_enc(40, 8, obj_type[5]);
+	cmd.params[1] |= mc_enc(48, 8, obj_type[6]);
+	cmd.params[1] |= mc_enc(56, 8, obj_type[7]);
+	cmd.params[2] |= mc_enc(0, 8, obj_type[8]);
+	cmd.params[2] |= mc_enc(8, 8, obj_type[9]);
+	cmd.params[2] |= mc_enc(16, 8, obj_type[10]);
+	cmd.params[2] |= mc_enc(24, 8, obj_type[11]);
+	cmd.params[2] |= mc_enc(32, 8, obj_type[12]);
+	cmd.params[2] |= mc_enc(40, 8, obj_type[13]);
+	cmd.params[2] |= mc_enc(48, 8, obj_type[14]);
+	cmd.params[2] |= mc_enc(56, 8, obj_type[15]);
+
+	/* send command to mc*/
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	/* retrieve response parameters */
+	irq_cfg->val = (uint32_t)mc_dec(cmd.params[0], 0, 32);
+	irq_cfg->paddr = (uint64_t)mc_dec(cmd.params[1], 0, 64);
+	irq_cfg->irq_num = (int)mc_dec(cmd.params[2], 0, 32);
+	*type = (int)mc_dec(cmd.params[2], 32, 32);
+
+	return 0;
+}
+EXPORT_SYMBOL(dprc_get_obj_irq);
+
 int dprc_get_res_count(struct fsl_mc_io *mc_io,
+		       uint32_t cmd_flags,
 		       uint16_t token,
 		       char *type,
 		       int *res_count)
@@ -621,7 +905,8 @@ int dprc_get_res_count(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_RES_COUNT,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[1] |= mc_enc(0, 8, type[0]);
 	cmd.params[1] |= mc_enc(8, 8, type[1]);
 	cmd.params[1] |= mc_enc(16, 8, type[2]);
@@ -652,6 +937,7 @@ int dprc_get_res_count(struct fsl_mc_io *mc_io,
 EXPORT_SYMBOL(dprc_get_res_count);
 
 int dprc_get_res_ids(struct fsl_mc_io *mc_io,
+		     uint32_t cmd_flags,
 		     uint16_t token,
 		     char *type,
 		     struct dprc_res_ids_range_desc *range_desc)
@@ -661,7 +947,8 @@ int dprc_get_res_ids(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_RES_IDS,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(42, 7, range_desc->iter_status);
 	cmd.params[1] |= mc_enc(0, 32, range_desc->base_id);
 	cmd.params[1] |= mc_enc(32, 32, range_desc->last_id);
@@ -696,32 +983,8 @@ int dprc_get_res_ids(struct fsl_mc_io *mc_io,
 }
 EXPORT_SYMBOL(dprc_get_res_ids);
 
-int dprc_get_portal_paddr(struct fsl_mc_io *mc_io,
-			  uint16_t token,
-			  int portal_id,
-			  uint64_t *portal_addr)
-{
-	struct mc_command cmd = { 0 };
-	int err;
-
-	/* prepare command */
-	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_PORTAL_PADDR,
-					  MC_CMD_PRI_LOW, token);
-	cmd.params[0] |= mc_enc(0, 32, portal_id);
-
-	/* send command to mc*/
-	err = mc_send_command(mc_io, &cmd);
-	if (err)
-		return err;
-
-	/* retrieve response parameters */
-	*portal_addr = mc_dec(cmd.params[1], 0, 64);
-
-	return 0;
-}
-EXPORT_SYMBOL(dprc_get_portal_paddr);
-
 int dprc_get_obj_region(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
 			uint16_t token,
 			char *obj_type,
 			int obj_id,
@@ -733,7 +996,8 @@ int dprc_get_obj_region(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_OBJ_REG,
-					  MC_CMD_PRI_LOW, token);
+					  cmd_flags,
+					  token);
 	cmd.params[0] |= mc_enc(0, 32, obj_id);
 	cmd.params[0] |= mc_enc(48, 8, region_index);
 	cmd.params[3] |= mc_enc(0, 8, obj_type[0]);
@@ -759,28 +1023,83 @@ int dprc_get_obj_region(struct fsl_mc_io *mc_io,
 		return err;
 
 	/* retrieve response parameters */
-	region_desc->base_paddr = mc_dec(cmd.params[1], 0, 64);
+	region_desc->base_offset = mc_dec(cmd.params[1], 0, 64);
 	region_desc->size = mc_dec(cmd.params[2], 0, 32);
 
 	return 0;
 }
 EXPORT_SYMBOL(dprc_get_obj_region);
 
+int dprc_set_obj_label(struct fsl_mc_io *mc_io,
+		       uint32_t cmd_flags,
+		       uint16_t  token,
+		       char *obj_type,
+		       int  obj_id,
+		       char *label)
+{
+	struct mc_command cmd = { 0 };
+
+	/* prepare command */
+	cmd.header = mc_encode_cmd_header(DPRC_CMDID_SET_OBJ_LABEL,
+					  cmd_flags,
+					  token);
+
+	cmd.params[0] |= mc_enc(0, 32, obj_id);
+	cmd.params[1] |= mc_enc(0, 8, label[0]);
+	cmd.params[1] |= mc_enc(8, 8, label[1]);
+	cmd.params[1] |= mc_enc(16, 8, label[2]);
+	cmd.params[1] |= mc_enc(24, 8, label[3]);
+	cmd.params[1] |= mc_enc(32, 8, label[4]);
+	cmd.params[1] |= mc_enc(40, 8, label[5]);
+	cmd.params[1] |= mc_enc(48, 8, label[6]);
+	cmd.params[1] |= mc_enc(56, 8, label[7]);
+	cmd.params[2] |= mc_enc(0, 8, label[8]);
+	cmd.params[2] |= mc_enc(8, 8, label[9]);
+	cmd.params[2] |= mc_enc(16, 8, label[10]);
+	cmd.params[2] |= mc_enc(24, 8, label[11]);
+	cmd.params[2] |= mc_enc(32, 8, label[12]);
+	cmd.params[2] |= mc_enc(40, 8, label[13]);
+	cmd.params[2] |= mc_enc(48, 8, label[14]);
+	cmd.params[2] |= mc_enc(56, 8, label[15]);
+	cmd.params[3] |= mc_enc(0, 8, obj_type[0]);
+	cmd.params[3] |= mc_enc(8, 8, obj_type[1]);
+	cmd.params[3] |= mc_enc(16, 8, obj_type[2]);
+	cmd.params[3] |= mc_enc(24, 8, obj_type[3]);
+	cmd.params[3] |= mc_enc(32, 8, obj_type[4]);
+	cmd.params[3] |= mc_enc(40, 8, obj_type[5]);
+	cmd.params[3] |= mc_enc(48, 8, obj_type[6]);
+	cmd.params[3] |= mc_enc(56, 8, obj_type[7]);
+	cmd.params[4] |= mc_enc(0, 8, obj_type[8]);
+	cmd.params[4] |= mc_enc(8, 8, obj_type[9]);
+	cmd.params[4] |= mc_enc(16, 8, obj_type[10]);
+	cmd.params[4] |= mc_enc(24, 8, obj_type[11]);
+	cmd.params[4] |= mc_enc(32, 8, obj_type[12]);
+	cmd.params[4] |= mc_enc(40, 8, obj_type[13]);
+	cmd.params[4] |= mc_enc(48, 8, obj_type[14]);
+	cmd.params[4] |= mc_enc(56, 8, obj_type[15]);
+
+	/* send command to mc*/
+	return mc_send_command(mc_io, &cmd);
+}
+EXPORT_SYMBOL(dprc_set_obj_label);
+
 int dprc_connect(struct fsl_mc_io *mc_io,
+		 uint32_t cmd_flags,
 		 uint16_t token,
 		 const struct dprc_endpoint *endpoint1,
-		 const struct dprc_endpoint *endpoint2)
+		 const struct dprc_endpoint *endpoint2,
+		 const struct dprc_connection_cfg *cfg)
 {
 	struct mc_command cmd = { 0 };
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_CONNECT,
-					  MC_CMD_PRI_LOW,
+					  cmd_flags,
 					  token);
 	cmd.params[0] |= mc_enc(0, 32, endpoint1->id);
-	cmd.params[0] |= mc_enc(32, 32, endpoint1->interface_id);
+	cmd.params[0] |= mc_enc(32, 32, endpoint1->if_id);
 	cmd.params[1] |= mc_enc(0, 32, endpoint2->id);
-	cmd.params[1] |= mc_enc(32, 32, endpoint2->interface_id);
+	cmd.params[1] |= mc_enc(32, 32, endpoint2->if_id);
 	cmd.params[2] |= mc_enc(0, 8, endpoint1->type[0]);
 	cmd.params[2] |= mc_enc(8, 8, endpoint1->type[1]);
 	cmd.params[2] |= mc_enc(16, 8, endpoint1->type[2]);
@@ -797,6 +1116,8 @@ int dprc_connect(struct fsl_mc_io *mc_io,
 	cmd.params[3] |= mc_enc(40, 8, endpoint1->type[13]);
 	cmd.params[3] |= mc_enc(48, 8, endpoint1->type[14]);
 	cmd.params[3] |= mc_enc(56, 8, endpoint1->type[15]);
+	cmd.params[4] |= mc_enc(0, 32, cfg->max_rate);
+	cmd.params[4] |= mc_enc(32, 32, cfg->committed_rate);
 	cmd.params[5] |= mc_enc(0, 8, endpoint2->type[0]);
 	cmd.params[5] |= mc_enc(8, 8, endpoint2->type[1]);
 	cmd.params[5] |= mc_enc(16, 8, endpoint2->type[2]);
@@ -817,8 +1138,10 @@ int dprc_connect(struct fsl_mc_io *mc_io,
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
+EXPORT_SYMBOL(dprc_connect);
 
 int dprc_disconnect(struct fsl_mc_io *mc_io,
+		    uint32_t cmd_flags,
 		    uint16_t token,
 		    const struct dprc_endpoint *endpoint)
 {
@@ -826,10 +1149,10 @@ int dprc_disconnect(struct fsl_mc_io *mc_io,
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_DISCONNECT,
-					  MC_CMD_PRI_LOW,
+					  cmd_flags,
 					  token);
 	cmd.params[0] |= mc_enc(0, 32, endpoint->id);
-	cmd.params[0] |= mc_enc(32, 32, endpoint->interface_id);
+	cmd.params[0] |= mc_enc(32, 32, endpoint->if_id);
 	cmd.params[1] |= mc_enc(0, 8, endpoint->type[0]);
 	cmd.params[1] |= mc_enc(8, 8, endpoint->type[1]);
 	cmd.params[1] |= mc_enc(16, 8, endpoint->type[2]);
@@ -850,22 +1173,24 @@ int dprc_disconnect(struct fsl_mc_io *mc_io,
 	/* send command to mc*/
 	return mc_send_command(mc_io, &cmd);
 }
+EXPORT_SYMBOL(dprc_disconnect);
 
 int dprc_get_connection(struct fsl_mc_io *mc_io,
+			uint32_t cmd_flags,
 			uint16_t token,
-					const struct dprc_endpoint *endpoint1,
-					struct dprc_endpoint *endpoint2,
-					int *state)
+			const struct dprc_endpoint *endpoint1,
+			struct dprc_endpoint *endpoint2,
+			int *state)
 {
 	struct mc_command cmd = { 0 };
 	int err;
 
 	/* prepare command */
 	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_CONNECTION,
-					  MC_CMD_PRI_LOW,
+					  cmd_flags,
 					  token);
 	cmd.params[0] |= mc_enc(0, 32, endpoint1->id);
-	cmd.params[0] |= mc_enc(32, 32, endpoint1->interface_id);
+	cmd.params[0] |= mc_enc(32, 32, endpoint1->if_id);
 	cmd.params[1] |= mc_enc(0, 8, endpoint1->type[0]);
 	cmd.params[1] |= mc_enc(8, 8, endpoint1->type[1]);
 	cmd.params[1] |= mc_enc(16, 8, endpoint1->type[2]);
@@ -890,7 +1215,7 @@ int dprc_get_connection(struct fsl_mc_io *mc_io,
 
 	/* retrieve response parameters */
 	endpoint2->id = mc_dec(cmd.params[3], 0, 32);
-	endpoint2->interface_id = mc_dec(cmd.params[3], 32, 32);
+	endpoint2->if_id = mc_dec(cmd.params[3], 32, 32);
 	endpoint2->type[0] = mc_dec(cmd.params[4], 0, 8);
 	endpoint2->type[1] = mc_dec(cmd.params[4], 8, 8);
 	endpoint2->type[2] = mc_dec(cmd.params[4], 16, 8);
@@ -911,3 +1236,26 @@ int dprc_get_connection(struct fsl_mc_io *mc_io,
 
 	return 0;
 }
+EXPORT_SYMBOL(dprc_get_connection);
+
+int dprc_get_api_version(struct fsl_mc_io *mc_io,
+			   uint32_t cmd_flags,
+			   uint16_t *major_ver,
+			   uint16_t *minor_ver)
+{
+	struct mc_command cmd = { 0 };
+	int err;
+
+	cmd.header = mc_encode_cmd_header(DPRC_CMDID_GET_VERSION,
+					cmd_flags,
+					0);
+
+	err = mc_send_command(mc_io, &cmd);
+	if (err)
+		return err;
+
+	get_mc_cmd_object_api_ver(&cmd, major_ver, minor_ver);
+
+	return 0;
+}
+EXPORT_SYMBOL(dprc_get_api_version);
diff --git a/drivers/staging/fsl-mc/bus/mc-allocator.c b/drivers/staging/fsl-mc/bus/mc-allocator.c
index e36235d..a3940a0 100644
--- a/drivers/staging/fsl-mc/bus/mc-allocator.c
+++ b/drivers/staging/fsl-mc/bus/mc-allocator.c
@@ -111,7 +111,7 @@ static int __must_check fsl_mc_resource_pool_remove_device(struct fsl_mc_device
 		goto out;
 
 	resource = mc_dev->resource;
-	if (WARN_ON(resource->data != mc_dev))
+	if (WARN_ON(!resource || resource->data != mc_dev))
 		goto out;
 
 	mc_bus_dev = to_fsl_mc_device(mc_dev->dev.parent);
@@ -160,6 +160,7 @@ static const char *const fsl_mc_pool_type_strings[] = {
 	[FSL_MC_POOL_DPMCP] = "dpmcp",
 	[FSL_MC_POOL_DPBP] = "dpbp",
 	[FSL_MC_POOL_DPCON] = "dpcon",
+	[FSL_MC_POOL_IRQ] = "irq",
 };
 
 static int __must_check object_type_to_pool_type(const char *object_type,
@@ -284,12 +285,17 @@ int __must_check fsl_mc_portal_allocate(struct fsl_mc_device *mc_dev,
 	struct fsl_mc_bus *mc_bus;
 	phys_addr_t mc_portal_phys_addr;
 	size_t mc_portal_size;
-	struct fsl_mc_device *mc_adev;
+	struct fsl_mc_device *dpmcp_dev;
 	int error = -EINVAL;
 	struct fsl_mc_resource *resource = NULL;
 	struct fsl_mc_io *mc_io = NULL;
 
-	if (mc_dev->flags & FSL_MC_IS_DPRC) {
+	if (!mc_dev) {
+		if (WARN_ON(!fsl_mc_bus_type.dev_root))
+			return error;
+
+		mc_bus_dev = to_fsl_mc_device(fsl_mc_bus_type.dev_root);
+	} else if (mc_dev->flags & FSL_MC_IS_DPRC) {
 		mc_bus_dev = mc_dev;
 	} else {
 		if (WARN_ON(mc_dev->dev.parent->bus != &fsl_mc_bus_type))
@@ -304,23 +310,36 @@ int __must_check fsl_mc_portal_allocate(struct fsl_mc_device *mc_dev,
 	if (error < 0)
 		return error;
 
-	mc_adev = resource->data;
-	if (WARN_ON(!mc_adev))
+	error = -EINVAL;
+	dpmcp_dev = resource->data;
+	if (WARN_ON(!dpmcp_dev ||
+		    strcmp(dpmcp_dev->obj_desc.type, "dpmcp") != 0))
+		goto error_cleanup_resource;
+
+	if (dpmcp_dev->obj_desc.ver_major < DPMCP_MIN_VER_MAJOR ||
+	    (dpmcp_dev->obj_desc.ver_major == DPMCP_MIN_VER_MAJOR &&
+	     dpmcp_dev->obj_desc.ver_minor < DPMCP_MIN_VER_MINOR)) {
+		dev_err(&dpmcp_dev->dev,
+			"ERROR: Version %d.%d of DPMCP not supported.\n",
+			dpmcp_dev->obj_desc.ver_major,
+			dpmcp_dev->obj_desc.ver_minor);
+		error = -ENOTSUPP;
 		goto error_cleanup_resource;
+	}
 
-	if (WARN_ON(mc_adev->obj_desc.region_count == 0))
+	if (WARN_ON(dpmcp_dev->obj_desc.region_count == 0))
 		goto error_cleanup_resource;
 
-	mc_portal_phys_addr = mc_adev->regions[0].start;
-	mc_portal_size = mc_adev->regions[0].end -
-			 mc_adev->regions[0].start + 1;
+	mc_portal_phys_addr = dpmcp_dev->regions[0].start;
+	mc_portal_size = dpmcp_dev->regions[0].end -
+			 dpmcp_dev->regions[0].start + 1;
 
 	if (WARN_ON(mc_portal_size != mc_bus_dev->mc_io->portal_size))
 		goto error_cleanup_resource;
 
 	error = fsl_create_mc_io(&mc_bus_dev->dev,
 				 mc_portal_phys_addr,
-				 mc_portal_size, resource,
+				 mc_portal_size, dpmcp_dev,
 				 mc_io_flags, &mc_io);
 	if (error < 0)
 		goto error_cleanup_resource;
@@ -342,12 +361,26 @@ EXPORT_SYMBOL_GPL(fsl_mc_portal_allocate);
  */
 void fsl_mc_portal_free(struct fsl_mc_io *mc_io)
 {
+	struct fsl_mc_device *dpmcp_dev;
 	struct fsl_mc_resource *resource;
 
-	resource = mc_io->resource;
-	if (WARN_ON(resource->type != FSL_MC_POOL_DPMCP))
+	/*
+	 * Every mc_io obtained by calling fsl_mc_portal_allocate() is supposed
+	 * to have a DPMCP object associated with.
+	 */
+	dpmcp_dev = mc_io->dpmcp_dev;
+	if (WARN_ON(!dpmcp_dev))
+		return;
+	if (WARN_ON(strcmp(dpmcp_dev->obj_desc.type, "dpmcp") != 0))
+		return;
+	if (WARN_ON(dpmcp_dev->mc_io != mc_io))
+		return;
+
+	resource = dpmcp_dev->resource;
+	if (WARN_ON(!resource || resource->type != FSL_MC_POOL_DPMCP))
 		return;
-	if (WARN_ON(!resource->data))
+
+	if (WARN_ON(resource->data != dpmcp_dev))
 		return;
 
 	fsl_destroy_mc_io(mc_io);
@@ -363,31 +396,14 @@ EXPORT_SYMBOL_GPL(fsl_mc_portal_free);
 int fsl_mc_portal_reset(struct fsl_mc_io *mc_io)
 {
 	int error;
-	uint16_t token;
-	struct fsl_mc_resource *resource = mc_io->resource;
-	struct fsl_mc_device *mc_dev = resource->data;
+	struct fsl_mc_device *dpmcp_dev = mc_io->dpmcp_dev;
 
-	if (WARN_ON(resource->type != FSL_MC_POOL_DPMCP))
+	if (WARN_ON(!dpmcp_dev))
 		return -EINVAL;
 
-	if (WARN_ON(!mc_dev))
-		return -EINVAL;
-
-	error = dpmcp_open(mc_io, mc_dev->obj_desc.id, &token);
-	if (error < 0) {
-		dev_err(&mc_dev->dev, "dpmcp_open() failed: %d\n", error);
-		return error;
-	}
-
-	error = dpmcp_reset(mc_io, token);
-	if (error < 0) {
-		dev_err(&mc_dev->dev, "dpmcp_reset() failed: %d\n", error);
-		return error;
-	}
-
-	error = dpmcp_close(mc_io, token);
+	error = dpmcp_reset(mc_io, 0, dpmcp_dev->mc_handle);
 	if (error < 0) {
-		dev_err(&mc_dev->dev, "dpmcp_close() failed: %d\n", error);
+		dev_err(&dpmcp_dev->dev, "dpmcp_reset() failed: %d\n", error);
 		return error;
 	}
 
@@ -473,6 +489,124 @@ void fsl_mc_object_free(struct fsl_mc_device *mc_adev)
 EXPORT_SYMBOL_GPL(fsl_mc_object_free);
 
 /**
+ * It allocates the IRQs required by a given MC object device. The
+ * IRQs are allocated from the interrupt pool associated with the
+ * MC bus that contains the device, if the device is not a DPRC device.
+ * Otherwise, the IRQs are allocated from the interrupt pool associated
+ * with the MC bus that represents the DPRC device itself.
+ */
+int __must_check fsl_mc_allocate_irqs(struct fsl_mc_device *mc_dev)
+{
+	int i;
+	int irq_count;
+	int res_allocated_count = 0;
+	int error = -EINVAL;
+	struct fsl_mc_device_irq **irqs = NULL;
+	struct fsl_mc_bus *mc_bus;
+	struct fsl_mc_resource_pool *res_pool;
+	struct fsl_mc *mc = dev_get_drvdata(fsl_mc_bus_type.dev_root->parent);
+
+	if (!mc->gic_supported)
+		return -ENOTSUPP;
+
+	if (WARN_ON(mc_dev->irqs))
+		goto error;
+
+	irq_count = mc_dev->obj_desc.irq_count;
+	if (WARN_ON(irq_count == 0))
+		goto error;
+
+	if (strcmp(mc_dev->obj_desc.type, "dprc") == 0)
+		mc_bus = to_fsl_mc_bus(mc_dev);
+	else
+		mc_bus = to_fsl_mc_bus(to_fsl_mc_device(mc_dev->dev.parent));
+
+	if (WARN_ON(!mc_bus->irq_resources))
+		goto error;
+
+	res_pool = &mc_bus->resource_pools[FSL_MC_POOL_IRQ];
+	if (res_pool->free_count < irq_count) {
+		dev_err(&mc_dev->dev,
+			"Not able to allocate %u irqs for device\n", irq_count);
+		error = -ENOSPC;
+		goto error;
+	}
+
+	irqs = devm_kzalloc(&mc_dev->dev, irq_count * sizeof(irqs[0]),
+			    GFP_KERNEL);
+	if (!irqs) {
+		error = -ENOMEM;
+		dev_err(&mc_dev->dev, "No memory to allocate irqs[]\n");
+		goto error;
+	}
+
+	for (i = 0; i < irq_count; i++) {
+		struct fsl_mc_resource *resource;
+
+		error = fsl_mc_resource_allocate(mc_bus, FSL_MC_POOL_IRQ,
+						 &resource);
+		if (error < 0)
+			goto error;
+
+		irqs[i] = to_fsl_mc_irq(resource);
+		res_allocated_count++;
+
+		WARN_ON(irqs[i]->mc_dev);
+		irqs[i]->mc_dev = mc_dev;
+		irqs[i]->dev_irq_index = i;
+	}
+
+	mc_dev->irqs = irqs;
+	return 0;
+error:
+	for (i = 0; i < res_allocated_count; i++) {
+		irqs[i]->mc_dev = NULL;
+		fsl_mc_resource_free(&irqs[i]->resource);
+	}
+
+	if (irqs)
+		devm_kfree(&mc_dev->dev, irqs);
+
+	return error;
+}
+EXPORT_SYMBOL_GPL(fsl_mc_allocate_irqs);
+
+/*
+ * It frees the IRQs that were allocated for a MC object device, by
+ * returning them to the corresponding interrupt pool.
+ */
+void fsl_mc_free_irqs(struct fsl_mc_device *mc_dev)
+{
+	int i;
+	int irq_count;
+	struct fsl_mc_bus *mc_bus;
+	struct fsl_mc_device_irq **irqs = mc_dev->irqs;
+
+	if (WARN_ON(!irqs))
+		return;
+
+	irq_count = mc_dev->obj_desc.irq_count;
+
+	if (strcmp(mc_dev->obj_desc.type, "dprc") == 0)
+		mc_bus = to_fsl_mc_bus(mc_dev);
+	else
+		mc_bus = to_fsl_mc_bus(to_fsl_mc_device(mc_dev->dev.parent));
+
+	if (WARN_ON(!mc_bus->irq_resources))
+		return;
+
+	for (i = 0; i < irq_count; i++) {
+		WARN_ON(!irqs[i]->mc_dev);
+		irqs[i]->mc_dev = NULL;
+		fsl_mc_resource_free(&irqs[i]->resource);
+	}
+
+	devm_kfree(&mc_dev->dev, mc_dev->irqs);
+	mc_dev->irqs = NULL;
+}
+EXPORT_SYMBOL_GPL(fsl_mc_free_irqs);
+
+/**
  * fsl_mc_allocator_probe - callback invoked when an allocatable device is
  * being added to the system
  */
@@ -491,16 +625,31 @@ static int fsl_mc_allocator_probe(struct fsl_mc_device *mc_dev)
 		goto error;
 
 	mc_bus = to_fsl_mc_bus(mc_bus_dev);
-	error = object_type_to_pool_type(mc_dev->obj_desc.type, &pool_type);
-	if (error < 0)
-		goto error;
 
-	error = fsl_mc_resource_pool_add_device(mc_bus, pool_type, mc_dev);
-	if (error < 0)
-		goto error;
+	/*
+	 * If mc_dev is the DPMCP object for the parent DPRC's built-in
+	 * portal, we don't add this DPMCP to the DPMCP object pool,
+	 * but instead allocate it directly to the parent DPRC (mc_bus_dev):
+	 */
+	if (strcmp(mc_dev->obj_desc.type, "dpmcp") == 0 &&
+	    mc_dev->obj_desc.id == mc_bus->dprc_attr.portal_id) {
+		error = fsl_mc_io_set_dpmcp(mc_bus_dev->mc_io, mc_dev);
+		if (error < 0)
+			goto error;
+	} else {
+		error = object_type_to_pool_type(mc_dev->obj_desc.type,
+						 &pool_type);
+		if (error < 0)
+			goto error;
+
+		error = fsl_mc_resource_pool_add_device(mc_bus, pool_type,
+							mc_dev);
+		if (error < 0)
+			goto error;
+	}
 
-	dev_info(&mc_dev->dev,
-		 "Allocatable MC object device bound to fsl_mc_allocator driver");
+	dev_dbg(&mc_dev->dev,
+		"Allocatable MC object device bound to fsl_mc_allocator driver");
 	return 0;
 error:
 
@@ -513,40 +662,34 @@ error:
  */
 static int fsl_mc_allocator_remove(struct fsl_mc_device *mc_dev)
 {
-	int error = -EINVAL;
+	int error;
 
 	if (WARN_ON(!FSL_MC_IS_ALLOCATABLE(mc_dev->obj_desc.type)))
-		goto out;
+		return -EINVAL;
 
-	error = fsl_mc_resource_pool_remove_device(mc_dev);
-	if (error < 0)
-		goto out;
+	if (mc_dev->resource) {
+		error = fsl_mc_resource_pool_remove_device(mc_dev);
+		if (error < 0)
+			return error;
+	}
 
-	dev_info(&mc_dev->dev,
-		 "Allocatable MC object device unbound from fsl_mc_allocator driver");
-	error = 0;
-out:
-	return error;
+	dev_dbg(&mc_dev->dev,
+		"Allocatable MC object device unbound from fsl_mc_allocator driver");
+	return 0;
 }
 
 static const struct fsl_mc_device_match_id match_id_table[] = {
 	{
 	 .vendor = FSL_MC_VENDOR_FREESCALE,
 	 .obj_type = "dpbp",
-	 .ver_major = DPBP_VER_MAJOR,
-	 .ver_minor = DPBP_VER_MINOR
 	},
 	{
 	 .vendor = FSL_MC_VENDOR_FREESCALE,
 	 .obj_type = "dpmcp",
-	 .ver_major = DPMCP_VER_MAJOR,
-	 .ver_minor = DPMCP_VER_MINOR
 	},
 	{
 	 .vendor = FSL_MC_VENDOR_FREESCALE,
 	 .obj_type = "dpcon",
-	 .ver_major = DPCON_VER_MAJOR,
-	 .ver_minor = DPCON_VER_MINOR
 	},
 	{.vendor = 0x0},
 };
diff --git a/drivers/staging/fsl-mc/bus/mc-bus.c b/drivers/staging/fsl-mc/bus/mc-bus.c
index 23512d0..5403e9b 100644
--- a/drivers/staging/fsl-mc/bus/mc-bus.c
+++ b/drivers/staging/fsl-mc/bus/mc-bus.c
@@ -1,7 +1,7 @@
 /*
  * Freescale Management Complex (MC) bus driver
  *
- * Copyright (C) 2014 Freescale Semiconductor, Inc.
+ * Copyright (C) 2014-2016 Freescale Semiconductor, Inc.
  * Author: German Rivera <German.Rivera@freescale.com>
  *
  * This file is licensed under the terms of the GNU General Public
@@ -15,11 +15,29 @@
 #include <linux/of_address.h>
 #include <linux/ioport.h>
 #include <linux/slab.h>
+#include <linux/irqchip/arm-gic-v3.h>
+#include <linux/irq.h>
+#include <linux/irqdomain.h>
 #include <linux/limits.h>
+#include <linux/bitops.h>
 #include "../include/dpmng.h"
 #include "../include/mc-sys.h"
 #include "dprc-cmd.h"
 
+/*
+ * IOMMU stream ID flags
+ */
+#define STREAM_ID_PL_MASK   BIT(9)	    /* privilege level */
+#define STREAM_ID_BMT_MASK  BIT(8)	    /* bypass memory translation */
+#define STREAM_ID_VA_MASK   BIT(7)	    /* virtual address translation
+					     * (two-stage translation) */
+#define STREAM_ID_ICID_MASK (BIT(7) - 1)    /* isolation context ID
+					     * (translation context) */
+
+#define MAX_STREAM_ID_ICID  STREAM_ID_ICID_MASK
+
+/* Minimal supported MC Firmware version */
+#define MC_FW_MIN_VER_MAJOR 10
 static struct kmem_cache *mc_dev_cache;
 
 /**
@@ -36,11 +54,12 @@ static int fsl_mc_bus_match(struct device *dev, struct device_driver *drv)
 	struct fsl_mc_device *mc_dev = to_fsl_mc_device(dev);
 	struct fsl_mc_driver *mc_drv = to_fsl_mc_driver(drv);
 	bool found = false;
-	bool major_version_mismatch = false;
-	bool minor_version_mismatch = false;
 
-	if (WARN_ON(!fsl_mc_bus_type.dev_root))
+	/* When driver_override is set, only bind to the matching driver */
+	if (mc_dev->driver_override) {
+		found = !strcmp(mc_dev->driver_override, mc_drv->driver.name);
 		goto out;
+	}
 
 	if (!mc_drv->match_id_table)
 		goto out;
@@ -48,9 +67,12 @@ static int fsl_mc_bus_match(struct device *dev, struct device_driver *drv)
 	/*
 	 * If the object is not 'plugged' don't match.
 	 * Only exception is the root DPRC, which is a special case.
+	 *
+	 * NOTE: Only when this function is invoked for the root DPRC,
+	 * mc_dev->mc_io is not NULL
 	 */
 	if ((mc_dev->obj_desc.state & DPRC_OBJ_STATE_PLUGGED) == 0 &&
-	    &mc_dev->dev != fsl_mc_bus_type.dev_root)
+	    !mc_dev->mc_io)
 		goto out;
 
 	/*
@@ -60,32 +82,12 @@ static int fsl_mc_bus_match(struct device *dev, struct device_driver *drv)
 	for (id = mc_drv->match_id_table; id->vendor != 0x0; id++) {
 		if (id->vendor == mc_dev->obj_desc.vendor &&
 		    strcmp(id->obj_type, mc_dev->obj_desc.type) == 0) {
-			if (id->ver_major == mc_dev->obj_desc.ver_major) {
-				found = true;
-				if (id->ver_minor != mc_dev->obj_desc.ver_minor)
-					minor_version_mismatch = true;
-			} else {
-				major_version_mismatch = true;
-			}
+			found = true;
 
 			break;
 		}
 	}
 
-	if (major_version_mismatch) {
-		dev_warn(dev,
-			 "Major version mismatch: driver version %u.%u, MC object version %u.%u\n",
-			 id->ver_major, id->ver_minor,
-			 mc_dev->obj_desc.ver_major,
-			 mc_dev->obj_desc.ver_minor);
-	} else if (minor_version_mismatch) {
-		dev_warn(dev,
-			 "Minor version mismatch: driver version %u.%u, MC object version %u.%u\n",
-			 id->ver_major, id->ver_minor,
-			 mc_dev->obj_desc.ver_major,
-			 mc_dev->obj_desc.ver_minor);
-	}
-
 out:
 	dev_dbg(dev, "%smatched\n", found ? "" : "not ");
 	return found;
@@ -100,10 +102,146 @@ static int fsl_mc_bus_uevent(struct device *dev, struct kobj_uevent_env *env)
 	return 0;
 }
 
+static ssize_t driver_override_store(struct device *dev,
+				     struct device_attribute *attr,
+				     const char *buf, size_t count)
+{
+	struct fsl_mc_device *mc_dev = to_fsl_mc_device(dev);
+	const char *driver_override, *old = mc_dev->driver_override;
+	char *cp;
+
+	if (WARN_ON(dev->bus != &fsl_mc_bus_type))
+		return -EINVAL;
+
+	if (count > PATH_MAX)
+		return -EINVAL;
+
+	driver_override = kstrndup(buf, count, GFP_KERNEL);
+	if (!driver_override)
+		return -ENOMEM;
+
+	cp = strchr(driver_override, '\n');
+	if (cp)
+		*cp = '\0';
+
+	if (strlen(driver_override)) {
+		mc_dev->driver_override = driver_override;
+	} else {
+		kfree(driver_override);
+		mc_dev->driver_override = NULL;
+	}
+
+	kfree(old);
+
+	return count;
+}
+
+static ssize_t driver_override_show(struct device *dev,
+				    struct device_attribute *attr, char *buf)
+{
+	struct fsl_mc_device *mc_dev = to_fsl_mc_device(dev);
+
+	return sprintf(buf, "%s\n", mc_dev->driver_override);
+}
+
+static DEVICE_ATTR_RW(driver_override);
+
+static ssize_t rescan_store(struct device *dev,
+			    struct device_attribute *attr,
+			    const char *buf, size_t count)
+{
+	unsigned long val;
+	unsigned int irq_count;
+	struct fsl_mc_device *root_mc_dev;
+	struct fsl_mc_bus *root_mc_bus;
+
+	if (!is_root_dprc(dev))
+		return -EINVAL;
+
+	root_mc_dev = to_fsl_mc_device(dev);
+	root_mc_bus = to_fsl_mc_bus(root_mc_dev);
+
+	if (kstrtoul(buf, 0, &val) < 0)
+		return -EINVAL;
+
+	if (val) {
+		mutex_lock(&root_mc_bus->scan_mutex);
+		dprc_scan_objects(root_mc_dev, NULL, &irq_count, 0);
+		mutex_unlock(&root_mc_bus->scan_mutex);
+	}
+
+	return count;
+}
+
+static DEVICE_ATTR_WO(rescan);
+
+static struct attribute *fsl_mc_dev_attrs[] = {
+	&dev_attr_driver_override.attr,
+	&dev_attr_rescan.attr,
+	NULL,
+};
+
+static const struct attribute_group fsl_mc_dev_group = {
+	.attrs = fsl_mc_dev_attrs,
+};
+
+static const struct attribute_group *fsl_mc_dev_groups[] = {
+	&fsl_mc_dev_group,
+	NULL,
+};
+
+static int scan_fsl_mc_bus(struct device *dev, void *data)
+{
+	unsigned int irq_count;
+	struct fsl_mc_device *root_mc_dev;
+	struct fsl_mc_bus *root_mc_bus;
+
+	if (is_root_dprc(dev)) {
+		root_mc_dev = to_fsl_mc_device(dev);
+		root_mc_bus = to_fsl_mc_bus(root_mc_dev);
+		mutex_lock(&root_mc_bus->scan_mutex);
+		dprc_scan_objects(root_mc_dev, NULL, &irq_count, 0);
+		mutex_unlock(&root_mc_bus->scan_mutex);
+	}
+
+	return 0;
+}
+
+static ssize_t bus_rescan_store(struct bus_type *bus,
+			    const char *buf, size_t count)
+{
+	unsigned long val;
+
+	if (kstrtoul(buf, 0, &val) < 0)
+		return -EINVAL;
+
+	if (val)
+		bus_for_each_dev(bus, NULL, NULL, scan_fsl_mc_bus);
+
+	return count;
+}
+static BUS_ATTR(rescan, (S_IWUSR|S_IWGRP), NULL, bus_rescan_store);
+
+static struct attribute *fsl_mc_bus_attrs[] = {
+	&bus_attr_rescan.attr,
+	NULL,
+};
+
+static const struct attribute_group fsl_mc_bus_group = {
+	.attrs = fsl_mc_bus_attrs,
+};
+
+static const struct attribute_group *fsl_mc_bus_groups[] = {
+	&fsl_mc_bus_group,
+	NULL,
+};
+
 struct bus_type fsl_mc_bus_type = {
 	.name = "fsl-mc",
 	.match = fsl_mc_bus_match,
 	.uevent = fsl_mc_bus_uevent,
+	.dev_groups = fsl_mc_dev_groups,
+	.bus_groups = fsl_mc_bus_groups,
 };
 EXPORT_SYMBOL_GPL(fsl_mc_bus_type);
 
@@ -206,35 +344,66 @@ void fsl_mc_driver_unregister(struct fsl_mc_driver *mc_driver)
 }
 EXPORT_SYMBOL_GPL(fsl_mc_driver_unregister);
 
-static int get_dprc_icid(struct fsl_mc_io *mc_io,
-			 int container_id, uint16_t *icid)
+bool fsl_mc_interrupts_supported(void)
+{
+	struct fsl_mc *mc = dev_get_drvdata(fsl_mc_bus_type.dev_root->parent);
+
+	return mc->gic_supported;
+}
+EXPORT_SYMBOL_GPL(fsl_mc_interrupts_supported);
+
+static int get_dprc_attr(struct fsl_mc_io *mc_io,
+			 int container_id, struct dprc_attributes *attr)
 {
 	uint16_t dprc_handle;
-	struct dprc_attributes attr;
 	int error;
 
-	error = dprc_open(mc_io, container_id, &dprc_handle);
+	error = dprc_open(mc_io, 0, container_id, &dprc_handle);
 	if (error < 0) {
 		pr_err("dprc_open() failed: %d\n", error);
 		return error;
 	}
 
-	memset(&attr, 0, sizeof(attr));
-	error = dprc_get_attributes(mc_io, dprc_handle, &attr);
+	memset(attr, 0, sizeof(struct dprc_attributes));
+	error = dprc_get_attributes(mc_io, 0, dprc_handle, attr);
 	if (error < 0) {
 		pr_err("dprc_get_attributes() failed: %d\n", error);
 		goto common_cleanup;
 	}
 
-	*icid = attr.icid;
 	error = 0;
 
 common_cleanup:
-	(void)dprc_close(mc_io, dprc_handle);
+	(void)dprc_close(mc_io, 0, dprc_handle);
 	return error;
 }
 
-static int translate_mc_addr(uint64_t mc_addr, phys_addr_t *phys_addr)
+static int get_dprc_icid(struct fsl_mc_io *mc_io,
+			 int container_id, uint16_t *icid)
+{
+	struct dprc_attributes attr;
+	int error;
+
+	error = get_dprc_attr(mc_io, container_id, &attr);
+	if (error == 0)
+		*icid = attr.icid;
+
+	return error;
+}
+
+static int get_dprc_version(struct fsl_mc_io *mc_io,
+			    int container_id, uint16_t *major, uint16_t *minor)
+{
+	int error = dprc_get_api_version(mc_io, 0, major, minor);
+	if (error < 0) {
+		pr_err("dprc_get_api_version() failed: %d\n", error);
+	}
+
+	return error;
+}
+
+static int translate_mc_addr(enum fsl_mc_region_types mc_region_type,
+			     uint64_t mc_offset, phys_addr_t *phys_addr)
 {
 	int i;
 	struct fsl_mc *mc = dev_get_drvdata(fsl_mc_bus_type.dev_root->parent);
@@ -243,7 +412,7 @@ static int translate_mc_addr(uint64_t mc_addr, phys_addr_t *phys_addr)
 		/*
 		 * Do identity mapping:
 		 */
-		*phys_addr = mc_addr;
+		*phys_addr = mc_offset;
 		return 0;
 	}
 
@@ -251,10 +420,11 @@ static int translate_mc_addr(uint64_t mc_addr, phys_addr_t *phys_addr)
 		struct fsl_mc_addr_translation_range *range =
 			&mc->translation_ranges[i];
 
-		if (mc_addr >= range->start_mc_addr &&
-		    mc_addr < range->end_mc_addr) {
+		if (mc_region_type == range->mc_region_type &&
+		    mc_offset >= range->start_mc_offset &&
+		    mc_offset < range->end_mc_offset) {
 			*phys_addr = range->start_phys_addr +
-				     (mc_addr - range->start_mc_addr);
+				     (mc_offset - range->start_mc_offset);
 			return 0;
 		}
 	}
@@ -270,6 +440,22 @@ static int fsl_mc_device_get_mmio_regions(struct fsl_mc_device *mc_dev,
 	struct resource *regions;
 	struct dprc_obj_desc *obj_desc = &mc_dev->obj_desc;
 	struct device *parent_dev = mc_dev->dev.parent;
+	enum fsl_mc_region_types mc_region_type;
+
+	if (strcmp(obj_desc->type, "dprc") == 0 ||
+	    strcmp(obj_desc->type, "dpmcp") == 0) {
+		mc_region_type = FSL_MC_PORTAL;
+	} else if (strcmp(obj_desc->type, "dpio") == 0) {
+		mc_region_type = FSL_QBMAN_PORTAL;
+	} else {
+		/*
+		 * This function should not have been called for this MC object
+		 * type, as this object type is not supposed to have MMIO
+		 * regions
+		 */
+		WARN_ON(true);
+		return -EINVAL;
+	}
 
 	regions = kmalloc_array(obj_desc->region_count,
 				sizeof(regions[0]), GFP_KERNEL);
@@ -280,6 +466,7 @@ static int fsl_mc_device_get_mmio_regions(struct fsl_mc_device *mc_dev,
 		struct dprc_region_desc region_desc;
 
 		error = dprc_get_obj_region(mc_bus_dev->mc_io,
+					    0,
 					    mc_bus_dev->mc_handle,
 					    obj_desc->type,
 					    obj_desc->id, i, &region_desc);
@@ -289,20 +476,23 @@ static int fsl_mc_device_get_mmio_regions(struct fsl_mc_device *mc_dev,
 			goto error_cleanup_regions;
 		}
 
-		WARN_ON(region_desc.base_paddr == 0x0);
 		WARN_ON(region_desc.size == 0);
-		error = translate_mc_addr(region_desc.base_paddr,
+		error = translate_mc_addr(mc_region_type,
+					  region_desc.base_offset,
 					  &regions[i].start);
 		if (error < 0) {
 			dev_err(parent_dev,
-				"Invalid MC address: %#llx\n",
-				region_desc.base_paddr);
+				"Invalid MC offset: %#x (for %s.%d\'s region %d)\n",
+				region_desc.base_offset,
+				obj_desc->type, obj_desc->id, i);
 			goto error_cleanup_regions;
 		}
 
 		regions[i].end = regions[i].start + region_desc.size - 1;
 		regions[i].name = "fsl-mc object MMIO region";
 		regions[i].flags = IORESOURCE_IO;
+		if (region_desc.flags & DPRC_REGION_CACHEABLE)
+			regions[i].flags |= IORESOURCE_CACHEABLE;
 	}
 
 	mc_dev->regions = regions;
@@ -319,6 +509,7 @@ error_cleanup_regions:
 int fsl_mc_device_add(struct dprc_obj_desc *obj_desc,
 		      struct fsl_mc_io *mc_io,
 		      struct device *parent_dev,
+		      const char *driver_override,
 		      struct fsl_mc_device **new_mc_dev)
 {
 	int error;
@@ -351,7 +542,20 @@ int fsl_mc_device_add(struct dprc_obj_desc *obj_desc,
 
 	mc_dev->obj_desc = *obj_desc;
 	mc_dev->mc_io = mc_io;
+	if (driver_override) {
+		/*
+		 * We trust driver_override, so we don't need to use
+		 * kstrndup() here
+		 */
+		mc_dev->driver_override = kstrdup(driver_override, GFP_KERNEL);
+		if (!mc_dev->driver_override) {
+			error = -ENOMEM;
+			goto error_cleanup_dev;
+		}
+	}
+
 	device_initialize(&mc_dev->dev);
+	INIT_LIST_HEAD(&mc_dev->dev.msi_list);
 	mc_dev->dev.parent = parent_dev;
 	mc_dev->dev.bus = &fsl_mc_bus_type;
 	dev_set_name(&mc_dev->dev, "%s.%d", obj_desc->type, obj_desc->id);
@@ -386,9 +590,6 @@ int fsl_mc_device_add(struct dprc_obj_desc *obj_desc,
 			}
 
 			mc_io2 = mc_io;
-
-			if (!fsl_mc_bus_type.dev_root)
-				fsl_mc_bus_type.dev_root = &mc_dev->dev;
 		}
 
 		error = get_dprc_icid(mc_io2, obj_desc->id, &mc_dev->icid);
@@ -418,6 +619,13 @@ int fsl_mc_device_add(struct dprc_obj_desc *obj_desc,
 	}
 
 	/*
+	 * Objects are coherent, unless 'no shareability' flag set.
+	 * FIXME: fill up @dma_base, @size, @iommu
+	 */
+	if (!(obj_desc->flags & DPRC_OBJ_FLAG_NO_MEM_SHAREABILITY))
+			arch_setup_dma_ops(&mc_dev->dev, 0, 0, NULL, true);
+
+	/*
 	 * The device-specific probe callback will get invoked by device_add()
 	 */
 	error = device_add(&mc_dev->dev);
@@ -466,15 +674,14 @@ void fsl_mc_device_remove(struct fsl_mc_device *mc_dev)
 
 	if (strcmp(mc_dev->obj_desc.type, "dprc") == 0) {
 		mc_bus = to_fsl_mc_bus(mc_dev);
-		if (mc_dev->mc_io) {
-			fsl_destroy_mc_io(mc_dev->mc_io);
-			mc_dev->mc_io = NULL;
-		}
 
 		if (&mc_dev->dev == fsl_mc_bus_type.dev_root)
 			fsl_mc_bus_type.dev_root = NULL;
-	}
+	} else
+		WARN_ON(mc_dev->mc_io != NULL);
 
+	kfree(mc_dev->driver_override);
+	mc_dev->driver_override = NULL;
 	if (mc_bus)
 		devm_kfree(mc_dev->dev.parent, mc_bus);
 	else
@@ -482,6 +689,339 @@ void fsl_mc_device_remove(struct fsl_mc_device *mc_dev)
 }
 EXPORT_SYMBOL_GPL(fsl_mc_device_remove);
 
+static int mc_bus_msi_prepare(struct irq_domain *domain, struct device *dev,
+			      int nvec, msi_alloc_info_t *info)
+{
+	int error;
+	u32 its_dev_id;
+	struct dprc_attributes dprc_attr;
+	struct fsl_mc_device *mc_bus_dev = to_fsl_mc_device(dev);
+
+	if (WARN_ON(!(mc_bus_dev->flags & FSL_MC_IS_DPRC)))
+		return -EINVAL;
+
+	error = dprc_get_attributes(mc_bus_dev->mc_io,
+				    0,
+				    mc_bus_dev->mc_handle, &dprc_attr);
+	if (error < 0) {
+		dev_err(&mc_bus_dev->dev,
+			"dprc_get_attributes() failed: %d\n",
+			error);
+		return error;
+	}
+
+	/*
+	 * Build the device Id to be passed to the GIC-ITS:
+	 *
+	 * NOTE: This device id corresponds to the IOMMU stream ID
+	 * associated with the DPRC object.
+	 */
+	its_dev_id = mc_bus_dev->icid;
+	if (its_dev_id > STREAM_ID_ICID_MASK) {
+		dev_err(&mc_bus_dev->dev,
+			"Invalid ICID: %#x\n", its_dev_id);
+		return -ERANGE;
+	}
+
+	if (dprc_attr.options & DPRC_CFG_OPT_AIOP)
+		its_dev_id |= STREAM_ID_PL_MASK | STREAM_ID_BMT_MASK;
+
+	return __its_msi_prepare(domain, its_dev_id, dev, nvec, info);
+}
+
+static void mc_bus_mask_msi_irq(struct irq_data *d)
+{
+	/* Bus specefic Mask */
+	irq_chip_mask_parent(d);
+}
+
+static void mc_bus_unmask_msi_irq(struct irq_data *d)
+{
+	/* Bus specefic unmask */
+	irq_chip_unmask_parent(d);
+}
+
+static void program_msi_at_mc(struct fsl_mc_device *mc_bus_dev,
+			      struct fsl_mc_device_irq *irq)
+{
+	int error;
+	struct fsl_mc_device *owner_mc_dev = irq->mc_dev;
+	struct fsl_mc_bus *mc_bus = to_fsl_mc_bus(mc_bus_dev);
+	struct dprc_irq_cfg irq_cfg;
+
+	/*
+	 * irq->msi_paddr is 0x0 when this function is invoked in the
+	 * free_irq() code path. In this case, for the MC, we don't
+	 * really need to "unprogram" the MSI, so we just return.
+	 * This helps avoid subtle ordering problems in the MC
+	 * bus IRQ teardown logic.
+	 * FIXME: evaluate whether there is a better way to address
+	 * the underlying issue (upstreamability concern)
+	 */
+	if (irq->msi_paddr == 0x0)
+		return;
+
+	if (WARN_ON(!owner_mc_dev))
+		return;
+
+	irq_cfg.paddr = irq->msi_paddr;
+	irq_cfg.val = irq->msi_value;
+	irq_cfg.irq_num = irq->irq_number;
+
+	if (owner_mc_dev == mc_bus_dev) {
+		/*
+		 * IRQ is for the mc_bus_dev's DPRC itself
+		 */
+		error = dprc_set_irq(mc_bus->atomic_mc_io,
+				     MC_CMD_FLAG_INTR_DIS | MC_CMD_FLAG_PRI,
+				     mc_bus->atomic_dprc_handle,
+				     irq->dev_irq_index,
+				     &irq_cfg);
+		if (error < 0) {
+			dev_err(&owner_mc_dev->dev,
+				"dprc_set_irq() failed: %d\n", error);
+		}
+	} else {
+		error = dprc_set_obj_irq(mc_bus->atomic_mc_io,
+					 MC_CMD_FLAG_INTR_DIS | MC_CMD_FLAG_PRI,
+					 mc_bus->atomic_dprc_handle,
+					 owner_mc_dev->obj_desc.type,
+					 owner_mc_dev->obj_desc.id,
+					 irq->dev_irq_index,
+					 &irq_cfg);
+		if (error < 0) {
+			dev_err(&owner_mc_dev->dev,
+				"dprc_obj_set_irq() failed: %d\n", error);
+		}
+	}
+}
+
+/*
+ * This function is invoked from devm_request_irq(),
+ * devm_request_threaded_irq(), dev_free_irq()
+ */
+static void mc_bus_msi_domain_write_msg(struct irq_data *irq_data,
+					struct msi_msg *msg)
+{
+	struct msi_desc *msi_entry = irq_data->msi_desc;
+	struct fsl_mc_device *mc_bus_dev = to_fsl_mc_device(msi_entry->dev);
+	struct fsl_mc_bus *mc_bus = to_fsl_mc_bus(mc_bus_dev);
+	struct fsl_mc_device_irq *irq_res =
+		&mc_bus->irq_resources[msi_entry->msi_attrib.entry_nr];
+
+	/*
+	 * NOTE: This function is invoked with interrupts disabled
+	 */
+
+	if (irq_res->irq_number == irq_data->irq) {
+		irq_res->msi_paddr =
+			((u64)msg->address_hi << 32) | msg->address_lo;
+
+		irq_res->msi_value = msg->data;
+
+		/*
+		 * Program the MSI (paddr, value) pair in the device:
+		 */
+		program_msi_at_mc(mc_bus_dev, irq_res);
+	}
+}
+
+static struct irq_chip mc_bus_msi_irq_chip = {
+	.name			= "fsl-mc-bus-msi",
+	.irq_unmask		= mc_bus_unmask_msi_irq,
+	.irq_mask		= mc_bus_mask_msi_irq,
+	.irq_eoi		= irq_chip_eoi_parent,
+	.irq_write_msi_msg	= mc_bus_msi_domain_write_msg,
+};
+
+static struct msi_domain_ops mc_bus_msi_ops = {
+	.msi_prepare	= mc_bus_msi_prepare,
+};
+
+static struct msi_domain_info mc_bus_msi_domain_info = {
+	.flags	= (MSI_FLAG_USE_DEF_DOM_OPS | MSI_FLAG_USE_DEF_CHIP_OPS |
+		   MSI_FLAG_MULTI_PCI_MSI | MSI_FLAG_PCI_MSIX),
+	.ops	= &mc_bus_msi_ops,
+	.chip	= &mc_bus_msi_irq_chip,
+};
+
+static int create_mc_irq_domain(struct platform_device *mc_pdev,
+				struct irq_domain **new_irq_domain)
+{
+	int error;
+	struct device_node *its_of_node;
+	struct irq_domain *its_domain;
+	struct irq_domain *irq_domain;
+	struct device_node *mc_of_node = mc_pdev->dev.of_node;
+
+	its_of_node = of_parse_phandle(mc_of_node, "msi-parent", 0);
+	if (!its_of_node) {
+		dev_err(&mc_pdev->dev,
+			"msi-parent phandle missing for %s\n",
+			mc_of_node->full_name);
+		return -ENOENT;
+	}
+
+	/*
+	 * Extract MSI parent node:
+	 */
+	its_domain = irq_find_host(its_of_node);
+	if (!its_domain) {
+		dev_err(&mc_pdev->dev, "Unable to find parent domain\n");
+		error = -ENOENT;
+		goto cleanup_its_of_node;
+	}
+
+	irq_domain = msi_create_irq_domain(mc_of_node, &mc_bus_msi_domain_info,
+					   its_domain->parent);
+	if (!irq_domain) {
+		dev_err(&mc_pdev->dev, "Failed to allocate msi_domain\n");
+		error = -ENOMEM;
+		goto cleanup_its_of_node;
+	}
+
+	dev_dbg(&mc_pdev->dev, "Allocated MSI domain\n");
+	*new_irq_domain = irq_domain;
+	return 0;
+
+cleanup_its_of_node:
+	of_node_put(its_of_node);
+	return error;
+}
+
+/*
+ * Initialize the interrupt pool associated with a MC bus.
+ * It allocates a block of IRQs from the GIC-ITS
+ */
+int __must_check fsl_mc_populate_irq_pool(struct fsl_mc_bus *mc_bus,
+					  unsigned int irq_count)
+{
+	unsigned int i;
+	struct msi_desc *msi_entry;
+	struct msi_desc *next_msi_entry;
+	struct fsl_mc_device_irq *irq_resources;
+	struct fsl_mc_device_irq *irq_res;
+	int error;
+	struct fsl_mc_device *mc_bus_dev = &mc_bus->mc_dev;
+	struct fsl_mc *mc = dev_get_drvdata(fsl_mc_bus_type.dev_root->parent);
+	struct fsl_mc_resource_pool *res_pool =
+			&mc_bus->resource_pools[FSL_MC_POOL_IRQ];
+
+	/*
+	 * Detect duplicate invocations of this function:
+	 */
+	if (WARN_ON(!list_empty(&mc_bus_dev->dev.msi_list)))
+		return -EINVAL;
+
+	if (WARN_ON(irq_count == 0 ||
+		    irq_count > FSL_MC_IRQ_POOL_MAX_TOTAL_IRQS))
+		return -EINVAL;
+
+	irq_resources =
+		devm_kzalloc(&mc_bus_dev->dev,
+			     sizeof(*irq_resources) * irq_count,
+			     GFP_KERNEL);
+	if (!irq_resources)
+		return -ENOMEM;
+
+	for (i = 0; i < irq_count; i++) {
+		irq_res = &irq_resources[i];
+		msi_entry = alloc_msi_entry(&mc_bus_dev->dev);
+		if (!msi_entry) {
+			dev_err(&mc_bus_dev->dev, "Failed to allocate msi entry\n");
+			error = -ENOMEM;
+			goto cleanup_msi_entries;
+		}
+
+		msi_entry->msi_attrib.is_msix = 1;
+		msi_entry->msi_attrib.is_64 = 1;
+		msi_entry->msi_attrib.entry_nr = i;
+		msi_entry->nvec_used = 1;
+		list_add_tail(&msi_entry->list, &mc_bus_dev->dev.msi_list);
+
+		/*
+		 * NOTE: irq_res->msi_paddr will be set by the
+		 * mc_bus_msi_domain_write_msg() callback
+		 */
+		irq_res->resource.type = res_pool->type;
+		irq_res->resource.data = irq_res;
+		irq_res->resource.parent_pool = res_pool;
+		INIT_LIST_HEAD(&irq_res->resource.node);
+		list_add_tail(&irq_res->resource.node, &res_pool->free_list);
+	}
+
+	/*
+	 * NOTE: Calling this function will trigger the invocation of the
+	 * mc_bus_msi_prepare() callback
+	 */
+	error = msi_domain_alloc_irqs(mc->irq_domain,
+				      &mc_bus_dev->dev, irq_count);
+
+	if (error) {
+		dev_err(&mc_bus_dev->dev, "Failed to allocate IRQs\n");
+		goto cleanup_msi_entries;
+	}
+
+	for_each_msi_entry(msi_entry, &mc_bus_dev->dev) {
+		u32 irq_num = msi_entry->irq;
+
+		irq_res = &irq_resources[msi_entry->msi_attrib.entry_nr];
+		irq_res->irq_number = irq_num;
+		irq_res->resource.id = irq_num;
+	}
+
+	res_pool->max_count = irq_count;
+	res_pool->free_count = irq_count;
+	mc_bus->irq_resources = irq_resources;
+	return 0;
+
+cleanup_msi_entries:
+	list_for_each_entry_safe(msi_entry, next_msi_entry,
+				 &mc_bus_dev->dev.msi_list, list) {
+		list_del(&msi_entry->list);
+		kfree(msi_entry);
+	}
+
+	devm_kfree(&mc_bus_dev->dev, irq_resources);
+	return error;
+}
+EXPORT_SYMBOL_GPL(fsl_mc_populate_irq_pool);
+
+/**
+ * Teardown the interrupt pool associated with an MC bus.
+ * It frees the IRQs that were allocated to the pool, back to the GIC-ITS.
+ */
+void fsl_mc_cleanup_irq_pool(struct fsl_mc_bus *mc_bus)
+{
+	struct msi_desc *msi_entry;
+	struct msi_desc *next_msi_entry;
+	struct fsl_mc *mc = dev_get_drvdata(fsl_mc_bus_type.dev_root->parent);
+	struct fsl_mc_resource_pool *res_pool =
+			&mc_bus->resource_pools[FSL_MC_POOL_IRQ];
+
+	if (WARN_ON(!mc_bus->irq_resources))
+		return;
+
+	if (WARN_ON(res_pool->max_count == 0))
+		return;
+
+	if (WARN_ON(res_pool->free_count != res_pool->max_count))
+		return;
+
+	msi_domain_free_irqs(mc->irq_domain, &mc_bus->mc_dev.dev);
+	list_for_each_entry_safe(msi_entry, next_msi_entry,
+				 &mc_bus->mc_dev.dev.msi_list, list) {
+		list_del(&msi_entry->list);
+		kfree(msi_entry);
+	}
+
+	devm_kfree(&mc_bus->mc_dev.dev, mc_bus->irq_resources);
+	res_pool->max_count = 0;
+	res_pool->free_count = 0;
+	mc_bus->irq_resources = NULL;
+}
+EXPORT_SYMBOL_GPL(fsl_mc_cleanup_irq_pool);
+
 static int parse_mc_ranges(struct device *dev,
 			   int *paddr_cells,
 			   int *mc_addr_cells,
@@ -574,12 +1114,14 @@ static int get_mc_addr_translation_ranges(struct device *dev,
 	for (i = 0; i < *num_ranges; ++i) {
 		struct fsl_mc_addr_translation_range *range = &(*ranges)[i];
 
-		range->start_mc_addr = of_read_number(cell, mc_addr_cells);
+		range->mc_region_type = of_read_number(cell, 1);
+		range->start_mc_offset = of_read_number(cell + 1,
+							mc_addr_cells - 1);
 		cell += mc_addr_cells;
 		range->start_phys_addr = of_read_number(cell, paddr_cells);
 		cell += paddr_cells;
-		range->end_mc_addr = range->start_mc_addr +
-				     of_read_number(cell, mc_size_cells);
+		range->end_mc_offset = range->start_mc_offset +
+				       of_read_number(cell, mc_size_cells);
 
 		cell += mc_size_cells;
 	}
@@ -611,6 +1153,13 @@ static int fsl_mc_bus_probe(struct platform_device *pdev)
 		return -ENOMEM;
 
 	platform_set_drvdata(pdev, mc);
+	error = create_mc_irq_domain(pdev, &mc->irq_domain);
+	if (error < 0) {
+		dev_warn(&pdev->dev,
+			 "WARNING: MC bus driver will run without interrupt support\n");
+	} else {
+		mc->gic_supported = true;
+	}
 
 	/*
 	 * Get physical address of MC portal for the root DPRC:
@@ -620,7 +1169,7 @@ static int fsl_mc_bus_probe(struct platform_device *pdev)
 		dev_err(&pdev->dev,
 			"of_address_to_resource() failed for %s\n",
 			pdev->dev.of_node->full_name);
-		return error;
+		goto error_cleanup_irq_domain;
 	}
 
 	mc_portal_phys_addr = res.start;
@@ -628,9 +1177,9 @@ static int fsl_mc_bus_probe(struct platform_device *pdev)
 	error = fsl_create_mc_io(&pdev->dev, mc_portal_phys_addr,
 				 mc_portal_size, NULL, 0, &mc_io);
 	if (error < 0)
-		return error;
+		goto error_cleanup_irq_domain;
 
-	error = mc_get_version(mc_io, &mc_version);
+	error = mc_get_version(mc_io, 0, &mc_version);
 	if (error != 0) {
 		dev_err(&pdev->dev,
 			"mc_get_version() failed with error %d\n", error);
@@ -641,41 +1190,41 @@ static int fsl_mc_bus_probe(struct platform_device *pdev)
 		 "Freescale Management Complex Firmware version: %u.%u.%u\n",
 		 mc_version.major, mc_version.minor, mc_version.revision);
 
-	if (mc_version.major < MC_VER_MAJOR) {
+	if (MC_FW_MIN_VER_MAJOR > mc_version.major) {
 		dev_err(&pdev->dev,
-			"ERROR: MC firmware version not supported by driver (driver version: %u.%u)\n",
-			MC_VER_MAJOR, MC_VER_MINOR);
+				"ERROR: Expected MC firmware version %u or later",
+				MC_FW_MIN_VER_MAJOR);
 		error = -ENOTSUPP;
 		goto error_cleanup_mc_io;
 	}
 
-	if (mc_version.major > MC_VER_MAJOR) {
-		dev_warn(&pdev->dev,
-			 "WARNING: driver may not support newer MC firmware features (driver version: %u.%u)\n",
-			 MC_VER_MAJOR, MC_VER_MINOR);
-	}
-
 	error = get_mc_addr_translation_ranges(&pdev->dev,
 					       &mc->translation_ranges,
 					       &mc->num_translation_ranges);
 	if (error < 0)
 		goto error_cleanup_mc_io;
 
-	error = dpmng_get_container_id(mc_io, &container_id);
+	error = dprc_get_container_id(mc_io, 0, &container_id);
 	if (error < 0) {
 		dev_err(&pdev->dev,
-			"dpmng_get_container_id() failed: %d\n", error);
+			"get container id failed: %d\n", error);
 		goto error_cleanup_mc_io;
 	}
 
+	memset(&obj_desc, 0, sizeof(struct dprc_obj_desc));
+	error = get_dprc_version(mc_io, container_id,
+				 &obj_desc.ver_major, &obj_desc.ver_minor);
+	if (error < 0)
+		goto error_cleanup_mc_io;
+
 	obj_desc.vendor = FSL_MC_VENDOR_FREESCALE;
 	strcpy(obj_desc.type, "dprc");
 	obj_desc.id = container_id;
-	obj_desc.ver_major = DPRC_VER_MAJOR;
-	obj_desc.ver_minor = DPRC_VER_MINOR;
+	obj_desc.irq_count = 1;
 	obj_desc.region_count = 0;
 
-	error = fsl_mc_device_add(&obj_desc, mc_io, &pdev->dev, &mc_bus_dev);
+	error = fsl_mc_device_add(&obj_desc, mc_io, &pdev->dev, NULL,
+				  &mc_bus_dev);
 	if (error < 0)
 		goto error_cleanup_mc_io;
 
@@ -684,6 +1233,11 @@ static int fsl_mc_bus_probe(struct platform_device *pdev)
 
 error_cleanup_mc_io:
 	fsl_destroy_mc_io(mc_io);
+
+error_cleanup_irq_domain:
+	if (mc->gic_supported)
+		irq_domain_remove(mc->irq_domain);
+
 	return error;
 }
 
@@ -698,7 +1252,13 @@ static int fsl_mc_bus_remove(struct platform_device *pdev)
 	if (WARN_ON(&mc->root_mc_bus_dev->dev != fsl_mc_bus_type.dev_root))
 		return -EINVAL;
 
+	if (mc->gic_supported)
+		irq_domain_remove(mc->irq_domain);
+
 	fsl_mc_device_remove(mc->root_mc_bus_dev);
+	fsl_destroy_mc_io(mc->root_mc_bus_dev->mc_io);
+	mc->root_mc_bus_dev->mc_io = NULL;
+
 	dev_info(&pdev->dev, "Root MC bus device removed");
 	return 0;
 }
diff --git a/drivers/staging/fsl-mc/bus/mc-ioctl.h b/drivers/staging/fsl-mc/bus/mc-ioctl.h
new file mode 100644
index 0000000..d5c1bc3
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/mc-ioctl.h
@@ -0,0 +1,25 @@
+/*
+ * Freescale Management Complex (MC) ioclt interface
+ *
+ * Copyright (C) 2014 Freescale Semiconductor, Inc.
+ * Author: German Rivera <German.Rivera@freescale.com>
+ *	   Lijun Pan <Lijun.Pan@freescale.com>
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2. This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+#ifndef _FSL_MC_IOCTL_H_
+#define _FSL_MC_IOCTL_H_
+
+#include <linux/ioctl.h>
+
+#define RESTOOL_IOCTL_TYPE   'R'
+
+#define RESTOOL_GET_ROOT_DPRC_INFO \
+	_IOR(RESTOOL_IOCTL_TYPE, 0x1, uint32_t)
+
+#define RESTOOL_SEND_MC_COMMAND \
+	_IOWR(RESTOOL_IOCTL_TYPE, 0x4, struct mc_command)
+
+#endif /* _FSL_MC_IOCTL_H_ */
diff --git a/drivers/staging/fsl-mc/bus/mc-restool.c b/drivers/staging/fsl-mc/bus/mc-restool.c
new file mode 100644
index 0000000..d261c1a
--- /dev/null
+++ b/drivers/staging/fsl-mc/bus/mc-restool.c
@@ -0,0 +1,312 @@
+/*
+ * Freescale Management Complex (MC) restool driver
+ *
+ * Copyright (C) 2014 Freescale Semiconductor, Inc.
+ * Author: German Rivera <German.Rivera@freescale.com>
+ *	   Lijun Pan <Lijun.Pan@freescale.com>
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2. This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#include "../include/mc-private.h"
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/miscdevice.h>
+#include <linux/mm.h>
+#include <linux/slab.h>
+#include <linux/uaccess.h>
+#include <linux/mutex.h>
+#include "mc-ioctl.h"
+#include "../include/mc-sys.h"
+#include "../include/mc-cmd.h"
+#include "../include/dpmng.h"
+
+/**
+ * Maximum number of DPRCs that can be opened at the same time
+ */
+#define MAX_DPRC_HANDLES	    64
+
+/**
+ * struct fsl_mc_restool - Management Complex (MC) resource manager object
+ * @tool_mc_io: pointer to the MC I/O object used by the restool
+ */
+struct fsl_mc_restool {
+	struct fsl_mc_io *tool_mc_io;
+};
+
+/**
+ * struct global_state - indicating the number of static and dynamic instance
+ * @dynamic_instance_count - number of dynamically created instances
+ * @static_instance_in_use - static instance is in use or not
+ * @mutex - mutex lock to serialze the operations
+ */
+struct global_state {
+	uint32_t dynamic_instance_count;
+	bool static_instance_in_use;
+	struct mutex mutex;
+};
+
+static struct fsl_mc_restool fsl_mc_restool = { 0 };
+static struct global_state global_state = { 0 };
+
+static int fsl_mc_restool_dev_open(struct inode *inode, struct file *filep)
+{
+	struct fsl_mc_device *root_mc_dev;
+	int error = 0;
+	struct fsl_mc_restool *fsl_mc_restool_new = NULL;
+
+	mutex_lock(&global_state.mutex);
+
+	if (WARN_ON(fsl_mc_bus_type.dev_root == NULL)) {
+		error = -EINVAL;
+		goto error;
+	}
+
+	if (!global_state.static_instance_in_use) {
+		global_state.static_instance_in_use = true;
+		filep->private_data = &fsl_mc_restool;
+	} else {
+		fsl_mc_restool_new = kmalloc(sizeof(struct fsl_mc_restool),
+						GFP_KERNEL);
+		if (fsl_mc_restool_new == NULL) {
+			error = -ENOMEM;
+			goto error;
+		}
+		memset(fsl_mc_restool_new, 0, sizeof(*fsl_mc_restool_new));
+
+		root_mc_dev = to_fsl_mc_device(fsl_mc_bus_type.dev_root);
+		error = fsl_mc_portal_allocate(root_mc_dev, 0,
+				       &fsl_mc_restool_new->tool_mc_io);
+		if (error < 0) {
+			pr_err("Not able to allocate MC portal\n");
+			goto error;
+		}
+		++global_state.dynamic_instance_count;
+		filep->private_data = fsl_mc_restool_new;
+	}
+
+	mutex_unlock(&global_state.mutex);
+	return 0;
+error:
+	if (fsl_mc_restool_new != NULL &&
+	    fsl_mc_restool_new->tool_mc_io != NULL) {
+		fsl_mc_portal_free(fsl_mc_restool_new->tool_mc_io);
+		fsl_mc_restool_new->tool_mc_io = NULL;
+	}
+
+	kfree(fsl_mc_restool_new);
+	mutex_unlock(&global_state.mutex);
+	return error;
+}
+
+static int fsl_mc_restool_dev_release(struct inode *inode, struct file *filep)
+{
+	struct fsl_mc_restool *fsl_mc_restool_local = filep->private_data;
+
+	if (WARN_ON(filep->private_data == NULL))
+		return -EINVAL;
+
+	mutex_lock(&global_state.mutex);
+
+	if (WARN_ON(global_state.dynamic_instance_count == 0 &&
+	    !global_state.static_instance_in_use)) {
+		mutex_unlock(&global_state.mutex);
+		return -EINVAL;
+	}
+
+	/* Globally clean up opened/untracked handles */
+	fsl_mc_portal_reset(fsl_mc_restool_local->tool_mc_io);
+
+	pr_debug("dynamic instance count: %d\n",
+		global_state.dynamic_instance_count);
+	pr_debug("static instance count: %d\n",
+		global_state.static_instance_in_use);
+
+	/*
+	 * must check
+	 * whether fsl_mc_restool_local is dynamic or global instance
+	 * Otherwise it will free up the reserved portal by accident
+	 * or even not free up the dynamic allocated portal
+	 * if 2 or more instances running concurrently
+	 */
+	if (fsl_mc_restool_local == &fsl_mc_restool) {
+		pr_debug("this is reserved portal");
+		pr_debug("reserved portal not in use\n");
+		global_state.static_instance_in_use = false;
+	} else {
+		pr_debug("this is dynamically allocated  portal");
+		pr_debug("free one dynamically allocated portal\n");
+		fsl_mc_portal_free(fsl_mc_restool_local->tool_mc_io);
+		kfree(filep->private_data);
+		--global_state.dynamic_instance_count;
+	}
+
+	filep->private_data = NULL;
+	mutex_unlock(&global_state.mutex);
+	return 0;
+}
+
+static int restool_get_root_dprc_info(unsigned long arg)
+{
+	int error = -EINVAL;
+	uint32_t root_dprc_id;
+	struct fsl_mc_device *root_mc_dev;
+
+	root_mc_dev = to_fsl_mc_device(fsl_mc_bus_type.dev_root);
+	root_dprc_id = root_mc_dev->obj_desc.id;
+	error = copy_to_user((void __user *)arg, &root_dprc_id,
+			     sizeof(root_dprc_id));
+	if (error < 0) {
+		pr_err("copy_to_user() failed with error %d\n", error);
+		goto error;
+	}
+
+	return 0;
+error:
+	return error;
+}
+
+static int restool_send_mc_command(unsigned long arg,
+				struct fsl_mc_restool *fsl_mc_restool)
+{
+	int error = -EINVAL;
+	struct mc_command mc_cmd;
+
+	error = copy_from_user(&mc_cmd, (void __user *)arg, sizeof(mc_cmd));
+	if (error < 0) {
+		pr_err("copy_to_user() failed with error %d\n", error);
+		goto error;
+	}
+
+	/*
+	 * Send MC command to the MC:
+	 */
+	error = mc_send_command(fsl_mc_restool->tool_mc_io, &mc_cmd);
+	if (error < 0)
+		goto error;
+
+	error = copy_to_user((void __user *)arg, &mc_cmd, sizeof(mc_cmd));
+	if (error < 0) {
+		pr_err("copy_to_user() failed with error %d\n", error);
+		goto error;
+	}
+
+	return 0;
+error:
+	return error;
+}
+
+static long
+fsl_mc_restool_dev_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
+{
+	int error = -EINVAL;
+
+	if (WARN_ON(fsl_mc_bus_type.dev_root == NULL))
+		goto out;
+
+	switch (cmd) {
+	case RESTOOL_GET_ROOT_DPRC_INFO:
+		error = restool_get_root_dprc_info(arg);
+		break;
+
+	case RESTOOL_SEND_MC_COMMAND:
+		error = restool_send_mc_command(arg, file->private_data);
+		break;
+	default:
+		error = -EINVAL;
+	}
+out:
+	return error;
+}
+
+static const struct file_operations fsl_mc_restool_dev_fops = {
+	.owner = THIS_MODULE,
+	.open = fsl_mc_restool_dev_open,
+	.release = fsl_mc_restool_dev_release,
+	.unlocked_ioctl = fsl_mc_restool_dev_ioctl,
+	.compat_ioctl = fsl_mc_restool_dev_ioctl,
+};
+
+static struct miscdevice fsl_mc_restool_dev = {
+	.minor = MISC_DYNAMIC_MINOR,
+	.name = "mc_restool",
+	.fops = &fsl_mc_restool_dev_fops
+};
+
+static int __init fsl_mc_restool_driver_init(void)
+{
+	struct fsl_mc_device *root_mc_dev;
+	int error = -EINVAL;
+	bool restool_dev_registered = false;
+
+	mutex_init(&global_state.mutex);
+
+	if (WARN_ON(fsl_mc_restool.tool_mc_io != NULL))
+		goto error;
+
+	if (WARN_ON(global_state.dynamic_instance_count != 0))
+		goto error;
+
+	if (WARN_ON(global_state.static_instance_in_use))
+		goto error;
+
+	if (fsl_mc_bus_type.dev_root == NULL) {
+		pr_err("fsl-mc bus not found, restool driver registration failed\n");
+		goto error;
+	}
+
+	root_mc_dev = to_fsl_mc_device(fsl_mc_bus_type.dev_root);
+	error = fsl_mc_portal_allocate(root_mc_dev, 0,
+				       &fsl_mc_restool.tool_mc_io);
+	if (error < 0) {
+		pr_err("Not able to allocate MC portal\n");
+		goto error;
+	}
+
+	error = misc_register(&fsl_mc_restool_dev);
+	if (error < 0) {
+		pr_err("misc_register() failed: %d\n", error);
+		goto error;
+	}
+
+	restool_dev_registered = true;
+	pr_info("%s driver registered\n", fsl_mc_restool_dev.name);
+	return 0;
+error:
+	if (restool_dev_registered)
+		misc_deregister(&fsl_mc_restool_dev);
+
+	if (fsl_mc_restool.tool_mc_io != NULL) {
+		fsl_mc_portal_free(fsl_mc_restool.tool_mc_io);
+		fsl_mc_restool.tool_mc_io = NULL;
+	}
+
+	return error;
+}
+
+module_init(fsl_mc_restool_driver_init);
+
+static void __exit fsl_mc_restool_driver_exit(void)
+{
+	if (WARN_ON(fsl_mc_restool.tool_mc_io == NULL))
+		return;
+
+	if (WARN_ON(global_state.dynamic_instance_count != 0))
+		return;
+
+	if (WARN_ON(global_state.static_instance_in_use))
+		return;
+
+	misc_deregister(&fsl_mc_restool_dev);
+	fsl_mc_portal_free(fsl_mc_restool.tool_mc_io);
+	fsl_mc_restool.tool_mc_io = NULL;
+	pr_info("%s driver unregistered\n", fsl_mc_restool_dev.name);
+}
+
+module_exit(fsl_mc_restool_driver_exit);
+
+MODULE_AUTHOR("Freescale Semiconductor Inc.");
+MODULE_DESCRIPTION("Freescale's MC restool driver");
+MODULE_LICENSE("GPL");
+
diff --git a/drivers/staging/fsl-mc/bus/mc-sys.c b/drivers/staging/fsl-mc/bus/mc-sys.c
index 5737f59..571eaae 100644
--- a/drivers/staging/fsl-mc/bus/mc-sys.c
+++ b/drivers/staging/fsl-mc/bus/mc-sys.c
@@ -34,15 +34,20 @@
 
 #include "../include/mc-sys.h"
 #include "../include/mc-cmd.h"
+#include "../include/mc.h"
 #include <linux/delay.h>
 #include <linux/slab.h>
 #include <linux/ioport.h>
 #include <linux/device.h>
+#include <linux/interrupt.h>
+#include "dpmcp.h"
 
 /**
- * Timeout in jiffies to wait for the completion of an MC command
+ * Timeout in milliseconds to wait for the completion of an MC command
+ * 5000 ms is barely enough for dpsw/dpdmux creation
+ * TODO: if MC firmware could response faster, we should decrease this value
  */
-#define MC_CMD_COMPLETION_TIMEOUT_JIFFIES   (HZ / 2)	/* 500 ms */
+#define MC_CMD_COMPLETION_TIMEOUT_MS	5000
 
 /*
  * usleep_range() min and max values used to throttle down polling
@@ -51,8 +56,208 @@
 #define MC_CMD_COMPLETION_POLLING_MIN_SLEEP_USECS    10
 #define MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS    500
 
-#define MC_CMD_HDR_READ_CMDID(_hdr) \
-	((uint16_t)mc_dec((_hdr), MC_CMD_HDR_CMDID_O, MC_CMD_HDR_CMDID_S))
+
+/**
+ * dpmcp_irq0_handler - Regular ISR for DPMCP interrupt 0
+ *
+ * @irq: IRQ number of the interrupt being handled
+ * @arg: Pointer to device structure
+ */
+static irqreturn_t dpmcp_irq0_handler(int irq_num, void *arg)
+{
+	struct device *dev = (struct device *)arg;
+	struct fsl_mc_device *dpmcp_dev = to_fsl_mc_device(dev);
+	struct fsl_mc_io *mc_io = dpmcp_dev->mc_io;
+
+	dev_dbg(dev, "DPMCP IRQ %d triggered on CPU %u\n", irq_num,
+		smp_processor_id());
+
+	if (WARN_ON(dpmcp_dev->irqs[0]->irq_number != (uint32_t)irq_num))
+		goto out;
+
+	if (WARN_ON(!mc_io))
+		goto out;
+
+	complete(&mc_io->mc_command_done_completion);
+out:
+	return IRQ_HANDLED;
+}
+
+/*
+ * Disable and clear interrupts for a given DPMCP object
+ */
+static int disable_dpmcp_irq(struct fsl_mc_device *dpmcp_dev)
+{
+	int error;
+
+	/*
+	 * Disable generation of the DPMCP interrupt:
+	 */
+	error = dpmcp_set_irq_enable(dpmcp_dev->mc_io,
+				     MC_CMD_FLAG_INTR_DIS,
+				     dpmcp_dev->mc_handle,
+				     DPMCP_IRQ_INDEX, 0);
+	if (error < 0) {
+		dev_err(&dpmcp_dev->dev,
+			"dpmcp_set_irq_enable() failed: %d\n", error);
+
+		return error;
+	}
+
+	/*
+	 * Disable all DPMCP interrupt causes:
+	 */
+	error = dpmcp_set_irq_mask(dpmcp_dev->mc_io,
+				   MC_CMD_FLAG_INTR_DIS,
+				   dpmcp_dev->mc_handle,
+				   DPMCP_IRQ_INDEX, 0x0);
+	if (error < 0) {
+		dev_err(&dpmcp_dev->dev,
+			"dpmcp_set_irq_mask() failed: %d\n", error);
+
+		return error;
+	}
+
+	return 0;
+}
+
+static void unregister_dpmcp_irq_handler(struct fsl_mc_device *dpmcp_dev)
+{
+	struct fsl_mc_device_irq *irq = dpmcp_dev->irqs[DPMCP_IRQ_INDEX];
+
+	devm_free_irq(&dpmcp_dev->dev, irq->irq_number, &dpmcp_dev->dev);
+}
+
+static int register_dpmcp_irq_handler(struct fsl_mc_device *dpmcp_dev)
+{
+	int error;
+	struct fsl_mc_device_irq *irq = dpmcp_dev->irqs[DPMCP_IRQ_INDEX];
+
+	error = devm_request_irq(&dpmcp_dev->dev,
+				 irq->irq_number,
+				 dpmcp_irq0_handler,
+				 IRQF_NO_SUSPEND | IRQF_ONESHOT,
+				 "FSL MC DPMCP irq0",
+				 &dpmcp_dev->dev);
+	if (error < 0) {
+		dev_err(&dpmcp_dev->dev,
+			"devm_request_irq() failed: %d\n",
+			error);
+		return error;
+	}
+
+	return 0;
+}
+
+static int enable_dpmcp_irq(struct fsl_mc_device *dpmcp_dev)
+{
+	int error;
+
+	/*
+	 * Enable MC command completion event to trigger DPMCP interrupt:
+	 */
+	error = dpmcp_set_irq_mask(dpmcp_dev->mc_io,
+				   MC_CMD_FLAG_INTR_DIS,
+				   dpmcp_dev->mc_handle,
+				   DPMCP_IRQ_INDEX,
+				   DPMCP_IRQ_EVENT_CMD_DONE);
+	if (error < 0) {
+		dev_err(&dpmcp_dev->dev,
+			"dpmcp_set_irq_mask() failed: %d\n", error);
+
+		return error;
+	}
+
+	/*
+	 * Enable generation of the interrupt:
+	 */
+	error = dpmcp_set_irq_enable(dpmcp_dev->mc_io,
+				     MC_CMD_FLAG_INTR_DIS,
+				     dpmcp_dev->mc_handle,
+				     DPMCP_IRQ_INDEX, 1);
+	if (error < 0) {
+		dev_err(&dpmcp_dev->dev,
+			"dpmcp_set_irq_enable() failed: %d\n", error);
+
+		return error;
+	}
+
+	return 0;
+}
+
+/*
+ * Setup MC command completion interrupt for the DPMCP device associated with a
+ * given fsl_mc_io object
+ */
+int fsl_mc_io_setup_dpmcp_irq(struct fsl_mc_io *mc_io)
+{
+	int error;
+	struct fsl_mc_device *dpmcp_dev = mc_io->dpmcp_dev;
+
+	if (WARN_ON(mc_io->flags & FSL_MC_IO_ATOMIC_CONTEXT_PORTAL))
+		return -EINVAL;
+
+	if (WARN_ON(!dpmcp_dev))
+		return -EINVAL;
+
+	if (WARN_ON(!fsl_mc_interrupts_supported()))
+		return -EINVAL;
+
+	if (WARN_ON(dpmcp_dev->obj_desc.irq_count != 1))
+		return -EINVAL;
+
+	if (WARN_ON(dpmcp_dev->mc_io != mc_io))
+		return -EINVAL;
+
+	error = fsl_mc_allocate_irqs(dpmcp_dev);
+	if (error < 0)
+		return error;
+
+	error = disable_dpmcp_irq(dpmcp_dev);
+	if (error < 0)
+		goto error_free_irqs;
+
+	error = register_dpmcp_irq_handler(dpmcp_dev);
+	if (error < 0)
+		goto error_free_irqs;
+
+	error = enable_dpmcp_irq(dpmcp_dev);
+	if (error < 0)
+		goto error_unregister_irq_handler;
+
+	mc_io->mc_command_done_irq_armed = true;
+	return 0;
+
+error_unregister_irq_handler:
+	unregister_dpmcp_irq_handler(dpmcp_dev);
+
+error_free_irqs:
+	fsl_mc_free_irqs(dpmcp_dev);
+
+	return error;
+}
+EXPORT_SYMBOL_GPL(fsl_mc_io_setup_dpmcp_irq);
+
+/*
+ * Tear down interrupts for the DPMCP device associated with a given fsl_mc_io
+ * object
+ */
+static void teardown_dpmcp_irq(struct fsl_mc_io *mc_io)
+{
+	struct fsl_mc_device *dpmcp_dev = mc_io->dpmcp_dev;
+
+	if (WARN_ON(!dpmcp_dev))
+		return;
+	if (WARN_ON(!fsl_mc_interrupts_supported()))
+		return;
+	if (WARN_ON(!dpmcp_dev->irqs))
+		return;
+
+	mc_io->mc_command_done_irq_armed = false;
+	(void)disable_dpmcp_irq(dpmcp_dev);
+	unregister_dpmcp_irq_handler(dpmcp_dev);
+	fsl_mc_free_irqs(dpmcp_dev);
+}
 
 /**
  * Creates an MC I/O object
@@ -70,9 +275,10 @@
 int __must_check fsl_create_mc_io(struct device *dev,
 				  phys_addr_t mc_portal_phys_addr,
 				  uint32_t mc_portal_size,
-				  struct fsl_mc_resource *resource,
+				  struct fsl_mc_device *dpmcp_dev,
 				  uint32_t flags, struct fsl_mc_io **new_mc_io)
 {
+	int error;
 	struct fsl_mc_io *mc_io;
 	void __iomem *mc_portal_virt_addr;
 	struct resource *res;
@@ -85,7 +291,14 @@ int __must_check fsl_create_mc_io(struct device *dev,
 	mc_io->flags = flags;
 	mc_io->portal_phys_addr = mc_portal_phys_addr;
 	mc_io->portal_size = mc_portal_size;
-	mc_io->resource = resource;
+	mc_io->mc_command_done_irq_armed = false;
+	if (flags & FSL_MC_IO_ATOMIC_CONTEXT_PORTAL) {
+		spin_lock_init(&mc_io->spinlock);
+	} else {
+		mutex_init(&mc_io->mutex);
+		init_completion(&mc_io->mc_command_done_completion);
+	}
+
 	res = devm_request_mem_region(dev,
 				      mc_portal_phys_addr,
 				      mc_portal_size,
@@ -108,8 +321,26 @@ int __must_check fsl_create_mc_io(struct device *dev,
 	}
 
 	mc_io->portal_virt_addr = mc_portal_virt_addr;
+	if (dpmcp_dev) {
+		error = fsl_mc_io_set_dpmcp(mc_io, dpmcp_dev);
+		if (error < 0)
+			goto error_destroy_mc_io;
+
+		if (!(flags & FSL_MC_IO_ATOMIC_CONTEXT_PORTAL) &&
+		    fsl_mc_interrupts_supported()) {
+			error = fsl_mc_io_setup_dpmcp_irq(mc_io);
+			if (error < 0)
+				goto error_destroy_mc_io;
+		}
+	}
+
 	*new_mc_io = mc_io;
 	return 0;
+
+error_destroy_mc_io:
+	fsl_destroy_mc_io(mc_io);
+	return error;
+
 }
 EXPORT_SYMBOL_GPL(fsl_create_mc_io);
 
@@ -120,6 +351,11 @@ EXPORT_SYMBOL_GPL(fsl_create_mc_io);
  */
 void fsl_destroy_mc_io(struct fsl_mc_io *mc_io)
 {
+	struct fsl_mc_device *dpmcp_dev = mc_io->dpmcp_dev;
+
+	if (dpmcp_dev)
+		fsl_mc_io_unset_dpmcp(mc_io);
+
 	devm_iounmap(mc_io->dev, mc_io->portal_virt_addr);
 	devm_release_mem_region(mc_io->dev,
 				mc_io->portal_phys_addr,
@@ -130,6 +366,64 @@ void fsl_destroy_mc_io(struct fsl_mc_io *mc_io)
 }
 EXPORT_SYMBOL_GPL(fsl_destroy_mc_io);
 
+int fsl_mc_io_set_dpmcp(struct fsl_mc_io *mc_io,
+			struct fsl_mc_device *dpmcp_dev)
+{
+	int error;
+
+	if (WARN_ON(!dpmcp_dev))
+		return -EINVAL;
+
+	if (WARN_ON(mc_io->dpmcp_dev))
+		return -EINVAL;
+
+	if (WARN_ON(dpmcp_dev->mc_io))
+		return -EINVAL;
+
+	if (!(mc_io->flags & FSL_MC_IO_ATOMIC_CONTEXT_PORTAL)) {
+		error = dpmcp_open(mc_io,
+				   0,
+				   dpmcp_dev->obj_desc.id,
+				   &dpmcp_dev->mc_handle);
+		if (error < 0)
+			return error;
+	}
+
+	mc_io->dpmcp_dev = dpmcp_dev;
+	dpmcp_dev->mc_io = mc_io;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(fsl_mc_io_set_dpmcp);
+
+void fsl_mc_io_unset_dpmcp(struct fsl_mc_io *mc_io)
+{
+	int error;
+	struct fsl_mc_device *dpmcp_dev = mc_io->dpmcp_dev;
+
+	if (WARN_ON(!dpmcp_dev))
+		return;
+
+	if (WARN_ON(dpmcp_dev->mc_io != mc_io))
+		return;
+
+	if (!(mc_io->flags & FSL_MC_IO_ATOMIC_CONTEXT_PORTAL)) {
+		if (dpmcp_dev->irqs)
+			teardown_dpmcp_irq(mc_io);
+
+		error = dpmcp_close(mc_io,
+				    0,
+				    dpmcp_dev->mc_handle);
+		if (error < 0) {
+			dev_err(&dpmcp_dev->dev, "dpmcp_close() failed: %d\n",
+				error);
+		}
+	}
+
+	mc_io->dpmcp_dev = NULL;
+	dpmcp_dev->mc_io = NULL;
+}
+EXPORT_SYMBOL_GPL(fsl_mc_io_unset_dpmcp);
+
 static int mc_status_to_error(enum mc_cmd_status status)
 {
 	static const int mc_status_to_error_map[] = {
@@ -223,21 +517,110 @@ static inline enum mc_cmd_status mc_read_response(struct mc_command __iomem *
 	return status;
 }
 
+static int mc_completion_wait(struct fsl_mc_io *mc_io, struct mc_command *cmd,
+			      enum mc_cmd_status *mc_status)
+{
+	enum mc_cmd_status status;
+	unsigned long jiffies_left;
+	unsigned long timeout_jiffies =
+		msecs_to_jiffies(MC_CMD_COMPLETION_TIMEOUT_MS);
+
+	if (WARN_ON(!mc_io->dpmcp_dev))
+		return -EINVAL;
+
+	if (WARN_ON(mc_io->flags & FSL_MC_IO_ATOMIC_CONTEXT_PORTAL))
+		return -EINVAL;
+
+	for (;;) {
+		status = mc_read_response(mc_io->portal_virt_addr, cmd);
+		if (status != MC_CMD_STATUS_READY)
+			break;
+
+		jiffies_left = wait_for_completion_timeout(
+					&mc_io->mc_command_done_completion,
+					timeout_jiffies);
+		if (jiffies_left == 0)
+			return -ETIMEDOUT;
+	}
+
+	*mc_status = status;
+	return 0;
+}
+
+static int mc_polling_wait_preemptible(struct fsl_mc_io *mc_io,
+				       struct mc_command *cmd,
+				       enum mc_cmd_status *mc_status)
+{
+	enum mc_cmd_status status;
+	unsigned long jiffies_until_timeout =
+		jiffies + msecs_to_jiffies(MC_CMD_COMPLETION_TIMEOUT_MS);
+
+	for (;;) {
+		status = mc_read_response(mc_io->portal_virt_addr, cmd);
+		if (status != MC_CMD_STATUS_READY)
+			break;
+
+		usleep_range(MC_CMD_COMPLETION_POLLING_MIN_SLEEP_USECS,
+			     MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS);
+
+		if (time_after_eq(jiffies, jiffies_until_timeout))
+			return -ETIMEDOUT;
+	}
+
+	*mc_status = status;
+	return 0;
+}
+
+static int mc_polling_wait_atomic(struct fsl_mc_io *mc_io,
+				  struct mc_command *cmd,
+				  enum mc_cmd_status *mc_status)
+{
+	enum mc_cmd_status status;
+	unsigned long timeout_usecs = MC_CMD_COMPLETION_TIMEOUT_MS * 1000;
+
+	BUILD_BUG_ON((MC_CMD_COMPLETION_TIMEOUT_MS * 1000) %
+		     MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS != 0);
+
+	for (;;) {
+		status = mc_read_response(mc_io->portal_virt_addr, cmd);
+		if (status != MC_CMD_STATUS_READY)
+			break;
+
+		udelay(MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS);
+		timeout_usecs -= MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS;
+		if (timeout_usecs == 0)
+			return -ETIMEDOUT;
+	}
+
+	*mc_status = status;
+	return 0;
+}
+
 /**
- * Sends an command to the MC device using the given MC I/O object
+ * Sends a command to the MC device using the given MC I/O object
  *
  * @mc_io: MC I/O object to be used
  * @cmd: command to be sent
  *
  * Returns '0' on Success; Error code otherwise.
- *
- * NOTE: This function cannot be invoked from from atomic contexts.
  */
 int mc_send_command(struct fsl_mc_io *mc_io, struct mc_command *cmd)
 {
+	int error;
 	enum mc_cmd_status status;
-	unsigned long jiffies_until_timeout =
-	    jiffies + MC_CMD_COMPLETION_TIMEOUT_JIFFIES;
+	unsigned long irq_flags = 0;
+	bool dpmcp_completion_intr_disabled =
+		(MC_CMD_HDR_READ_FLAGS(cmd->header) & MC_CMD_FLAG_INTR_DIS);
+
+	if (WARN_ON(in_irq() &&
+		    (!dpmcp_completion_intr_disabled ||
+		    !(mc_io->flags & FSL_MC_IO_ATOMIC_CONTEXT_PORTAL))))
+		return -EINVAL;
+
+	if (mc_io->flags & FSL_MC_IO_ATOMIC_CONTEXT_PORTAL)
+		spin_lock_irqsave(&mc_io->spinlock, irq_flags);
+	else
+		mutex_lock(&mc_io->mutex);
 
 	/*
 	 * Send command to the MC hardware:
@@ -247,41 +630,44 @@ int mc_send_command(struct fsl_mc_io *mc_io, struct mc_command *cmd)
 	/*
 	 * Wait for response from the MC hardware:
 	 */
-	for (;;) {
-		status = mc_read_response(mc_io->portal_virt_addr, cmd);
-		if (status != MC_CMD_STATUS_READY)
-			break;
-
-		/*
-		 * TODO: When MC command completion interrupts are supported
-		 * call wait function here instead of usleep_range()
-		 */
-		usleep_range(MC_CMD_COMPLETION_POLLING_MIN_SLEEP_USECS,
-			     MC_CMD_COMPLETION_POLLING_MAX_SLEEP_USECS);
-
-		if (time_after_eq(jiffies, jiffies_until_timeout)) {
+	if (mc_io->mc_command_done_irq_armed && !dpmcp_completion_intr_disabled)
+		error = mc_completion_wait(mc_io, cmd, &status);
+	else if (!(mc_io->flags & FSL_MC_IO_ATOMIC_CONTEXT_PORTAL))
+		error = mc_polling_wait_preemptible(mc_io, cmd, &status);
+	else
+		error = mc_polling_wait_atomic(mc_io, cmd, &status);
+
+	if (error < 0) {
+		if (error == -ETIMEDOUT) {
 			pr_debug("MC command timed out (portal: %#llx, obj handle: %#x, command: %#x)\n",
 				 mc_io->portal_phys_addr,
-				 (unsigned int)
-					MC_CMD_HDR_READ_TOKEN(cmd->header),
-				 (unsigned int)
-					MC_CMD_HDR_READ_CMDID(cmd->header));
-
-			return -ETIMEDOUT;
+				 (unsigned int) get_mc_cmd_hdr_token(cmd->header),
+				 (unsigned int) get_mc_cmd_hdr_cmdid(cmd->header));
 		}
+		goto common_exit;
+
 	}
 
 	if (status != MC_CMD_STATUS_OK) {
 		pr_debug("MC command failed: portal: %#llx, obj handle: %#x, command: %#x, status: %s (%#x)\n",
 			 mc_io->portal_phys_addr,
-			 (unsigned int)MC_CMD_HDR_READ_TOKEN(cmd->header),
-			 (unsigned int)MC_CMD_HDR_READ_CMDID(cmd->header),
+			 (unsigned int)get_mc_cmd_hdr_token(cmd->header),
+			 (unsigned int)get_mc_cmd_hdr_cmdid(cmd->header),
 			 mc_status_to_string(status),
 			 (unsigned int)status);
 
-		return mc_status_to_error(status);
+		error = mc_status_to_error(status);
+		goto common_exit;
 	}
 
-	return 0;
+	error = 0;
+
+common_exit:
+	if (mc_io->flags & FSL_MC_IO_ATOMIC_CONTEXT_PORTAL)
+		spin_unlock_irqrestore(&mc_io->spinlock, irq_flags);
+	else
+		mutex_unlock(&mc_io->mutex);
+
+	return error;
 }
 EXPORT_SYMBOL(mc_send_command);
diff --git a/drivers/staging/fsl-mc/include/dpbp-cmd.h b/drivers/staging/fsl-mc/include/dpbp-cmd.h
index 1fd70a2..7726800 100644
--- a/drivers/staging/fsl-mc/include/dpbp-cmd.h
+++ b/drivers/staging/fsl-mc/include/dpbp-cmd.h
@@ -1,60 +1,66 @@
-/* Copyright 2013-2014 Freescale Semiconductor Inc.
-*
-* Redistribution and use in source and binary forms, with or without
-* modification, are permitted provided that the following conditions are met:
-* * Redistributions of source code must retain the above copyright
-* notice, this list of conditions and the following disclaimer.
-* * Redistributions in binary form must reproduce the above copyright
-* notice, this list of conditions and the following disclaimer in the
-* documentation and/or other materials provided with the distribution.
-* * Neither the name of the above-listed copyright holders nor the
-* names of any contributors may be used to endorse or promote products
-* derived from this software without specific prior written permission.
-*
-*
-* ALTERNATIVELY, this software may be distributed under the terms of the
-* GNU General Public License ("GPL") as published by the Free Software
-* Foundation, either version 2 of that License or (at your option) any
-* later version.
-*
-* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
-* AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-* IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
-* ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
-* LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
-* CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
-* SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
-* INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
-* CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
-* ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
-* POSSIBILITY OF SUCH DAMAGE.
-*/
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ * * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * * Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in the
+ * documentation and/or other materials provided with the distribution.
+ * * Neither the name of the above-listed copyright holders nor the
+ * names of any contributors may be used to endorse or promote products
+ * derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
 #ifndef _FSL_DPBP_CMD_H
 #define _FSL_DPBP_CMD_H
 
 /* DPBP Version */
-#define DPBP_VER_MAJOR				2
-#define DPBP_VER_MINOR				0
+#define DPBP_VER_MAJOR				3
+#define DPBP_VER_MINOR				2
+#define DPBP_CMD_BASE_VERSION			1
+#define DPBP_CMD_ID_OFFSET			4
 
 /* Command IDs */
-#define DPBP_CMDID_CLOSE				0x800
-#define DPBP_CMDID_OPEN					0x804
-#define DPBP_CMDID_CREATE				0x904
-#define DPBP_CMDID_DESTROY				0x900
+#define DPBP_CMDID_CLOSE                        ((0x800 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_OPEN                         ((0x804 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_CREATE                       ((0x904 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_DESTROY                      ((0x984 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_GET_API_VERSION              ((0xa04 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
 
-#define DPBP_CMDID_ENABLE				0x002
-#define DPBP_CMDID_DISABLE				0x003
-#define DPBP_CMDID_GET_ATTR				0x004
-#define DPBP_CMDID_RESET				0x005
-#define DPBP_CMDID_IS_ENABLED				0x006
+#define DPBP_CMDID_ENABLE                       ((0x002 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_DISABLE                      ((0x003 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_GET_ATTR                     ((0x004 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_RESET                        ((0x005 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_IS_ENABLED                   ((0x006 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
 
-#define DPBP_CMDID_SET_IRQ				0x010
-#define DPBP_CMDID_GET_IRQ				0x011
-#define DPBP_CMDID_SET_IRQ_ENABLE			0x012
-#define DPBP_CMDID_GET_IRQ_ENABLE			0x013
-#define DPBP_CMDID_SET_IRQ_MASK				0x014
-#define DPBP_CMDID_GET_IRQ_MASK				0x015
-#define DPBP_CMDID_GET_IRQ_STATUS			0x016
-#define DPBP_CMDID_CLEAR_IRQ_STATUS			0x017
+#define DPBP_CMDID_SET_IRQ                      ((0x010 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_GET_IRQ                      ((0x011 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_SET_IRQ_ENABLE               ((0x012 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_GET_IRQ_ENABLE               ((0x013 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_SET_IRQ_MASK                 ((0x014 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_GET_IRQ_MASK                 ((0x015 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_GET_IRQ_STATUS               ((0x016 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_CLEAR_IRQ_STATUS             ((0x017 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+
+#define DPBP_CMDID_SET_NOTIFICATIONS           ((0x01b0 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
+#define DPBP_CMDID_GET_NOTIFICATIONS           ((0x01b1 << DPBP_CMD_ID_OFFSET) | DPBP_CMD_BASE_VERSION)
 
 #endif /* _FSL_DPBP_CMD_H */
diff --git a/drivers/staging/fsl-mc/include/dpbp.h b/drivers/staging/fsl-mc/include/dpbp.h
index 5f3c8e7..4268b59 100644
--- a/drivers/staging/fsl-mc/include/dpbp.h
+++ b/drivers/staging/fsl-mc/include/dpbp.h
@@ -1,4 +1,4 @@
-/* Copyright 2013-2015 Freescale Semiconductor Inc.
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -41,6 +41,7 @@ struct fsl_mc_io;
 /**
  * dpbp_open() - Open a control session for the specified object.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @dpbp_id:	DPBP unique ID
  * @token:	Returned token; use in subsequent API calls
  *
@@ -54,11 +55,15 @@ struct fsl_mc_io;
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dpbp_open(struct fsl_mc_io *mc_io, int dpbp_id, uint16_t *token);
+int dpbp_open(struct fsl_mc_io	*mc_io,
+	      uint32_t		cmd_flags,
+	      int		dpbp_id,
+	      uint16_t		*token);
 
 /**
  * dpbp_close() - Close the control session of the object
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  *
  * After this function is called, no further operations are
@@ -66,10 +71,12 @@ int dpbp_open(struct fsl_mc_io *mc_io, int dpbp_id, uint16_t *token);
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dpbp_close(struct fsl_mc_io *mc_io, uint16_t token);
+int dpbp_close(struct fsl_mc_io	*mc_io,
+	       uint32_t		cmd_flags,
+	       uint16_t		token);
 
 /**
- * struct dpbp_cfg() - Structure representing DPBP configuration
+ * struct dpbp_cfg - Structure representing DPBP configuration
  * @options:	place holder
  */
 struct dpbp_cfg {
@@ -79,117 +86,147 @@ struct dpbp_cfg {
 /**
  * dpbp_create() - Create the DPBP object.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @dprc_token:	Parent container token; '0' for default container
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @cfg:	Configuration structure
- * @token:	Returned token; use in subsequent API calls
+ * @obj_id: returned object id
  *
  * Create the DPBP object, allocate required resources and
  * perform required initialization.
  *
  * The object can be created either by declaring it in the
  * DPL file, or by calling this function.
- * This function returns a unique authentication token,
- * associated with the specific object ID and the specific MC
- * portal; this token must be used in all subsequent calls to
- * this specific object. For objects that are created using the
- * DPL file, call dpbp_open function to get an authentication
- * token first.
+ *
+ * The function accepts an authentication token of a parent
+ * container that this object should be assigned to. The token
+ * can be '0' so the object will be assigned to the default container.
+ * The newly created object can be opened with the returned
+ * object id and using the container's associated tokens and MC portals.
  *
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpbp_create(struct fsl_mc_io	*mc_io,
+		uint16_t		dprc_token,
+		uint32_t		cmd_flags,
 		const struct dpbp_cfg	*cfg,
-		uint16_t		*token);
+		uint32_t		*obj_id);
 
 /**
  * dpbp_destroy() - Destroy the DPBP object and release all its resources.
+ * @dprc_token: Parent container token; '0' for default container
  * @mc_io:	Pointer to MC portal's I/O object
- * @token:	Token of DPBP object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @object_id:	The object id; it must be a valid id within the container that
+ * created this object;
  *
  * Return:	'0' on Success; error code otherwise.
  */
-int dpbp_destroy(struct fsl_mc_io *mc_io, uint16_t token);
+int dpbp_destroy(struct fsl_mc_io	*mc_io,
+		 uint16_t		dprc_token,
+		 uint32_t		cmd_flags,
+		 uint32_t		object_id);
 
 /**
  * dpbp_enable() - Enable the DPBP.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dpbp_enable(struct fsl_mc_io *mc_io, uint16_t token);
+int dpbp_enable(struct fsl_mc_io	*mc_io,
+		uint32_t		cmd_flags,
+		uint16_t		token);
 
 /**
  * dpbp_disable() - Disable the DPBP.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dpbp_disable(struct fsl_mc_io *mc_io, uint16_t token);
+int dpbp_disable(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
+		 uint16_t		token);
 
 /**
  * dpbp_is_enabled() - Check if the DPBP is enabled.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  * @en:		Returns '1' if object is enabled; '0' otherwise
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dpbp_is_enabled(struct fsl_mc_io *mc_io, uint16_t token, int *en);
+int dpbp_is_enabled(struct fsl_mc_io	*mc_io,
+		    uint32_t		cmd_flags,
+		    uint16_t		token,
+		    int			*en);
 
 /**
  * dpbp_reset() - Reset the DPBP, returns the object to initial state.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dpbp_reset(struct fsl_mc_io *mc_io, uint16_t token);
+int dpbp_reset(struct fsl_mc_io	*mc_io,
+	       uint32_t		cmd_flags,
+	       uint16_t		token);
+
+/**
+ * struct dpbp_irq_cfg - IRQ configuration
+ * @addr:	Address that must be written to signal a message-based interrupt
+ * @val:	Value to write into irq_addr address
+ * @irq_num: A user defined number associated with this IRQ
+ */
+struct dpbp_irq_cfg {
+	     uint64_t		addr;
+	     uint32_t		val;
+	     int		irq_num;
+};
 
 /**
  * dpbp_set_irq() - Set IRQ information for the DPBP to trigger an interrupt.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  * @irq_index:	Identifies the interrupt index to configure
- * @irq_addr:	Address that must be written to
- *				signal a message-based interrupt
- * @irq_val:	Value to write into irq_addr address
- * @user_irq_id: A user defined number associated with this IRQ
+ * @irq_cfg:	IRQ configuration
  *
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpbp_set_irq(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
 		 uint16_t		token,
 		 uint8_t		irq_index,
-		 uint64_t		irq_addr,
-		 uint32_t		irq_val,
-		 int			user_irq_id);
+		 struct dpbp_irq_cfg	*irq_cfg);
 
 /**
  * dpbp_get_irq() - Get IRQ information from the DPBP.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  * @irq_index:	The interrupt index to configure
  * @type:	Interrupt type: 0 represents message interrupt
- *				type (both irq_addr and irq_val are valid)
- * @irq_addr:	Returned address that must be written to
- *				signal the message-based interrupt
- * @irq_val:	Value to write into irq_addr address
- * @user_irq_id: A user defined number associated with this IRQ
+ *		type (both irq_addr and irq_val are valid)
+ * @irq_cfg:	IRQ attributes
  *
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpbp_get_irq(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
 		 uint16_t		token,
 		 uint8_t		irq_index,
 		 int			*type,
-		 uint64_t		*irq_addr,
-		 uint32_t		*irq_val,
-		 int			*user_irq_id);
+		 struct dpbp_irq_cfg	*irq_cfg);
 
 /**
  * dpbp_set_irq_enable() - Set overall interrupt state.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  * @irq_index:	The interrupt index to configure
  * @en:	Interrupt state - enable = 1, disable = 0
@@ -202,6 +239,7 @@ int dpbp_get_irq(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpbp_set_irq_enable(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
 			uint16_t		token,
 			uint8_t			irq_index,
 			uint8_t			en);
@@ -209,6 +247,7 @@ int dpbp_set_irq_enable(struct fsl_mc_io	*mc_io,
 /**
  * dpbp_get_irq_enable() - Get overall interrupt state
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  * @irq_index:	The interrupt index to configure
  * @en:		Returned interrupt state - enable = 1, disable = 0
@@ -216,6 +255,7 @@ int dpbp_set_irq_enable(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpbp_get_irq_enable(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
 			uint16_t		token,
 			uint8_t			irq_index,
 			uint8_t			*en);
@@ -223,6 +263,7 @@ int dpbp_get_irq_enable(struct fsl_mc_io	*mc_io,
 /**
  * dpbp_set_irq_mask() - Set interrupt mask.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  * @irq_index:	The interrupt index to configure
  * @mask:	Event mask to trigger interrupt;
@@ -236,6 +277,7 @@ int dpbp_get_irq_enable(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpbp_set_irq_mask(struct fsl_mc_io	*mc_io,
+		      uint32_t		cmd_flags,
 		      uint16_t		token,
 		      uint8_t		irq_index,
 		      uint32_t		mask);
@@ -243,6 +285,7 @@ int dpbp_set_irq_mask(struct fsl_mc_io	*mc_io,
 /**
  * dpbp_get_irq_mask() - Get interrupt mask.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  * @irq_index:	The interrupt index to configure
  * @mask:	Returned event mask to trigger interrupt
@@ -253,6 +296,7 @@ int dpbp_set_irq_mask(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpbp_get_irq_mask(struct fsl_mc_io	*mc_io,
+		      uint32_t		cmd_flags,
 		      uint16_t		token,
 		      uint8_t		irq_index,
 		      uint32_t		*mask);
@@ -261,6 +305,7 @@ int dpbp_get_irq_mask(struct fsl_mc_io	*mc_io,
  * dpbp_get_irq_status() - Get the current status of any pending interrupts.
  *
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  * @irq_index:	The interrupt index to configure
  * @status:	Returned interrupts status - one bit per cause:
@@ -270,6 +315,7 @@ int dpbp_get_irq_mask(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpbp_get_irq_status(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
 			uint16_t		token,
 			uint8_t			irq_index,
 			uint32_t		*status);
@@ -278,6 +324,7 @@ int dpbp_get_irq_status(struct fsl_mc_io	*mc_io,
  * dpbp_clear_irq_status() - Clear a pending interrupt's status
  *
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  * @irq_index:	The interrupt index to configure
  * @status:	Bits to clear (W1C) - one bit per cause:
@@ -287,6 +334,7 @@ int dpbp_get_irq_status(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpbp_clear_irq_status(struct fsl_mc_io	*mc_io,
+			  uint32_t		cmd_flags,
 			  uint16_t		token,
 			  uint8_t		irq_index,
 			  uint32_t		status);
@@ -294,21 +342,11 @@ int dpbp_clear_irq_status(struct fsl_mc_io	*mc_io,
 /**
  * struct dpbp_attr - Structure representing DPBP attributes
  * @id:		DPBP object ID
- * @version:	DPBP version
  * @bpid:	Hardware buffer pool ID; should be used as an argument in
  *		acquire/release operations on buffers
  */
 struct dpbp_attr {
 	int id;
-	/**
-	 * struct version - Structure representing DPBP version
-	 * @major:	DPBP major version
-	 * @minor:	DPBP minor version
-	 */
-	struct {
-		uint16_t major;
-		uint16_t minor;
-	} version;
 	uint16_t bpid;
 };
 
@@ -316,15 +354,94 @@ struct dpbp_attr {
  * dpbp_get_attributes - Retrieve DPBP attributes.
  *
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPBP object
  * @attr:	Returned object's attributes
  *
  * Return:	'0' on Success; Error code otherwise.
  */
 int dpbp_get_attributes(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
 			uint16_t		token,
 			struct dpbp_attr	*attr);
 
-/** @} */
+/**
+ *  DPBP notifications options
+ */
+
+/**
+ * BPSCN write will attempt to allocate into a cache (coherent write)
+ */
+#define DPBP_NOTIF_OPT_COHERENT_WRITE	0x00000001
+
+/**
+ * struct dpbp_notification_cfg - Structure representing DPBP notifications
+ *	towards software
+ * @depletion_entry: below this threshold the pool is "depleted";
+ *	set it to '0' to disable it
+ * @depletion_exit: greater than or equal to this threshold the pool exit its
+ *	"depleted" state
+ * @surplus_entry: above this threshold the pool is in "surplus" state;
+ *	set it to '0' to disable it
+ * @surplus_exit: less than or equal to this threshold the pool exit its
+ *	"surplus" state
+ * @message_iova: MUST be given if either 'depletion_entry' or 'surplus_entry'
+ *	is not '0' (enable); I/O virtual address (must be in DMA-able memory),
+ *	must be 16B aligned.
+ * @message_ctx: The context that will be part of the BPSCN message and will
+ *	be written to 'message_iova'
+ * @options: Mask of available options; use 'DPBP_NOTIF_OPT_<X>' values
+ */
+struct dpbp_notification_cfg {
+	uint32_t	depletion_entry;
+	uint32_t	depletion_exit;
+	uint32_t	surplus_entry;
+	uint32_t	surplus_exit;
+	uint64_t	message_iova;
+	uint64_t	message_ctx;
+	uint16_t	options;
+};
+
+/**
+ * dpbp_set_notifications() - Set notifications towards software
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPBP object
+ * @cfg:	notifications configuration
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpbp_set_notifications(struct fsl_mc_io	*mc_io,
+			   uint32_t		cmd_flags,
+			   uint16_t		token,
+			   struct dpbp_notification_cfg	*cfg);
+
+/**
+ * dpbp_get_notifications() - Get the notifications configuration
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPBP object
+ * @cfg:	notifications configuration
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpbp_get_notifications(struct fsl_mc_io		*mc_io,
+			   uint32_t			cmd_flags,
+			   uint16_t			token,
+			   struct dpbp_notification_cfg	*cfg);
+
+/**
+ * dpbp_get_api_version() - Get buffer pool API version
+ * @mc_io:  Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @major_ver:	Major version of data path buffer pool API
+ * @minor_ver:	Minor version of data path buffer pool API
+ *
+ * Return:  '0' on Success; Error code otherwise.
+ */
+int dpbp_get_api_version(struct fsl_mc_io *mc_io,
+			 uint32_t cmd_flags,
+			 uint16_t *major_ver,
+			 uint16_t *minor_ver);
 
 #endif /* __FSL_DPBP_H */
diff --git a/drivers/staging/fsl-mc/include/dpcon-cmd.h b/drivers/staging/fsl-mc/include/dpcon-cmd.h
index c878d33..bf35382 100644
--- a/drivers/staging/fsl-mc/include/dpcon-cmd.h
+++ b/drivers/staging/fsl-mc/include/dpcon-cmd.h
@@ -1,62 +1,163 @@
-/* Copyright 2013-2015 Freescale Semiconductor Inc.
-*
-* Redistribution and use in source and binary forms, with or without
-* modification, are permitted provided that the following conditions are met:
-* * Redistributions of source code must retain the above copyright
-* notice, this list of conditions and the following disclaimer.
-* * Redistributions in binary form must reproduce the above copyright
-* notice, this list of conditions and the following disclaimer in the
-* documentation and/or other materials provided with the distribution.
-* * Neither the name of the above-listed copyright holders nor the
-* names of any contributors may be used to endorse or promote products
-* derived from this software without specific prior written permission.
-*
-*
-* ALTERNATIVELY, this software may be distributed under the terms of the
-* GNU General Public License ("GPL") as published by the Free Software
-* Foundation, either version 2 of that License or (at your option) any
-* later version.
-*
-* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
-* AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-* IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
-* ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
-* LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
-* CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
-* SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
-* INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
-* CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
-* ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
-* POSSIBILITY OF SUCH DAMAGE.
-*/
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ * * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * * Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in the
+ * documentation and/or other materials provided with the distribution.
+ * * Neither the name of the above-listed copyright holders nor the
+ * names of any contributors may be used to endorse or promote products
+ * derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
 #ifndef _FSL_DPCON_CMD_H
 #define _FSL_DPCON_CMD_H
 
 /* DPCON Version */
-#define DPCON_VER_MAJOR				2
-#define DPCON_VER_MINOR				0
+#define DPCON_VER_MAJOR				3
+#define DPCON_VER_MINOR				2
+#define DPCON_CMD_BASE_VERSION			1
+#define DPCON_CMD_ID_OFFSET			4
 
 /* Command IDs */
-#define DPCON_CMDID_CLOSE				0x800
-#define DPCON_CMDID_OPEN				0x808
-#define DPCON_CMDID_CREATE				0x908
-#define DPCON_CMDID_DESTROY				0x900
-
-#define DPCON_CMDID_ENABLE				0x002
-#define DPCON_CMDID_DISABLE				0x003
-#define DPCON_CMDID_GET_ATTR				0x004
-#define DPCON_CMDID_RESET				0x005
-#define DPCON_CMDID_IS_ENABLED				0x006
-
-#define DPCON_CMDID_SET_IRQ				0x010
-#define DPCON_CMDID_GET_IRQ				0x011
-#define DPCON_CMDID_SET_IRQ_ENABLE			0x012
-#define DPCON_CMDID_GET_IRQ_ENABLE			0x013
-#define DPCON_CMDID_SET_IRQ_MASK			0x014
-#define DPCON_CMDID_GET_IRQ_MASK			0x015
-#define DPCON_CMDID_GET_IRQ_STATUS			0x016
-#define DPCON_CMDID_CLEAR_IRQ_STATUS			0x017
-
-#define DPCON_CMDID_SET_NOTIFICATION			0x100
+#define DPCON_CMDID_CLOSE                       ((0x800 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_OPEN                        ((0x808 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_CREATE                      ((0x908 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_DESTROY                     ((0x988 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_GET_API_VERSION             ((0xa08 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+
+#define DPCON_CMDID_ENABLE                      ((0x002 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_DISABLE                     ((0x003 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_GET_ATTR                    ((0x004 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_RESET                       ((0x005 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_IS_ENABLED                  ((0x006 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+
+#define DPCON_CMDID_SET_IRQ                     ((0x010 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_GET_IRQ                     ((0x011 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_SET_IRQ_ENABLE              ((0x012 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_GET_IRQ_ENABLE              ((0x013 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_SET_IRQ_MASK                ((0x014 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_GET_IRQ_MASK                ((0x015 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_GET_IRQ_STATUS              ((0x016 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+#define DPCON_CMDID_CLEAR_IRQ_STATUS            ((0x017 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+
+#define DPCON_CMDID_SET_NOTIFICATION            ((0x100 << DPCON_CMD_ID_OFFSET) | DPCON_CMD_BASE_VERSION)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_CMD_OPEN(cmd, dpcon_id) \
+	MC_CMD_OP(cmd, 0, 0,  32, int,      dpcon_id)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_CMD_CREATE(cmd, cfg) \
+	MC_CMD_OP(cmd, 0, 0,  8,  uint8_t,  cfg->num_priorities)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_RSP_IS_ENABLED(cmd, en) \
+	MC_RSP_OP(cmd, 0, 0,  1,  int,	    en)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_CMD_SET_IRQ(cmd, irq_index, irq_cfg) \
+do { \
+	MC_CMD_OP(cmd, 0, 0,  8,  uint8_t,  irq_index);\
+	MC_CMD_OP(cmd, 0, 32, 32, uint32_t, irq_cfg->val);\
+	MC_CMD_OP(cmd, 1, 0,  64, uint64_t, irq_cfg->addr);\
+	MC_CMD_OP(cmd, 2, 0,  32, int,	    irq_cfg->irq_num); \
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_CMD_GET_IRQ(cmd, irq_index) \
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_RSP_GET_IRQ(cmd, type, irq_cfg) \
+do { \
+	MC_RSP_OP(cmd, 0, 0,  32, uint32_t, irq_cfg->val);\
+	MC_RSP_OP(cmd, 1, 0,  64, uint64_t, irq_cfg->addr);\
+	MC_RSP_OP(cmd, 2, 0,  32, int,	    irq_cfg->irq_num); \
+	MC_RSP_OP(cmd, 2, 32, 32, int,	    type);\
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_CMD_SET_IRQ_ENABLE(cmd, irq_index, en) \
+do { \
+	MC_CMD_OP(cmd, 0, 0,  8,  uint8_t,  en); \
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index);\
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_CMD_GET_IRQ_ENABLE(cmd, irq_index) \
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_RSP_GET_IRQ_ENABLE(cmd, en) \
+	MC_RSP_OP(cmd, 0, 0,  8,  uint8_t,  en)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_CMD_SET_IRQ_MASK(cmd, irq_index, mask) \
+do { \
+	MC_CMD_OP(cmd, 0, 0,  32, uint32_t, mask); \
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index);\
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_CMD_GET_IRQ_MASK(cmd, irq_index) \
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_RSP_GET_IRQ_MASK(cmd, mask) \
+	MC_RSP_OP(cmd, 0, 0,  32, uint32_t, mask)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_CMD_GET_IRQ_STATUS(cmd, irq_index, status) \
+do { \
+	MC_CMD_OP(cmd, 0, 0,  32, uint32_t, status);\
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index);\
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_RSP_GET_IRQ_STATUS(cmd, status) \
+	MC_RSP_OP(cmd, 0, 0,  32, uint32_t, status)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_CMD_CLEAR_IRQ_STATUS(cmd, irq_index, status) \
+do { \
+	MC_CMD_OP(cmd, 0, 0,  32, uint32_t, status); \
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  irq_index);\
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_RSP_GET_ATTR(cmd, attr) \
+do { \
+	MC_RSP_OP(cmd, 0, 0,  32, int,	    attr->id);\
+	MC_RSP_OP(cmd, 0, 32, 16, uint16_t, attr->qbman_ch_id);\
+	MC_RSP_OP(cmd, 0, 48, 8,  uint8_t,  attr->num_priorities);\
+} while (0)
+
+/*                cmd, param, offset, width, type, arg_name */
+#define DPCON_CMD_SET_NOTIFICATION(cmd, cfg) \
+do { \
+	MC_CMD_OP(cmd, 0, 0,  32, int,      cfg->dpio_id);\
+	MC_CMD_OP(cmd, 0, 32, 8,  uint8_t,  cfg->priority);\
+	MC_CMD_OP(cmd, 1, 0,  64, uint64_t, cfg->user_ctx);\
+} while (0)
 
 #endif /* _FSL_DPCON_CMD_H */
diff --git a/drivers/staging/fsl-mc/include/dpcon.h b/drivers/staging/fsl-mc/include/dpcon.h
new file mode 100644
index 0000000..b81c37c
--- /dev/null
+++ b/drivers/staging/fsl-mc/include/dpcon.h
@@ -0,0 +1,421 @@
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ * * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * * Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in the
+ * documentation and/or other materials provided with the distribution.
+ * * Neither the name of the above-listed copyright holders nor the
+ * names of any contributors may be used to endorse or promote products
+ * derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef __FSL_DPCON_H
+#define __FSL_DPCON_H
+
+/* Data Path Concentrator API
+ * Contains initialization APIs and runtime control APIs for DPCON
+ */
+
+struct fsl_mc_io;
+
+/** General DPCON macros */
+
+/**
+ * Use it to disable notifications; see dpcon_set_notification()
+ */
+#define DPCON_INVALID_DPIO_ID		(int)(-1)
+
+/**
+ * dpcon_open() - Open a control session for the specified object
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @dpcon_id:	DPCON unique ID
+ * @token:	Returned token; use in subsequent API calls
+ *
+ * This function can be used to open a control session for an
+ * already created object; an object may have been declared in
+ * the DPL or by calling the dpcon_create() function.
+ * This function returns a unique authentication token,
+ * associated with the specific object ID and the specific MC
+ * portal; this token must be used in all subsequent commands for
+ * this specific object.
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_open(struct fsl_mc_io *mc_io,
+	       uint32_t		cmd_flags,
+	       int		dpcon_id,
+	       uint16_t		*token);
+
+/**
+ * dpcon_close() - Close the control session of the object
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ *
+ * After this function is called, no further operations are
+ * allowed on the object without opening a new control session.
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_close(struct fsl_mc_io	*mc_io,
+		uint32_t		cmd_flags,
+		uint16_t		token);
+
+/**
+ * struct dpcon_cfg - Structure representing DPCON configuration
+ * @num_priorities: Number of priorities for the DPCON channel (1-8)
+ */
+struct dpcon_cfg {
+	uint8_t num_priorities;
+};
+
+/**
+ * dpcon_create() - Create the DPCON object.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @dprc_token:	Parent container token; '0' for default container
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @cfg:	Configuration structure
+ * @obj_id: returned object id
+ *
+ * Create the DPCON object, allocate required resources and
+ * perform required initialization.
+ *
+ * The object can be created either by declaring it in the
+ * DPL file, or by calling this function.
+ *
+ * The function accepts an authentication token of a parent
+ * container that this object should be assigned to. The token
+ * can be '0' so the object will be assigned to the default container.
+ * The newly created object can be opened with the returned
+ * object id and using the container's associated tokens and MC portals.
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_create(struct fsl_mc_io	*mc_io,
+		 uint16_t		dprc_token,
+		uint32_t		cmd_flags,
+		const struct dpcon_cfg	*cfg,
+		uint32_t		*obj_id);
+
+/**
+ * dpcon_destroy() - Destroy the DPCON object and release all its resources.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @dprc_token: Parent container token; '0' for default container
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @object_id:	The object id; it must be a valid id within the container that
+ * created this object;
+ *
+ * The function accepts the authentication token of the parent container that
+ * created the object (not the one that currently owns the object). The object
+ * is searched within parent using the provided 'object_id'.
+ * All tokens to the object must be closed before calling destroy.
+ *
+ * Return:	'0' on Success; error code otherwise.
+ */
+int dpcon_destroy(struct fsl_mc_io	*mc_io,
+		  uint16_t		dprc_token,
+		uint32_t		cmd_flags,
+		uint32_t		object_id);
+
+/**
+ * dpcon_enable() - Enable the DPCON
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ *
+ * Return:	'0' on Success; Error code otherwise
+ */
+int dpcon_enable(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
+		 uint16_t		token);
+
+/**
+ * dpcon_disable() - Disable the DPCON
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ *
+ * Return:	'0' on Success; Error code otherwise
+ */
+int dpcon_disable(struct fsl_mc_io	*mc_io,
+		  uint32_t		cmd_flags,
+		  uint16_t		token);
+
+/**
+ * dpcon_is_enabled() -	Check if the DPCON is enabled.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ * @en:		Returns '1' if object is enabled; '0' otherwise
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_is_enabled(struct fsl_mc_io	*mc_io,
+		     uint32_t		cmd_flags,
+		     uint16_t		token,
+		     int		*en);
+
+/**
+ * dpcon_reset() - Reset the DPCON, returns the object to initial state.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_reset(struct fsl_mc_io	*mc_io,
+		uint32_t		cmd_flags,
+		uint16_t		token);
+
+/**
+ * struct dpcon_irq_cfg - IRQ configuration
+ * @addr:	Address that must be written to signal a message-based interrupt
+ * @val:	Value to write into irq_addr address
+ * @irq_num: A user defined number associated with this IRQ
+ */
+struct dpcon_irq_cfg {
+	     uint64_t		addr;
+	     uint32_t		val;
+	     int		irq_num;
+};
+
+/**
+ * dpcon_set_irq() - Set IRQ information for the DPCON to trigger an interrupt.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ * @irq_index:	Identifies the interrupt index to configure
+ * @irq_cfg:	IRQ configuration
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_set_irq(struct fsl_mc_io	*mc_io,
+		  uint32_t		cmd_flags,
+		  uint16_t		token,
+		  uint8_t		irq_index,
+		  struct dpcon_irq_cfg	*irq_cfg);
+
+/**
+ * dpcon_get_irq() - Get IRQ information from the DPCON.
+ *
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ * @irq_index:	The interrupt index to configure
+ * @type:	Interrupt type: 0 represents message interrupt
+ *		type (both irq_addr and irq_val are valid)
+ * @irq_cfg:	IRQ attributes
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_get_irq(struct fsl_mc_io	*mc_io,
+		  uint32_t		cmd_flags,
+		  uint16_t		token,
+		  uint8_t		irq_index,
+		  int			*type,
+		  struct dpcon_irq_cfg	*irq_cfg);
+
+/**
+ * dpcon_set_irq_enable() - Set overall interrupt state.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ * @irq_index:	The interrupt index to configure
+ * @en:		Interrupt state - enable = 1, disable = 0
+ *
+ * Allows GPP software to control when interrupts are generated.
+ * Each interrupt can have up to 32 causes.  The enable/disable control's the
+ * overall interrupt state. if the interrupt is disabled no causes will cause
+ * an interrupt.
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_set_irq_enable(struct fsl_mc_io	*mc_io,
+			 uint32_t		cmd_flags,
+			 uint16_t		token,
+			 uint8_t		irq_index,
+			 uint8_t		en);
+
+/**
+ * dpcon_get_irq_enable() - Get overall interrupt state.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ * @irq_index:	The interrupt index to configure
+ * @en:		Returned interrupt state - enable = 1, disable = 0
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_get_irq_enable(struct fsl_mc_io	*mc_io,
+			 uint32_t		cmd_flags,
+			 uint16_t		token,
+			 uint8_t		irq_index,
+			 uint8_t		*en);
+
+/**
+ * dpcon_set_irq_mask() - Set interrupt mask.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ * @irq_index:	The interrupt index to configure
+ * @mask:	Event mask to trigger interrupt;
+ *				each bit:
+ *					0 = ignore event
+ *					1 = consider event for asserting IRQ
+ *
+ * Every interrupt can have up to 32 causes and the interrupt model supports
+ * masking/unmasking each cause independently
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_set_irq_mask(struct fsl_mc_io	*mc_io,
+		       uint32_t		cmd_flags,
+		       uint16_t		token,
+		       uint8_t		irq_index,
+		       uint32_t		mask);
+
+/**
+ * dpcon_get_irq_mask() - Get interrupt mask.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ * @irq_index:	The interrupt index to configure
+ * @mask:	Returned event mask to trigger interrupt
+ *
+ * Every interrupt can have up to 32 causes and the interrupt model supports
+ * masking/unmasking each cause independently
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_get_irq_mask(struct fsl_mc_io	*mc_io,
+		       uint32_t		cmd_flags,
+		       uint16_t		token,
+		       uint8_t		irq_index,
+		       uint32_t		*mask);
+
+/**
+ * dpcon_get_irq_status() - Get the current status of any pending interrupts.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ * @irq_index:	The interrupt index to configure
+ * @status:	interrupts status - one bit per cause:
+ *			0 = no interrupt pending
+ *			1 = interrupt pending
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_get_irq_status(struct fsl_mc_io	*mc_io,
+			 uint32_t		cmd_flags,
+			 uint16_t		token,
+			 uint8_t		irq_index,
+			 uint32_t		*status);
+
+/**
+ * dpcon_clear_irq_status() - Clear a pending interrupt's status
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ * @irq_index:	The interrupt index to configure
+ * @status:	bits to clear (W1C) - one bit per cause:
+ *			0 = don't change
+ *			1 = clear status bit
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_clear_irq_status(struct fsl_mc_io	*mc_io,
+			   uint32_t		cmd_flags,
+			   uint16_t		token,
+			   uint8_t		irq_index,
+			   uint32_t		status);
+
+/**
+ * struct dpcon_attr - Structure representing DPCON attributes
+ * @id: DPCON object ID
+ * @qbman_ch_id: Channel ID to be used by dequeue operation
+ * @num_priorities: Number of priorities for the DPCON channel (1-8)
+ */
+struct dpcon_attr {
+	int id;
+	uint16_t qbman_ch_id;
+	uint8_t num_priorities;
+};
+
+/**
+ * dpcon_get_attributes() - Retrieve DPCON attributes.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ * @attr:	Object's attributes
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dpcon_get_attributes(struct fsl_mc_io	*mc_io,
+			 uint32_t		cmd_flags,
+			 uint16_t		token,
+			 struct dpcon_attr	*attr);
+
+/**
+ * struct dpcon_notification_cfg - Structure representing notification
+ *					parameters
+ * @dpio_id:	DPIO object ID; must be configured with a notification channel;
+ *	to disable notifications set it to 'DPCON_INVALID_DPIO_ID';
+ * @priority:	Priority selection within the DPIO channel; valid values
+ *		are 0-7, depending on the number of priorities in that channel
+ * @user_ctx:	User context value provided with each CDAN message
+ */
+struct dpcon_notification_cfg {
+	int		dpio_id;
+	uint8_t		priority;
+	uint64_t	user_ctx;
+};
+
+/**
+ * dpcon_set_notification() - Set DPCON notification destination
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPCON object
+ * @cfg:	Notification parameters
+ *
+ * Return:	'0' on Success; Error code otherwise
+ */
+int dpcon_set_notification(struct fsl_mc_io			*mc_io,
+			   uint32_t				cmd_flags,
+			   uint16_t				token,
+			   struct dpcon_notification_cfg	*cfg);
+
+/**
+ * dpcon_get_api_version() - Get Data Path Concentrator API version
+ * @mc_io:  Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @major_ver:	Major version of data path concentrator API
+ * @minor_ver:	Minor version of data path concentrator API
+ *
+ * Return:  '0' on Success; Error code otherwise.
+ */
+int dpcon_get_api_version(struct fsl_mc_io *mc_io,
+			  uint32_t cmd_flags,
+			  uint16_t *major_ver,
+			  uint16_t *minor_ver);
+
+#endif /* __FSL_DPCON_H */
diff --git a/drivers/staging/fsl-mc/include/dpmng.h b/drivers/staging/fsl-mc/include/dpmng.h
index 1b052b8..dd194df 100644
--- a/drivers/staging/fsl-mc/include/dpmng.h
+++ b/drivers/staging/fsl-mc/include/dpmng.h
@@ -1,4 +1,4 @@
-/* Copyright 2013-2015 Freescale Semiconductor Inc.
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -39,13 +39,7 @@
 struct fsl_mc_io;
 
 /**
- * Management Complex firmware version information
- */
-#define MC_VER_MAJOR 6
-#define MC_VER_MINOR 0
-
-/**
- * struct mc_versoin
+ * struct mc_version
  * @major: Major version number: incremented on API compatibility changes
  * @minor: Minor version number: incremented on API additions (that are
  *		backward compatible); reset when major version is incremented
@@ -62,19 +56,14 @@ struct mc_version {
  * mc_get_version() - Retrieves the Management Complex firmware
  *			version information
  * @mc_io:		Pointer to opaque I/O object
+ * @cmd_flags:		Command flags; one or more of 'MC_CMD_FLAG_'
  * @mc_ver_info:	Returned version information structure
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int mc_get_version(struct fsl_mc_io *mc_io, struct mc_version *mc_ver_info);
+int mc_get_version(struct fsl_mc_io	*mc_io,
+		   uint32_t		cmd_flags,
+		   struct mc_version	*mc_ver_info);
 
-/**
- * dpmng_get_container_id() - Get container ID associated with a given portal.
- * @mc_io:		Pointer to MC portal's I/O object
- * @container_id:	Requested container ID
- *
- * Return:	'0' on Success; Error code otherwise.
- */
-int dpmng_get_container_id(struct fsl_mc_io *mc_io, int *container_id);
 
 #endif /* __FSL_DPMNG_H */
diff --git a/drivers/staging/fsl-mc/include/dprc.h b/drivers/staging/fsl-mc/include/dprc.h
index f1862a7..e9dab47 100644
--- a/drivers/staging/fsl-mc/include/dprc.h
+++ b/drivers/staging/fsl-mc/include/dprc.h
@@ -1,4 +1,4 @@
-/* Copyright 2013-2015 Freescale Semiconductor Inc.
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -32,6 +32,8 @@
 #ifndef _FSL_DPRC_H
 #define _FSL_DPRC_H
 
+#include "mc-cmd.h"
+
 /* Data Path Resource Container API
  * Contains DPRC API for managing and querying DPAA resources
  */
@@ -53,8 +55,21 @@ struct fsl_mc_io;
 #define DPRC_GET_PORTAL_ID_FROM_POOL	(int)(~(0))
 
 /**
+ * dprc_get_container_id() - Get container ID associated with a given portal.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @container_id:	Requested container ID
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dprc_get_container_id(struct fsl_mc_io	*mc_io,
+			  uint32_t		cmd_flags,
+			  int			*container_id);
+
+/**
  * dprc_open() - Open DPRC object for use
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @container_id: Container ID to open
  * @token:	Returned token of DPRC object
  *
@@ -62,11 +77,15 @@ struct fsl_mc_io;
  *
  * @warning	Required before any operation on the object.
  */
-int dprc_open(struct fsl_mc_io *mc_io, int container_id, uint16_t *token);
+int dprc_open(struct fsl_mc_io	*mc_io,
+	      uint32_t		cmd_flags,
+	      int		container_id,
+	      uint16_t		*token);
 
 /**
  * dprc_close() - Close the control session of the object
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  *
  * After this function is called, no further operations are
@@ -74,7 +93,9 @@ int dprc_open(struct fsl_mc_io *mc_io, int container_id, uint16_t *token);
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dprc_close(struct fsl_mc_io *mc_io, uint16_t token);
+int dprc_close(struct fsl_mc_io	*mc_io,
+	       uint32_t		cmd_flags,
+	       uint16_t		token);
 
 /**
  * Container general options
@@ -99,7 +120,7 @@ int dprc_close(struct fsl_mc_io *mc_io, uint16_t token);
 /* Object initialization allowed - software context associated with this
  * container is allowed to invoke object initialization operations.
  */
-#define DPRC_CFG_OPT_OBJ_CREATE_ALLOWED	0x00000004
+#define DPRC_CFG_OPT_OBJ_CREATE_ALLOWED         0x00000004
 
 /* Topology change allowed - software context associated with this
  * container is allowed to invoke topology operations, such as attach/detach
@@ -107,14 +128,12 @@ int dprc_close(struct fsl_mc_io *mc_io, uint16_t token);
  */
 #define DPRC_CFG_OPT_TOPOLOGY_CHANGES_ALLOWED	0x00000008
 
-/* IOMMU bypass - indicates whether objects of this container are permitted
- * to bypass the IOMMU.
- */
-#define DPRC_CFG_OPT_IOMMU_BYPASS		0x00000010
-
 /* AIOP - Indicates that container belongs to AIOP.  */
 #define DPRC_CFG_OPT_AIOP			0x00000020
 
+/* IRQ Config - Indicates that the container allowed to configure its IRQs.  */
+#define DPRC_CFG_OPT_IRQ_CFG_ALLOWED		0x00000040
+
 /**
  * struct dprc_cfg - Container configuration options
  * @icid: Container's ICID; if set to 'DPRC_GET_ICID_FROM_POOL', a free
@@ -122,33 +141,37 @@ int dprc_close(struct fsl_mc_io *mc_io, uint16_t token);
  * @portal_id: Portal ID; if set to 'DPRC_GET_PORTAL_ID_FROM_POOL', a free
  *		portal ID is allocated by the DPRC
  * @options: Combination of 'DPRC_CFG_OPT_<X>' options
+ * @label: Object's label
  */
 struct dprc_cfg {
-	uint16_t icid;
-	int portal_id;
-	uint64_t options;
+	uint16_t	icid;
+	int		portal_id;
+	uint64_t	options;
+	char		label[16];
 };
 
 /**
  * dprc_create_container() - Create child container
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @cfg:	Child container configuration
  * @child_container_id:	Returned child container ID
- * @child_portal_paddr:	Returned base physical address of the
- *					child portal
+ * @child_portal_offset: Returned child portal offset from MC portal base
  *
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_create_container(struct fsl_mc_io	*mc_io,
+			  uint32_t		cmd_flags,
 			  uint16_t		token,
 			  struct dprc_cfg	*cfg,
 			  int			*child_container_id,
-			  uint64_t		*child_portal_paddr);
+			  uint64_t		*child_portal_offset);
 
 /**
  * dprc_destroy_container() - Destroy child container.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @child_container_id:	ID of the container to destroy
  *
@@ -168,12 +191,14 @@ int dprc_create_container(struct fsl_mc_io	*mc_io,
  *
  */
 int dprc_destroy_container(struct fsl_mc_io	*mc_io,
+			   uint32_t		cmd_flags,
 			   uint16_t		token,
 			   int			child_container_id);
 
 /**
  * dprc_reset_container - Reset child container.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @child_container_id:	ID of the container to reset
  *
@@ -192,25 +217,33 @@ int dprc_destroy_container(struct fsl_mc_io	*mc_io,
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dprc_reset_container(struct fsl_mc_io *mc_io,
-			 uint16_t token,
-			 int child_container_id);
+int dprc_reset_container(struct fsl_mc_io	*mc_io,
+			 uint32_t		cmd_flags,
+			 uint16_t		token,
+			 int			child_container_id);
 
 /* IRQ */
 
+/* IRQ index */
+#define DPRC_IRQ_INDEX          0
+
 /* Number of dprc's IRQs */
 #define DPRC_NUM_OF_IRQS		1
 
-/* Object irq events */
+/* DPRC IRQ events */
 
-/* IRQ event - Indicates that a new object assigned to the container */
+/* IRQ event - Indicates that a new object added to the container */
 #define DPRC_IRQ_EVENT_OBJ_ADDED		0x00000001
-/* IRQ event - Indicates that an object was unassigned from the container */
+
+/* IRQ event - Indicates that an object was removed from the container */
 #define DPRC_IRQ_EVENT_OBJ_REMOVED		0x00000002
-/* IRQ event - Indicates that resources assigned to the container */
+
+/* IRQ event - Indicates that resources added to the container */
 #define DPRC_IRQ_EVENT_RES_ADDED		0x00000004
-/* IRQ event - Indicates that resources unassigned from the container */
+
+/* IRQ event - Indicates that resources removed from the container */
 #define DPRC_IRQ_EVENT_RES_REMOVED		0x00000008
+
 /* IRQ event - Indicates that one of the descendant containers that opened by
  * this container is destroyed
  */
@@ -225,49 +258,56 @@ int dprc_reset_container(struct fsl_mc_io *mc_io,
 #define DPRC_IRQ_EVENT_OBJ_CREATED		0x00000040
 
 /**
+ * struct dprc_irq_cfg - IRQ configuration
+ * @paddr:	Address that must be written to signal a message-based interrupt
+ * @val:	Value to write into irq_addr address
+ * @irq_num:	A user defined number associated with this IRQ
+ */
+struct dprc_irq_cfg {
+	     uint64_t		paddr;
+	     uint32_t		val;
+	     int		irq_num;
+};
+
+/**
  * dprc_set_irq() - Set IRQ information for the DPRC to trigger an interrupt.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @irq_index:	Identifies the interrupt index to configure
- * @irq_addr:	Address that must be written to
- *			signal a message-based interrupt
- * @irq_val:	Value to write into irq_addr address
- * @user_irq_id: Returned a user defined number associated with this IRQ
+ * @irq_cfg:	IRQ configuration
  *
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_set_irq(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
 		 uint16_t		token,
 		 uint8_t		irq_index,
-		 uint64_t		irq_addr,
-		 uint32_t		irq_val,
-		 int			user_irq_id);
+		 struct dprc_irq_cfg	*irq_cfg);
 
 /**
  * dprc_get_irq() - Get IRQ information from the DPRC.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @irq_index:	The interrupt index to configure
- * @type:	Returned interrupt type: 0 represents message interrupt
- *			type (both irq_addr and irq_val are valid)
- * @irq_addr:	Returned address that must be written to
- *			signal the message-based interrupt
- * @irq_val:	Value to write into irq_addr address
- * @user_irq_id: A user defined number associated with this IRQ
+ * @type:	Interrupt type: 0 represents message interrupt
+ *		type (both irq_addr and irq_val are valid)
+ * @irq_cfg:	IRQ attributes
  *
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_get_irq(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
 		 uint16_t		token,
 		 uint8_t		irq_index,
 		 int			*type,
-		 uint64_t		*irq_addr,
-		 uint32_t		*irq_val,
-		 int			*user_irq_id);
+		 struct dprc_irq_cfg	*irq_cfg);
 
 /**
  * dprc_set_irq_enable() - Set overall interrupt state.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @irq_index:	The interrupt index to configure
  * @en:		Interrupt state - enable = 1, disable = 0
@@ -280,6 +320,7 @@ int dprc_get_irq(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_set_irq_enable(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
 			uint16_t		token,
 			uint8_t			irq_index,
 			uint8_t			en);
@@ -287,6 +328,7 @@ int dprc_set_irq_enable(struct fsl_mc_io	*mc_io,
 /**
  * dprc_get_irq_enable() - Get overall interrupt state.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @irq_index:  The interrupt index to configure
  * @en:		Returned interrupt state - enable = 1, disable = 0
@@ -294,6 +336,7 @@ int dprc_set_irq_enable(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_get_irq_enable(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
 			uint16_t		token,
 			uint8_t			irq_index,
 			uint8_t			*en);
@@ -301,6 +344,7 @@ int dprc_get_irq_enable(struct fsl_mc_io	*mc_io,
 /**
  * dprc_set_irq_mask() - Set interrupt mask.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @irq_index:	The interrupt index to configure
  * @mask:	event mask to trigger interrupt;
@@ -314,6 +358,7 @@ int dprc_get_irq_enable(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_set_irq_mask(struct fsl_mc_io	*mc_io,
+		      uint32_t		cmd_flags,
 		      uint16_t		token,
 		      uint8_t		irq_index,
 		      uint32_t		mask);
@@ -321,6 +366,7 @@ int dprc_set_irq_mask(struct fsl_mc_io	*mc_io,
 /**
  * dprc_get_irq_mask() - Get interrupt mask.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @irq_index:	The interrupt index to configure
  * @mask:	Returned event mask to trigger interrupt
@@ -331,6 +377,7 @@ int dprc_set_irq_mask(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_get_irq_mask(struct fsl_mc_io	*mc_io,
+		      uint32_t		cmd_flags,
 		      uint16_t		token,
 		      uint8_t		irq_index,
 		      uint32_t		*mask);
@@ -338,6 +385,7 @@ int dprc_get_irq_mask(struct fsl_mc_io	*mc_io,
 /**
  * dprc_get_irq_status() - Get the current status of any pending interrupts.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @irq_index:	The interrupt index to configure
  * @status:	Returned interrupts status - one bit per cause:
@@ -347,6 +395,7 @@ int dprc_get_irq_mask(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_get_irq_status(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
 			uint16_t		token,
 			uint8_t			irq_index,
 			uint32_t		*status);
@@ -354,6 +403,7 @@ int dprc_get_irq_status(struct fsl_mc_io	*mc_io,
 /**
  * dprc_clear_irq_status() - Clear a pending interrupt's status
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @irq_index:	The interrupt index to configure
  * @status:	bits to clear (W1C) - one bit per cause:
@@ -363,6 +413,7 @@ int dprc_get_irq_status(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_clear_irq_status(struct fsl_mc_io	*mc_io,
+			  uint32_t		cmd_flags,
 			  uint16_t		token,
 			  uint8_t		irq_index,
 			  uint32_t		status);
@@ -373,33 +424,25 @@ int dprc_clear_irq_status(struct fsl_mc_io	*mc_io,
  * @icid: Container's ICID
  * @portal_id: Container's portal ID
  * @options: Container's options as set at container's creation
- * @version: DPRC version
  */
 struct dprc_attributes {
 	int container_id;
 	uint16_t icid;
 	int portal_id;
 	uint64_t options;
-	/**
-	 * struct version - DPRC version
-	 * @major: DPRC major version
-	 * @minor: DPRC minor version
-	 */
-	struct {
-		uint16_t major;
-		uint16_t minor;
-	} version;
 };
 
 /**
  * dprc_get_attributes() - Obtains container attributes
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
- * @attributes	Returned container attributes
+ * @attributes:	Returned container attributes
  *
  * Return:     '0' on Success; Error code otherwise.
  */
 int dprc_get_attributes(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
 			uint16_t		token,
 			struct dprc_attributes	*attributes);
 
@@ -407,6 +450,7 @@ int dprc_get_attributes(struct fsl_mc_io	*mc_io,
  * dprc_set_res_quota() - Set allocation policy for a specific resource/object
  *		type in a child container
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @child_container_id:	ID of the child container
  * @type:	Resource/object type
@@ -428,6 +472,7 @@ int dprc_get_attributes(struct fsl_mc_io	*mc_io,
  * @warning	Only the parent container is allowed to change a child policy.
  */
 int dprc_set_res_quota(struct fsl_mc_io	*mc_io,
+		       uint32_t		cmd_flags,
 		       uint16_t		token,
 		       int		child_container_id,
 		       char		*type,
@@ -437,8 +482,9 @@ int dprc_set_res_quota(struct fsl_mc_io	*mc_io,
  * dprc_get_res_quota() - Gets the allocation policy of a specific
  *		resource/object type in a child container
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
- * @child_container_id;	ID of the child container
+ * @child_container_id:	ID of the child container
  * @type:	resource/object type
  * @quota:	Returnes the maximum number of resources of the selected type
  *		that the child container is allowed to allocate from the parent;
@@ -448,6 +494,7 @@ int dprc_set_res_quota(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_get_res_quota(struct fsl_mc_io	*mc_io,
+		       uint32_t		cmd_flags,
 		       uint16_t		token,
 		       int		child_container_id,
 		       char		*type,
@@ -500,6 +547,7 @@ struct dprc_res_req {
 /**
  * dprc_assign() - Assigns objects or resource to a child container.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @container_id: ID of the child container
  * @res_req:	Describes the type and amount of resources to
@@ -529,6 +577,7 @@ struct dprc_res_req {
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_assign(struct fsl_mc_io	*mc_io,
+		uint32_t		cmd_flags,
 		uint16_t		token,
 		int			container_id,
 		struct dprc_res_req	*res_req);
@@ -537,6 +586,7 @@ int dprc_assign(struct fsl_mc_io	*mc_io,
  * dprc_unassign() - Un-assigns objects or resources from a child container
  *		and moves them into this (parent) DPRC.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @child_container_id:	ID of the child container
  * @res_req:	Describes the type and amount of resources to un-assign from
@@ -548,12 +598,14 @@ int dprc_assign(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_unassign(struct fsl_mc_io	*mc_io,
+		  uint32_t		cmd_flags,
 		  uint16_t		token,
 		  int			child_container_id,
 		  struct dprc_res_req	*res_req);
 
 /**
  * dprc_get_pool_count() - Get the number of dprc's pools
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @mc_io:	Pointer to MC portal's I/O object
  * @token:	Token of DPRC object
  * @pool_count:	Returned number of resource pools in the dprc
@@ -561,14 +613,16 @@ int dprc_unassign(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_get_pool_count(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
 			uint16_t		token,
 			int			*pool_count);
 
 /**
  * dprc_get_pool() - Get the type (string) of a certain dprc's pool
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
- * @pool_index;	Index of the pool to be queried (< pool_count)
+ * @pool_index:	Index of the pool to be queried (< pool_count)
  * @type:	The type of the pool
  *
  * The pool types retrieved one by one by incrementing
@@ -579,6 +633,7 @@ int dprc_get_pool_count(struct fsl_mc_io	*mc_io,
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_get_pool(struct fsl_mc_io	*mc_io,
+		  uint32_t		cmd_flags,
 		  uint16_t		token,
 		  int			pool_index,
 		  char			*type);
@@ -586,12 +641,16 @@ int dprc_get_pool(struct fsl_mc_io	*mc_io,
 /**
  * dprc_get_obj_count() - Obtains the number of objects in the DPRC
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @obj_count:	Number of objects assigned to the DPRC
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dprc_get_obj_count(struct fsl_mc_io *mc_io, uint16_t token, int *obj_count);
+int dprc_get_obj_count(struct fsl_mc_io	*mc_io,
+		       uint32_t		cmd_flags,
+		       uint16_t		token,
+		       int		*obj_count);
 
 /* Objects Attributes Flags */
 
@@ -601,6 +660,14 @@ int dprc_get_obj_count(struct fsl_mc_io *mc_io, uint16_t token, int *obj_count);
 #define DPRC_OBJ_STATE_PLUGGED		0x00000002
 
 /**
+ * Shareability flag - Object flag indicating no memory shareability.
+ * the object generates memory accesses that are non coherent with other
+ * masters;
+ * user is responsible for proper memory handling through IOMMU configuration.
+ */
+#define DPRC_OBJ_FLAG_NO_MEM_SHAREABILITY		0x0001
+
+/**
  * struct dprc_obj_desc - Object descriptor, returned from dprc_get_obj()
  * @type: Type of object: NULL terminated string
  * @id: ID of logical object resource
@@ -610,6 +677,8 @@ int dprc_get_obj_count(struct fsl_mc_io *mc_io, uint16_t token, int *obj_count);
  * @irq_count: Number of interrupts supported by the object
  * @region_count: Number of mappable regions supported by the object
  * @state: Object state: combination of DPRC_OBJ_STATE_ states
+ * @label: Object label
+ * @flags: Object's flags
  */
 struct dprc_obj_desc {
 	char type[16];
@@ -620,11 +689,14 @@ struct dprc_obj_desc {
 	uint8_t irq_count;
 	uint8_t region_count;
 	uint32_t state;
+	char label[16];
+	uint16_t flags;
 };
 
 /**
  * dprc_get_obj() - Get general information on an object
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @obj_index:	Index of the object to be queried (< obj_count)
  * @obj_desc:	Returns the requested object descriptor
@@ -637,14 +709,79 @@ struct dprc_obj_desc {
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_get_obj(struct fsl_mc_io	*mc_io,
+		 uint32_t		cmd_flags,
 		 uint16_t		token,
 		 int			obj_index,
 		 struct dprc_obj_desc	*obj_desc);
 
 /**
+ * dprc_get_obj_desc() - Get object descriptor.
+ *
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPRC object
+ * @obj_type:	The type of the object to get its descriptor.
+ * @obj_id:	The id of the object to get its descriptor
+ * @obj_desc:	The returned descriptor to fill and return to the user
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ *
+ */
+int dprc_get_obj_desc(struct fsl_mc_io		*mc_io,
+		      uint32_t		cmd_flags,
+			uint16_t		token,
+			char			*obj_type,
+			int			obj_id,
+			struct dprc_obj_desc	*obj_desc);
+
+/**
+ * dprc_set_obj_irq() - Set IRQ information for object to trigger an interrupt.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPRC object
+ * @obj_type:	Type of the object to set its IRQ
+ * @obj_id:	ID of the object to set its IRQ
+ * @irq_index:	The interrupt index to configure
+ * @irq_cfg:	IRQ configuration
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dprc_set_obj_irq(struct fsl_mc_io		*mc_io,
+		     uint32_t			cmd_flags,
+		     uint16_t			token,
+		     char			*obj_type,
+		     int			obj_id,
+		     uint8_t			irq_index,
+		     struct dprc_irq_cfg	*irq_cfg);
+
+/**
+ * dprc_get_obj_irq() - Get IRQ information from object.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPRC object
+ * @obj_type:	Type od the object to get its IRQ
+ * @obj_id:	ID of the object to get its IRQ
+ * @irq_index:	The interrupt index to configure
+ * @type:	Interrupt type: 0 represents message interrupt
+ *		type (both irq_addr and irq_val are valid)
+ * @irq_cfg:	The returned IRQ attributes
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dprc_get_obj_irq(struct fsl_mc_io		*mc_io,
+		     uint32_t			cmd_flags,
+		     uint16_t			token,
+		     char			*obj_type,
+		     int			obj_id,
+		     uint8_t			irq_index,
+		     int			*type,
+		     struct dprc_irq_cfg	*irq_cfg);
+
+/**
  * dprc_get_res_count() - Obtains the number of free resources that are assigned
  *		to this container, by pool type
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @type:	pool type
  * @res_count:	Returned number of free resources of the given
@@ -652,7 +789,8 @@ int dprc_get_obj(struct fsl_mc_io	*mc_io,
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dprc_get_res_count(struct fsl_mc_io	*mc_io,
+int dprc_get_res_count(struct		fsl_mc_io *mc_io,
+		       uint32_t		cmd_flags,
 		       uint16_t		token,
 		       char		*type,
 		       int		*res_count);
@@ -687,6 +825,7 @@ struct dprc_res_ids_range_desc {
 /**
  * dprc_get_res_ids() - Obtains IDs of free resources in the container
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @type:	pool type
  * @range_desc:	range descriptor
@@ -694,39 +833,48 @@ struct dprc_res_ids_range_desc {
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_get_res_ids(struct fsl_mc_io			*mc_io,
+		     uint32_t				cmd_flags,
 		     uint16_t				token,
 		     char				*type,
 		     struct dprc_res_ids_range_desc	*range_desc);
 
+/* Region flags */
+/* Cacheable - Indicates that region should be mapped as cacheable */
+#define DPRC_REGION_CACHEABLE	0x00000001
+
 /**
- * dprc_get_portal_paddr() - Get the physical address of MC portals
- * @mc_io:	Pointer to MC portal's I/O object
- * @token:	Token of DPRC object
- * @portal_id:	MC portal ID
- * @portal_addr: The physical address of the MC portal ID
- *
- * Return:	'0' on Success; Error code otherwise.
+ * enum dprc_region_type - Region type
+ * @DPRC_REGION_TYPE_MC_PORTAL: MC portal region
+ * @DPRC_REGION_TYPE_QBMAN_PORTAL: Qbman portal region
  */
-int dprc_get_portal_paddr(struct fsl_mc_io	*mc_io,
-			  uint16_t		token,
-			  int			portal_id,
-			  uint64_t		*portal_addr);
+enum dprc_region_type {
+	DPRC_REGION_TYPE_MC_PORTAL,
+	DPRC_REGION_TYPE_QBMAN_PORTAL
+};
 
 /**
  * struct dprc_region_desc - Mappable region descriptor
- * @base_paddr: Region base physical address
+ * @base_offset: Region offset from region's base address.
+ *	For DPMCP and DPRC objects, region base is offset from SoC MC portals
+ *	base address; For DPIO, region base is offset from SoC QMan portals
+ *	base address
  * @size: Region size (in bytes)
+ * @flags: Region attributes
+ * @type: Portal region type
  */
 struct dprc_region_desc {
-	uint64_t base_paddr;
-	uint32_t size;
+	uint32_t		base_offset;
+	uint32_t		size;
+	uint32_t		flags;
+	enum dprc_region_type	type;
 };
 
 /**
  * dprc_get_obj_region() - Get region information for a specified object.
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
- * @obj_type;	Object type as returned in dprc_get_obj()
+ * @obj_type:	Object type as returned in dprc_get_obj()
  * @obj_id:	Unique object instance as returned in dprc_get_obj()
  * @region_index: The specific region to query
  * @region_desc:  Returns the requested region descriptor
@@ -734,6 +882,7 @@ struct dprc_region_desc {
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_get_obj_region(struct fsl_mc_io	*mc_io,
+			uint32_t		cmd_flags,
 			uint16_t		token,
 			char			*obj_type,
 			int			obj_id,
@@ -741,61 +890,116 @@ int dprc_get_obj_region(struct fsl_mc_io	*mc_io,
 			struct dprc_region_desc	*region_desc);
 
 /**
+ * dprc_set_obj_label() - Set object label.
+ * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @token:	Token of DPRC object
+ * @obj_type:	Object's type
+ * @obj_id:	Object's ID
+ * @label:	The required label. The maximum length is 16 chars.
+ *
+ * Return:	'0' on Success; Error code otherwise.
+ */
+int dprc_set_obj_label(struct fsl_mc_io	*mc_io,
+		       uint32_t		cmd_flags,
+		       uint16_t		token,
+		       char		*obj_type,
+		       int		obj_id,
+		       char		*label);
+
+/**
  * struct dprc_endpoint - Endpoint description for link connect/disconnect
  *			operations
  * @type: Endpoint object type: NULL terminated string
  * @id: Endpoint object ID
- * @interface_id: Interface ID; should be set for endpoints with multiple
+ * @if_id: Interface ID; should be set for endpoints with multiple
  *		interfaces ("dpsw", "dpdmux"); for others, always set to 0
  */
 struct dprc_endpoint {
 	char type[16];
 	int id;
-	int interface_id;
+	int if_id;
+};
+
+/**
+ * struct dprc_connection_cfg - Connection configuration.
+ *				Used for virtual connections only
+ * @committed_rate: Committed rate (Mbits/s)
+ * @max_rate: Maximum rate (Mbits/s)
+ */
+struct dprc_connection_cfg {
+	uint32_t committed_rate;
+	uint32_t max_rate;
 };
 
 /**
  * dprc_connect() - Connect two endpoints to create a network link between them
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @endpoint1:	Endpoint 1 configuration parameters
  * @endpoint2:	Endpoint 2 configuration parameters
+ * @cfg: Connection configuration. The connection configuration is ignored for
+ * 	 connections made to DPMAC objects, where rate is retrieved from the
+ *	 MAC configuration.
  *
  * Return:	'0' on Success; Error code otherwise.
  */
-int dprc_connect(struct fsl_mc_io		*mc_io,
-		 uint16_t			token,
-		 const struct dprc_endpoint	*endpoint1,
-		 const struct dprc_endpoint	*endpoint2);
+int dprc_connect(struct fsl_mc_io			*mc_io,
+		 uint32_t				cmd_flags,
+		 uint16_t				token,
+		 const struct dprc_endpoint		*endpoint1,
+		 const struct dprc_endpoint		*endpoint2,
+		 const struct dprc_connection_cfg	*cfg);
 
 /**
  * dprc_disconnect() - Disconnect one endpoint to remove its network connection
  * @mc_io:	Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
  * @token:	Token of DPRC object
  * @endpoint:	Endpoint configuration parameters
  *
  * Return:	'0' on Success; Error code otherwise.
  */
 int dprc_disconnect(struct fsl_mc_io		*mc_io,
+		    uint32_t			cmd_flags,
 		    uint16_t			token,
 		    const struct dprc_endpoint	*endpoint);
 
 /**
 * dprc_get_connection() - Get connected endpoint and link status if connection
 *			exists.
-* @mc_io		Pointer to MC portal's I/O object
-* @token		Token of DPRC object
-* @endpoint1	Endpoint 1 configuration parameters
-* @endpoint2	Returned endpoint 2 configuration parameters
-* @state:	Returned link state: 1 - link is up, 0 - link is down
+* @mc_io:	Pointer to MC portal's I/O object
+* @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+* @token:	Token of DPRC object
+* @endpoint1:	Endpoint 1 configuration parameters
+* @endpoint2:	Returned endpoint 2 configuration parameters
+* @state:	Returned link state:
+*		1 - link is up;
+*		0 - link is down;
+*		-1 - no connection (endpoint2 information is irrelevant)
 *
 * Return:     '0' on Success; -ENAVAIL if connection does not exist.
 */
 int dprc_get_connection(struct fsl_mc_io		*mc_io,
+			uint32_t			cmd_flags,
 			uint16_t			token,
 			const struct dprc_endpoint	*endpoint1,
 			struct dprc_endpoint		*endpoint2,
 			int				*state);
 
+/**
+ * dprc_get_api_version() - Get Data Path Resource Container API version
+ * @mc_io:  Pointer to MC portal's I/O object
+ * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'
+ * @major_ver: 	Major version of data path resource container API
+ * @minor_ver: 	Minor version of data path resource container API
+ *
+ * Return:  '0' on Success; Error code otherwise.
+ */
+int dprc_get_api_version(struct fsl_mc_io *mc_io,
+			   uint32_t cmd_flags,
+			   uint16_t *major_ver,
+			   uint16_t *minor_ver);
 #endif /* _FSL_DPRC_H */
 
diff --git a/drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h b/drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h
new file mode 100644
index 0000000..3e9af59
--- /dev/null
+++ b/drivers/staging/fsl-mc/include/fsl_dpaa2_fd.h
@@ -0,0 +1,774 @@
+/* Copyright 2014 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef __FSL_DPAA2_FD_H
+#define __FSL_DPAA2_FD_H
+
+/**
+ * DOC: DPAA2 FD - Frame Descriptor APIs for DPAA2
+ *
+ * Frame Descriptors (FDs) are used to describe frame data in the DPAA2.
+ * Frames can be enqueued and dequeued to Frame Queues which are consumed
+ * by the various DPAA accelerators (WRIOP, SEC, PME, DCE)
+ *
+ * There are three types of frames: Single, Scatter Gather and Frame Lists.
+ *
+ * The set of APIs in this file must be used to create, manipulate and
+ * query Frame Descriptor.
+ *
+ */
+
+/**
+ * struct dpaa2_fd - Place-holder for FDs.
+ * @words: for easier/faster copying the whole FD structure.
+ * @addr_lo: the lower 32 bits of the address in FD.
+ * @addr_hi: the upper 32 bits of the address in FD.
+ * @len: the length field in FD.
+ * @bpid_offset: represent the bpid and offset fields in FD
+ * @frc: frame context
+ * @ctrl: the 32bit control bits including dd, sc,... va, err.
+ * @flc_lo: the lower 32bit of flow context.
+ * @flc_hi: the upper 32bits of flow context.
+ *
+ * This structure represents the basic Frame Descriptor used in the system.
+ * We represent it via the simplest form that we need for now. Different
+ * overlays may be needed to support different options, etc. (It is impractical
+ * to define One True Struct, because the resulting encoding routines (lots of
+ * read-modify-writes) would be worst-case performance whether or not
+ * circumstances required them.)
+ */
+struct dpaa2_fd {
+	union {
+		u32 words[8];
+		struct dpaa2_fd_simple {
+			u32 addr_lo;
+			u32 addr_hi;
+			u32 len;
+			/* offset in the MS 16 bits, BPID in the LS 16 bits */
+			u32 bpid_offset;
+			u32 frc; /* frame context */
+			/* "err", "va", "cbmt", "asal", [...] */
+			u32 ctrl;
+			/* flow context */
+			u32 flc_lo;
+			u32 flc_hi;
+		} simple;
+	};
+};
+
+enum dpaa2_fd_format {
+	dpaa2_fd_single = 0,
+	dpaa2_fd_list,
+	dpaa2_fd_sg
+};
+
+/* Accessors for SG entry fields
+ *
+ * These setters and getters assume little endian format. For converting
+ * between LE and cpu endianness, the specific conversion functions must be
+ * called before the SGE contents are accessed by the core (on Rx),
+ * respectively before the SG table is sent to hardware (on Tx)
+ */
+
+/**
+ * dpaa2_fd_get_addr() - get the addr field of frame descriptor
+ * @fd: the given frame descriptor.
+ *
+ * Return the address in the frame descriptor.
+ */
+static inline dma_addr_t dpaa2_fd_get_addr(const struct dpaa2_fd *fd)
+{
+	return (dma_addr_t)((((uint64_t)fd->simple.addr_hi) << 32)
+				+ fd->simple.addr_lo);
+}
+
+/**
+ * dpaa2_fd_set_addr() - Set the addr field of frame descriptor
+ * @fd: the given frame descriptor.
+ * @addr: the address needs to be set in frame descriptor.
+ */
+static inline void dpaa2_fd_set_addr(struct dpaa2_fd *fd, dma_addr_t addr)
+{
+	fd->simple.addr_hi = upper_32_bits(addr);
+	fd->simple.addr_lo = lower_32_bits(addr);
+}
+
+/**
+ * dpaa2_fd_get_frc() - Get the frame context in the frame descriptor
+ * @fd: the given frame descriptor.
+ *
+ * Return the frame context field in the frame descriptor.
+ */
+static inline u32 dpaa2_fd_get_frc(const struct dpaa2_fd *fd)
+{
+	return fd->simple.frc;
+}
+
+/**
+ * dpaa2_fd_set_frc() - Set the frame context in the frame descriptor
+ * @fd: the given frame descriptor.
+ * @frc: the frame context needs to be set in frame descriptor.
+ */
+static inline void dpaa2_fd_set_frc(struct dpaa2_fd *fd, u32 frc)
+{
+	fd->simple.frc = frc;
+}
+
+/**
+ * dpaa2_fd_get_flc() - Get the flow context in the frame descriptor
+ * @fd: the given frame descriptor.
+ *
+ * Return the flow context in the frame descriptor.
+ */
+static inline dma_addr_t dpaa2_fd_get_flc(const struct dpaa2_fd *fd)
+{
+	return (dma_addr_t)((((uint64_t)fd->simple.flc_hi) << 32) +
+			    fd->simple.flc_lo);
+}
+
+/**
+ * dpaa2_fd_set_flc() - Set the flow context field of frame descriptor
+ * @fd: the given frame descriptor.
+ * @flc_addr: the flow context needs to be set in frame descriptor.
+ */
+static inline void dpaa2_fd_set_flc(struct dpaa2_fd *fd,  dma_addr_t flc_addr)
+{
+	fd->simple.flc_hi = upper_32_bits(flc_addr);
+	fd->simple.flc_lo = lower_32_bits(flc_addr);
+}
+
+/**
+ * dpaa2_fd_get_len() - Get the length in the frame descriptor
+ * @fd: the given frame descriptor.
+ *
+ * Return the length field in the frame descriptor.
+ */
+static inline u32 dpaa2_fd_get_len(const struct dpaa2_fd *fd)
+{
+	return fd->simple.len;
+}
+
+/**
+ * dpaa2_fd_set_len() - Set the length field of frame descriptor
+ * @fd: the given frame descriptor.
+ * @len: the length needs to be set in frame descriptor.
+ */
+static inline void dpaa2_fd_set_len(struct dpaa2_fd *fd, u32 len)
+{
+	fd->simple.len = len;
+}
+
+/**
+ * dpaa2_fd_get_offset() - Get the offset field in the frame descriptor
+ * @fd: the given frame descriptor.
+ *
+ * Return the offset.
+ */
+static inline uint16_t dpaa2_fd_get_offset(const struct dpaa2_fd *fd)
+{
+	return (uint16_t)(fd->simple.bpid_offset >> 16) & 0x0FFF;
+}
+
+/**
+ * dpaa2_fd_set_offset() - Set the offset field of frame descriptor
+ *
+ * @fd: the given frame descriptor.
+ * @offset: the offset needs to be set in frame descriptor.
+ */
+static inline void dpaa2_fd_set_offset(struct dpaa2_fd *fd, uint16_t offset)
+{
+	fd->simple.bpid_offset &= 0xF000FFFF;
+	fd->simple.bpid_offset |= (u32)offset << 16;
+}
+
+/**
+ * dpaa2_fd_get_format() - Get the format field in the frame descriptor
+ * @fd: the given frame descriptor.
+ *
+ * Return the format.
+ */
+static inline enum dpaa2_fd_format dpaa2_fd_get_format(
+						const struct dpaa2_fd *fd)
+{
+	return (enum dpaa2_fd_format)((fd->simple.bpid_offset >> 28) & 0x3);
+}
+
+/**
+ * dpaa2_fd_set_format() - Set the format field of frame descriptor
+ *
+ * @fd: the given frame descriptor.
+ * @format: the format needs to be set in frame descriptor.
+ */
+static inline void dpaa2_fd_set_format(struct dpaa2_fd *fd,
+				       enum dpaa2_fd_format format)
+{
+	fd->simple.bpid_offset &= 0xCFFFFFFF;
+	fd->simple.bpid_offset |= (u32)format << 28;
+}
+
+/**
+ * dpaa2_fd_get_bpid() - Get the bpid field in the frame descriptor
+ * @fd: the given frame descriptor.
+ *
+ * Return the bpid.
+ */
+static inline uint16_t dpaa2_fd_get_bpid(const struct dpaa2_fd *fd)
+{
+	return (uint16_t)(fd->simple.bpid_offset & 0xFFFF);
+}
+
+/**
+ * dpaa2_fd_set_bpid() - Set the bpid field of frame descriptor
+ *
+ * @fd: the given frame descriptor.
+ * @bpid: the bpid needs to be set in frame descriptor.
+ */
+static inline void dpaa2_fd_set_bpid(struct dpaa2_fd *fd, uint16_t bpid)
+{
+	fd->simple.bpid_offset &= 0xFFFF0000;
+	fd->simple.bpid_offset |= (u32)bpid;
+}
+
+/**
+ * struct dpaa2_sg_entry - the scatter-gathering structure
+ * @addr_lo: the lower 32bit of address
+ * @addr_hi: the upper 32bit of address
+ * @len: the length in this sg entry.
+ * @bpid_offset: offset in the MS 16 bits, BPID in the LS 16 bits.
+ */
+struct dpaa2_sg_entry {
+	u32 addr_lo;
+	u32 addr_hi;
+	u32 len;
+	u32 bpid_offset;
+};
+
+enum dpaa2_sg_format {
+	dpaa2_sg_single = 0,
+	dpaa2_sg_frame_data,
+	dpaa2_sg_sgt_ext
+};
+
+/**
+ * dpaa2_sg_get_addr() - Get the address from SG entry
+ * @sg: the given scatter-gathering object.
+ *
+ * Return the address.
+ */
+static inline dma_addr_t dpaa2_sg_get_addr(const struct dpaa2_sg_entry *sg)
+{
+	return (dma_addr_t)((((u64)sg->addr_hi) << 32) + sg->addr_lo);
+}
+
+/**
+ * dpaa2_sg_set_addr() - Set the address in SG entry
+ * @sg: the given scatter-gathering object.
+ * @addr: the address to be set.
+ */
+static inline void dpaa2_sg_set_addr(struct dpaa2_sg_entry *sg, dma_addr_t addr)
+{
+	sg->addr_hi = upper_32_bits(addr);
+	sg->addr_lo = lower_32_bits(addr);
+}
+
+
+static inline bool dpaa2_sg_short_len(const struct dpaa2_sg_entry *sg)
+{
+	return (sg->bpid_offset >> 30) & 0x1;
+}
+
+/**
+ * dpaa2_sg_get_len() - Get the length in SG entry
+ * @sg: the given scatter-gathering object.
+ *
+ * Return the length.
+ */
+static inline u32 dpaa2_sg_get_len(const struct dpaa2_sg_entry *sg)
+{
+	if (dpaa2_sg_short_len(sg))
+		return sg->len & 0x1FFFF;
+	return sg->len;
+}
+
+/**
+ * dpaa2_sg_set_len() - Set the length in SG entry
+ * @sg: the given scatter-gathering object.
+ * @len: the length to be set.
+ */
+static inline void dpaa2_sg_set_len(struct dpaa2_sg_entry *sg, u32 len)
+{
+	sg->len = len;
+}
+
+/**
+ * dpaa2_sg_get_offset() - Get the offset in SG entry
+ * @sg: the given scatter-gathering object.
+ *
+ * Return the offset.
+ */
+static inline u16 dpaa2_sg_get_offset(const struct dpaa2_sg_entry *sg)
+{
+	return (u16)(sg->bpid_offset >> 16) & 0x0FFF;
+}
+
+/**
+ * dpaa2_sg_set_offset() - Set the offset in SG entry
+ * @sg: the given scatter-gathering object.
+ * @offset: the offset to be set.
+ */
+static inline void dpaa2_sg_set_offset(struct dpaa2_sg_entry *sg,
+				       u16 offset)
+{
+	sg->bpid_offset &= 0xF000FFFF;
+	sg->bpid_offset |= (u32)offset << 16;
+}
+
+/**
+ * dpaa2_sg_get_format() - Get the SG format in SG entry
+ * @sg: the given scatter-gathering object.
+ *
+ * Return the format.
+ */
+static inline enum dpaa2_sg_format
+	dpaa2_sg_get_format(const struct dpaa2_sg_entry *sg)
+{
+	return (enum dpaa2_sg_format)((sg->bpid_offset >> 28) & 0x3);
+}
+
+/**
+ * dpaa2_sg_set_format() - Set the SG format in SG entry
+ * @sg: the given scatter-gathering object.
+ * @format: the format to be set.
+ */
+static inline void dpaa2_sg_set_format(struct dpaa2_sg_entry *sg,
+				       enum dpaa2_sg_format format)
+{
+	sg->bpid_offset &= 0xCFFFFFFF;
+	sg->bpid_offset |= (u32)format << 28;
+}
+
+/**
+ * dpaa2_sg_get_bpid() - Get the buffer pool id in SG entry
+ * @sg: the given scatter-gathering object.
+ *
+ * Return the bpid.
+ */
+static inline u16 dpaa2_sg_get_bpid(const struct dpaa2_sg_entry *sg)
+{
+	return (u16)(sg->bpid_offset & 0x3FFF);
+}
+
+/**
+ * dpaa2_sg_set_bpid() - Set the buffer pool id in SG entry
+ * @sg: the given scatter-gathering object.
+ * @bpid: the bpid to be set.
+ */
+static inline void dpaa2_sg_set_bpid(struct dpaa2_sg_entry *sg, u16 bpid)
+{
+	sg->bpid_offset &= 0xFFFFC000;
+	sg->bpid_offset |= (u32)bpid;
+}
+
+/**
+ * dpaa2_sg_is_final() - Check final bit in SG entry
+ * @sg: the given scatter-gathering object.
+ *
+ * Return bool.
+ */
+static inline bool dpaa2_sg_is_final(const struct dpaa2_sg_entry *sg)
+{
+	return !!(sg->bpid_offset >> 31);
+}
+
+/**
+ * dpaa2_sg_set_final() - Set the final bit in SG entry
+ * @sg: the given scatter-gathering object.
+ * @final: the final boolean to be set.
+ */
+static inline void dpaa2_sg_set_final(struct dpaa2_sg_entry *sg, bool final)
+{
+	sg->bpid_offset &= 0x7FFFFFFF;
+	sg->bpid_offset |= (u32)final << 31;
+}
+
+/* Endianness conversion helper functions
+ * The accelerator drivers which construct / read scatter gather entries
+ * need to call these in order to account for endianness mismatches between
+ * hardware and cpu
+ */
+#ifdef __BIG_ENDIAN
+/**
+ * dpaa2_sg_cpu_to_le() - convert scatter gather entry from native cpu
+ * format little endian format.
+ * @sg: the given scatter gather entry.
+ */
+static inline void dpaa2_sg_cpu_to_le(struct dpaa2_sg_entry *sg)
+{
+	uint32_t *p = (uint32_t *)sg;
+	int i;
+
+	for (i = 0; i < sizeof(*sg) / sizeof(u32); i++)
+		cpu_to_le32s(p++);
+}
+
+/**
+ * dpaa2_sg_le_to_cpu() - convert scatter gather entry from little endian
+ * format to native cpu format.
+ * @sg: the given scatter gather entry.
+ */
+static inline void dpaa2_sg_le_to_cpu(struct dpaa2_sg_entry *sg)
+{
+	uint32_t *p = (uint32_t *)sg;
+	int i;
+
+	for (i = 0; i < sizeof(*sg) / sizeof(u32); i++)
+		le32_to_cpus(p++);
+}
+#else
+#define dpaa2_sg_cpu_to_le(sg)
+#define dpaa2_sg_le_to_cpu(sg)
+#endif /* __BIG_ENDIAN */
+
+
+/**
+ * struct dpaa2_fl_entry - structure for frame list entry.
+ * @addr_lo: the lower 32bit of address
+ * @addr_hi: the upper 32bit of address
+ * @len: the length in this sg entry.
+ * @bpid_offset: offset in the MS 16 bits, BPID in the LS 16 bits.
+ * @frc: frame context
+ * @ctrl: the 32bit control bits including dd, sc,... va, err.
+ * @flc_lo: the lower 32bit of flow context.
+ * @flc_hi: the upper 32bits of flow context.
+ *
+ * Frame List Entry (FLE)
+ * Identical to dpaa2_fd.simple layout, but some bits are different
+ */
+struct dpaa2_fl_entry {
+	u32 addr_lo;
+	u32 addr_hi;
+	u32 len;
+	u32 bpid_offset;
+	u32 frc;
+	u32 ctrl;
+	u32 flc_lo;
+	u32 flc_hi;
+};
+
+enum dpaa2_fl_format {
+	dpaa2_fl_single = 0,
+	dpaa2_fl_res,
+	dpaa2_fl_sg
+};
+
+/**
+ * dpaa2_fl_get_addr() - Get address in the frame list entry
+ * @fle: the given frame list entry.
+ *
+ * Return address for the get function.
+ */
+static inline dma_addr_t dpaa2_fl_get_addr(const struct dpaa2_fl_entry *fle)
+{
+	return (dma_addr_t)((((uint64_t)fle->addr_hi) << 32) + fle->addr_lo);
+}
+
+/**
+ * dpaa2_fl_set_addr() - Set the address in the frame list entry
+ * @fle: the given frame list entry.
+ * @addr: the address needs to be set.
+ *
+ */
+static inline void dpaa2_fl_set_addr(struct dpaa2_fl_entry *fle,
+				     dma_addr_t addr)
+{
+	fle->addr_hi = upper_32_bits(addr);
+	fle->addr_lo = lower_32_bits(addr);
+}
+
+/**
+ * dpaa2_fl_get_flc() - Get the flow context in the frame list entry
+ * @fle: the given frame list entry.
+ *
+ * Return flow context for the get function.
+ */
+static inline dma_addr_t dpaa2_fl_get_flc(const struct dpaa2_fl_entry *fle)
+{
+	return (dma_addr_t)((((uint64_t)fle->flc_hi) << 32) + fle->flc_lo);
+}
+
+/**
+ * dpaa2_fl_set_flc() - Set the flow context in the frame list entry
+ * @fle: the given frame list entry.
+ * @flc_addr: the flow context address needs to be set.
+ *
+ */
+static inline void dpaa2_fl_set_flc(struct dpaa2_fl_entry *fle,
+				    dma_addr_t flc_addr)
+{
+	fle->flc_hi = upper_32_bits(flc_addr);
+	fle->flc_lo = lower_32_bits(flc_addr);
+}
+
+/**
+ * dpaa2_fl_get_len() - Get the length in the frame list entry
+ * @fle: the given frame list entry.
+ *
+ * Return length for the get function.
+ */
+static inline u32 dpaa2_fl_get_len(const struct dpaa2_fl_entry *fle)
+{
+	return fle->len;
+}
+
+/**
+ * dpaa2_fl_set_len() - Set the length in the frame list entry
+ * @fle: the given frame list entry.
+ * @len: the length needs to be set.
+ *
+ */
+static inline void dpaa2_fl_set_len(struct dpaa2_fl_entry *fle, u32 len)
+{
+	fle->len = len;
+}
+
+/**
+ * dpaa2_fl_get_offset() - Get/Set the offset in the frame list entry
+ * @fle: the given frame list entry.
+ *
+ * Return offset for the get function.
+ */
+static inline uint16_t dpaa2_fl_get_offset(const struct dpaa2_fl_entry *fle)
+{
+	return (uint16_t)(fle->bpid_offset >> 16) & 0x0FFF;
+}
+
+/**
+ * dpaa2_fl_set_offset() - Set the offset in the frame list entry
+ * @fle: the given frame list entry.
+ * @offset: the offset needs to be set.
+ *
+ */
+static inline void dpaa2_fl_set_offset(struct dpaa2_fl_entry *fle,
+				       uint16_t offset)
+{
+	fle->bpid_offset &= 0xF000FFFF;
+	fle->bpid_offset |= (u32)(offset & 0x0FFF) << 16;
+}
+
+/**
+ * dpaa2_fl_get_format() - Get the format in the frame list entry
+ * @fle: the given frame list entry.
+ *
+ * Return frame list format for the get function.
+ */
+static inline enum dpaa2_fl_format dpaa2_fl_get_format(
+	const struct dpaa2_fl_entry *fle)
+{
+	return (enum dpaa2_fl_format)((fle->bpid_offset >> 28) & 0x3);
+}
+
+/**
+ * dpaa2_fl_set_format() - Set the format in the frame list entry
+ * @fle: the given frame list entry.
+ * @format: the frame list format needs to be set.
+ *
+ */
+static inline void dpaa2_fl_set_format(struct dpaa2_fl_entry *fle,
+				       enum dpaa2_fl_format format)
+{
+	fle->bpid_offset &= 0xCFFFFFFF;
+	fle->bpid_offset |= (u32)(format & 0x3) << 28;
+}
+
+/**
+ * dpaa2_fl_get_bpid() - Get the buffer pool id in the frame list entry
+ * @fle: the given frame list entry.
+ *
+ * Return bpid for the get function.
+ */
+static inline uint16_t dpaa2_fl_get_bpid(const struct dpaa2_fl_entry *fle)
+{
+	return (uint16_t)(fle->bpid_offset & 0x3FFF);
+}
+
+/**
+ * dpaa2_fl_set_bpid() - Set the buffer pool id in the frame list entry
+ * @fle: the given frame list entry.
+ * @bpid: the buffer pool id needs to be set.
+ *
+ */
+static inline void dpaa2_fl_set_bpid(struct dpaa2_fl_entry *fle, uint16_t bpid)
+{
+	fle->bpid_offset &= 0xFFFFC000;
+	fle->bpid_offset |= (u32)bpid;
+}
+
+/** dpaa2_fl_is_final() - check the final bit is set or not in the frame list.
+ * @fle: the given frame list entry.
+ *
+ * Return final bit settting.
+ */
+static inline bool dpaa2_fl_is_final(const struct dpaa2_fl_entry *fle)
+{
+	return !!(fle->bpid_offset >> 31);
+}
+
+/**
+ * dpaa2_fl_set_final() - Set the final bit in the frame list entry
+ * @fle: the given frame list entry.
+ * @final: the final bit needs to be set.
+ *
+ */
+static inline void dpaa2_fl_set_final(struct dpaa2_fl_entry *fle, bool final)
+{
+	fle->bpid_offset &= 0x7FFFFFFF;
+	fle->bpid_offset |= (u32)final << 31;
+}
+
+/**
+ * struct dpaa2_dq - the qman result structure
+ * @dont_manipulate_directly: the 16 32bit data to represent the whole
+ * possible qman dequeue result.
+ *
+ * When frames are dequeued, the FDs show up inside "dequeue" result structures
+ * (if at all, not all dequeue results contain valid FDs). This structure type
+ * is intentionally defined without internal detail, and the only reason it
+ * isn't declared opaquely (without size) is to allow the user to provide
+ * suitably-sized (and aligned) memory for these entries.
+ */
+struct dpaa2_dq {
+	uint32_t dont_manipulate_directly[16];
+};
+
+/* Parsing frame dequeue results */
+/* FQ empty */
+#define DPAA2_DQ_STAT_FQEMPTY       0x80
+/* FQ held active */
+#define DPAA2_DQ_STAT_HELDACTIVE    0x40
+/* FQ force eligible */
+#define DPAA2_DQ_STAT_FORCEELIGIBLE 0x20
+/* Valid frame */
+#define DPAA2_DQ_STAT_VALIDFRAME    0x10
+/* FQ ODP enable */
+#define DPAA2_DQ_STAT_ODPVALID      0x04
+/* Volatile dequeue */
+#define DPAA2_DQ_STAT_VOLATILE      0x02
+/* volatile dequeue command is expired */
+#define DPAA2_DQ_STAT_EXPIRED       0x01
+
+/**
+ * dpaa2_dq_flags() - Get the stat field of dequeue response
+ * @dq: the dequeue result.
+ */
+uint32_t dpaa2_dq_flags(const struct dpaa2_dq *dq);
+
+/**
+ * dpaa2_dq_is_pull() - Check whether the dq response is from a pull
+ * command.
+ * @dq: the dequeue result.
+ *
+ * Return 1 for volatile(pull) dequeue, 0 for static dequeue.
+ */
+static inline int dpaa2_dq_is_pull(const struct dpaa2_dq *dq)
+{
+	return (int)(dpaa2_dq_flags(dq) & DPAA2_DQ_STAT_VOLATILE);
+}
+
+/**
+ * dpaa2_dq_is_pull_complete() - Check whether the pull command is completed.
+ * @dq: the dequeue result.
+ *
+ * Return boolean.
+ */
+static inline int dpaa2_dq_is_pull_complete(
+					const struct dpaa2_dq *dq)
+{
+	return (int)(dpaa2_dq_flags(dq) & DPAA2_DQ_STAT_EXPIRED);
+}
+
+/**
+ * dpaa2_dq_seqnum() - Get the seqnum field in dequeue response
+ * seqnum is valid only if VALIDFRAME flag is TRUE
+ * @dq: the dequeue result.
+ *
+ * Return seqnum.
+ */
+uint16_t dpaa2_dq_seqnum(const struct dpaa2_dq *dq);
+
+/**
+ * dpaa2_dq_odpid() - Get the seqnum field in dequeue response
+ * odpid is valid only if ODPVAILD flag is TRUE.
+ * @dq: the dequeue result.
+ *
+ * Return odpid.
+ */
+uint16_t dpaa2_dq_odpid(const struct dpaa2_dq *dq);
+
+/**
+ * dpaa2_dq_fqid() - Get the fqid in dequeue response
+ * @dq: the dequeue result.
+ *
+ * Return fqid.
+ */
+uint32_t dpaa2_dq_fqid(const struct dpaa2_dq *dq);
+
+/**
+ * dpaa2_dq_byte_count() - Get the byte count in dequeue response
+ * @dq: the dequeue result.
+ *
+ * Return the byte count remaining in the FQ.
+ */
+uint32_t dpaa2_dq_byte_count(const struct dpaa2_dq *dq);
+
+/**
+ * dpaa2_dq_frame_count() - Get the frame count in dequeue response
+ * @dq: the dequeue result.
+ *
+ * Return the frame count remaining in the FQ.
+ */
+uint32_t dpaa2_dq_frame_count(const struct dpaa2_dq *dq);
+
+/**
+ * dpaa2_dq_fd_ctx() - Get the frame queue context in dequeue response
+ * @dq: the dequeue result.
+ *
+ * Return the frame queue context.
+ */
+uint64_t dpaa2_dq_fqd_ctx(const struct dpaa2_dq *dq);
+
+/**
+ * dpaa2_dq_fd() - Get the frame descriptor in dequeue response
+ * @dq: the dequeue result.
+ *
+ * Return the frame descriptor.
+ */
+const struct dpaa2_fd *dpaa2_dq_fd(const struct dpaa2_dq *dq);
+
+#endif /* __FSL_DPAA2_FD_H */
diff --git a/drivers/staging/fsl-mc/include/fsl_dpaa2_io.h b/drivers/staging/fsl-mc/include/fsl_dpaa2_io.h
new file mode 100644
index 0000000..9718583
--- /dev/null
+++ b/drivers/staging/fsl-mc/include/fsl_dpaa2_io.h
@@ -0,0 +1,693 @@
+/* Copyright 2014 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef __FSL_DPAA2_IO_H
+#define __FSL_DPAA2_IO_H
+
+#include "fsl_dpaa2_fd.h"
+
+struct dpaa2_io;
+struct dpaa2_io_store;
+
+/**
+ * DOC: DPIO Service Management
+ *
+ * The DPIO service provides APIs for users to interact with the datapath
+ * by enqueueing and dequeing frame descriptors.
+ *
+ * The following set of APIs can be used to enqueue and dequeue frames
+ * as well as producing notification callbacks when data is available
+ * for dequeue.
+ */
+
+/**
+ * struct dpaa2_io_desc - The DPIO descriptor.
+ * @receives_notifications: Use notificaton mode.
+ * @has_irq: use irq-based proessing.
+ * @will_poll: use poll processing.
+ * @has_8prio: set for channel with 8 priority WQs.
+ * @cpu: the cpu index that at least interrupt handlers will execute on.
+ * @stash_affinity: the stash affinity for this portal favour 'cpu'
+ * @regs_cena: the cache enabled regs.
+ * @regs_cinh: the cache inhibited regs.
+ * @dpio_id: The dpio index.
+ * @qman_version: the qman version
+ *
+ * Describe the attributes and features of the DPIO object.
+ */
+struct dpaa2_io_desc {
+	/* non-zero iff the DPIO has a channel */
+	int receives_notifications;
+	/* non-zero if the DPIO portal interrupt is handled. If so, the
+	 * caller/OS handles the interrupt and calls dpaa2_io_service_irq(). */
+	int has_irq;
+	/* non-zero if the caller/OS is prepared to called the
+	 * dpaa2_io_service_poll() routine as part of its run-to-completion (or
+	 * scheduling) loop. If so, the DPIO service may dynamically switch some
+	 * of its processing between polling-based and irq-based. It is illegal
+	 * combination to have (!has_irq && !will_poll). */
+	int will_poll;
+	/* ignored unless 'receives_notifications'. Non-zero iff the channel has
+	 * 8 priority WQs, otherwise the channel has 2. */
+	int has_8prio;
+	/* the cpu index that at least interrupt handlers will execute on. And
+	 * if 'stash_affinity' is non-zero, the cache targeted by stash
+	 * transactions is affine to this cpu. */
+	int cpu;
+	/* non-zero if stash transactions for this portal favour 'cpu' over
+	 * other CPUs. (Eg. zero if there's no stashing, or stashing is to
+	 * shared cache.) */
+	int stash_affinity;
+	/* Caller-provided flags, determined by bus-scanning and/or creation of
+	 * DPIO objects via MC commands. */
+	void *regs_cena;
+	void *regs_cinh;
+	int dpio_id;
+	uint32_t qman_version;
+};
+
+/**
+ * dpaa2_io_create() - create a dpaa2_io object.
+ * @desc: the dpaa2_io descriptor
+ *
+ * Activates a "struct dpaa2_io" corresponding to the given config of an actual
+ * DPIO object. This handle can be used on it's own (like a one-portal "DPIO
+ * service") or later be added to a service-type "struct dpaa2_io" object. Note,
+ * the information required on 'cfg' is copied so the caller is free to do as
+ * they wish with the input parameter upon return.
+ *
+ * Return a valid dpaa2_io object for success, or NULL for failure.
+ */
+struct dpaa2_io *dpaa2_io_create(const struct dpaa2_io_desc *desc);
+
+/**
+ * dpaa2_io_create_service() -  Create an (initially empty) DPIO service.
+ *
+ * Return a valid dpaa2_io object for success, or NULL for failure.
+ */
+struct dpaa2_io *dpaa2_io_create_service(void);
+
+/**
+ * dpaa2_io_default_service() - Use the driver's own global (and initially
+ * empty) DPIO service.
+ *
+ * This increments the reference count, so don't forget to use dpaa2_io_down()
+ * for each time this function is called.
+ *
+ * Return a valid dpaa2_io object for success, or NULL for failure.
+ */
+struct dpaa2_io *dpaa2_io_default_service(void);
+
+/**
+ * dpaa2_io_down() - release the dpaa2_io object.
+ * @d: the dpaa2_io object to be released.
+ *
+ * The "struct dpaa2_io" type can represent an individual DPIO object (as
+ * described by "struct dpaa2_io_desc") or an instance of a "DPIO service",
+ * which can be used to group/encapsulate multiple DPIO objects. In all cases,
+ * each handle obtained should be released using this function.
+ */
+void dpaa2_io_down(struct dpaa2_io *d);
+
+/**
+ * dpaa2_io_service_add() - Add the given DPIO object to the given DPIO service.
+ * @service: the given DPIO service.
+ * @obj: the given DPIO object.
+ *
+ * 'service' must have been created by dpaa2_io_create_service() and 'obj'
+ * must have been created by dpaa2_io_create(). This increments the reference
+ * count on the object that 'obj' refers to, so the user could call
+ * dpaa2_io_down(obj) after this and the object will persist within the service
+ * (and will be destroyed when the service is destroyed).
+ *
+ * Return 0 for success, or -EINVAL for failure.
+ */
+int dpaa2_io_service_add(struct dpaa2_io *service, struct dpaa2_io *obj);
+
+/**
+ * dpaa2_io_get_descriptor() - Get the DPIO descriptor of the given DPIO object.
+ * @obj: the given DPIO object.
+ * @desc: the returned DPIO descriptor.
+ *
+ * This function will return failure if the given dpaa2_io struct represents a
+ * service rather than an individual DPIO object, otherwise it returns zero and
+ * the given 'cfg' structure is filled in.
+ *
+ * Return 0 for success, or -EINVAL for failure.
+ */
+int dpaa2_io_get_descriptor(struct dpaa2_io *obj, struct dpaa2_io_desc *desc);
+
+/**
+ * dpaa2_io_poll() -  Process any notifications and h/w-initiated events that
+ * are polling-driven.
+ * @obj: the given DPIO object.
+ *
+ * Obligatory for DPIO objects that have dpaa2_io_desc::will_poll non-zero.
+ *
+ * Return 0 for success, or -EINVAL for failure.
+ */
+int dpaa2_io_poll(struct dpaa2_io *obj);
+
+/**
+ * dpaa2_io_irq() - Process any notifications and h/w-initiated events that are
+ * irq-driven.
+ * @obj: the given DPIO object.
+ *
+ * Obligatory for DPIO objects that have dpaa2_io_desc::has_irq non-zero.
+ *
+ * Return IRQ_HANDLED for success, or -EINVAL for failure.
+ */
+int dpaa2_io_irq(struct dpaa2_io *obj);
+
+/**
+ * dpaa2_io_pause_poll() - Used to stop polling.
+ * @obj: the given DPIO object.
+ *
+ * If a polling application is going to stop polling for a period of time and
+ * supports interrupt processing, it can call this function to convert all
+ * processing to IRQ. (Eg. when sleeping.)
+ *
+ * Return -EINVAL.
+ */
+int dpaa2_io_pause_poll(struct dpaa2_io *obj);
+
+/**
+ * dpaa2_io_resume_poll() - Resume polling
+ * @obj: the given DPIO object.
+ *
+ * Return -EINVAL.
+ */
+int dpaa2_io_resume_poll(struct dpaa2_io *obj);
+
+/**
+ * dpaa2_io_service_notifications() - Get a mask of cpus that the DPIO service
+ * can receive notifications on.
+ * @s: the given DPIO object.
+ * @mask: the mask of cpus.
+ *
+ * Note that this is a run-time snapshot. If things like cpu-hotplug are
+ * supported in the target system, then an attempt to register notifications
+ * for a cpu that appears present in the given mask might fail if that cpu has
+ * gone offline in the mean time.
+ */
+void dpaa2_io_service_notifications(struct dpaa2_io *s, cpumask_t *mask);
+
+/**
+ * dpaa2_io_service_stashing - Get a mask of cpus that the DPIO service has stash
+ * affinity to.
+ * @s: the given DPIO object.
+ * @mask: the mask of cpus.
+ */
+void dpaa2_io_service_stashing(struct dpaa2_io *s, cpumask_t *mask);
+
+/**
+ * dpaa2_io_service_nonaffine() - Check the DPIO service's cpu affinity
+ * for stashing.
+ * @s: the given DPIO object.
+ *
+ * Return a boolean, whether or not the DPIO service has resources that have no
+ * particular cpu affinity for stashing. (Useful to know if you wish to operate
+ * on CPUs that the service has no affinity to, you would choose to use
+ * resources that are neutral, rather than affine to a different CPU.) Unlike
+ * other service-specific APIs, this one doesn't return an error if it is passed
+ * a non-service object. So don't do it.
+ */
+int dpaa2_io_service_has_nonaffine(struct dpaa2_io *s);
+
+/*************************/
+/* Notification handling */
+/*************************/
+
+/**
+ * struct dpaa2_io_notification_ctx - The DPIO notification context structure.
+ * @cb: the callback to be invoked when the notification arrives.
+ * @is_cdan: Zero/FALSE for FQDAN, non-zero/TRUE for CDAN.
+ * @id: FQID or channel ID, needed for rearm.
+ * @desired_cpu: the cpu on which the notifications will show up.
+ * @actual_cpu: the cpu the notification actually shows up.
+ * @migration_cb: callback function used for migration.
+ * @dpio_id: the dpio index.
+ * @qman64: the 64-bit context value shows up in the FQDAN/CDAN.
+ * @node: the list node.
+ * @dpio_private: the dpio object internal to dpio_service.
+ *
+ * When a FQDAN/CDAN registration is made (eg. by DPNI/DPCON/DPAI code), a
+ * context of the following type is used. The caller can embed it within a
+ * larger structure in order to add state that is tracked along with the
+ * notification (this may be useful when callbacks are invoked that pass this
+ * notification context as a parameter).
+ */
+struct dpaa2_io_notification_ctx {
+	void (*cb)(struct dpaa2_io_notification_ctx *);
+	int is_cdan;
+	uint32_t id;
+	/* This specifies which cpu the user wants notifications to show up on
+	 * (ie. to execute 'cb'). If notification-handling on that cpu is not
+	 * available at the time of notification registration, the registration
+	 * will fail. */
+	int desired_cpu;
+	/* If the target platform supports cpu-hotplug or other features
+	 * (related to power-management, one would expect) that can migrate IRQ
+	 * handling of a given DPIO object, then this value will potentially be
+	 * different to 'desired_cpu' at run-time. */
+	int actual_cpu;
+	/* And if migration does occur and this callback is non-NULL, it will
+	 * be invoked prior to any futher notification callbacks executing on
+	 * 'newcpu'. Note that 'oldcpu' is what 'actual_cpu' was prior to the
+	 * migration, and 'newcpu' is what it is now. Both could conceivably be
+	 * different to 'desired_cpu'. */
+	void (*migration_cb)(struct dpaa2_io_notification_ctx *,
+			     int oldcpu, int newcpu);
+	/* These are returned from dpaa2_io_service_register().
+	 * 'dpio_id' is the dpaa2_io_desc::dpio_id value of the DPIO object that
+	 * has been selected by the service for receiving the notifications. The
+	 * caller can use this value in the MC command that attaches the FQ (or
+	 * channel) of their DPNI (or DPCON, respectively) to this DPIO for
+	 * notification-generation.
+	 * 'qman64' is the 64-bit context value that needs to be sent in the
+	 * same MC command in order to be programmed into the FQ or channel -
+	 * this is the 64-bit value that shows up in the FQDAN/CDAN messages to
+	 * the DPIO object, and the DPIO service specifies this value back to
+	 * the caller so that the notifications that show up will be
+	 * comprensible/demux-able to the DPIO service. */
+	int dpio_id;
+	uint64_t qman64;
+	/* These fields are internal to the DPIO service once the context is
+	 * registered. TBD: may require more internal state fields. */
+	struct list_head node;
+	void *dpio_private;
+};
+
+/**
+ * dpaa2_io_service_register() - Prepare for servicing of FQDAN or CDAN
+ * notifications on the given DPIO service.
+ * @service: the given DPIO service.
+ * @ctx: the notification context.
+ *
+ * The MC command to attach the caller's DPNI/DPCON/DPAI device to a
+ * DPIO object is performed after this function is called. In that way, (a) the
+ * DPIO service is "ready" to handle a notification arrival (which might happen
+ * before the "attach" command to MC has returned control of execution back to
+ * the caller), and (b) the DPIO service can provide back to the caller the
+ * 'dpio_id' and 'qman64' parameters that it should pass along in the MC command
+ * in order for the DPNI/DPCON/DPAI resources to be configured to produce the
+ * right notification fields to the DPIO service.
+ *
+ * Return 0 for success, or -ENODEV for failure.
+ */
+int dpaa2_io_service_register(struct dpaa2_io *service,
+			     struct dpaa2_io_notification_ctx *ctx);
+
+/**
+ * dpaa2_io_service_deregister - The opposite of 'register'.
+ * @service: the given DPIO service.
+ * @ctx: the notification context.
+ *
+ * Note that 'register' should be called *before*
+ * making the MC call to attach the notification-producing device to the
+ * notification-handling DPIO service, the 'unregister' function should be
+ * called *after* making the MC call to detach the notification-producing
+ * device.
+ *
+ * Return 0 for success.
+ */
+int dpaa2_io_service_deregister(struct dpaa2_io *service,
+			       struct dpaa2_io_notification_ctx *ctx);
+
+/**
+ * dpaa2_io_service_rearm() - Rearm the notification for the given DPIO service.
+ * @service: the given DPIO service.
+ * @ctx: the notification context.
+ *
+ * Once a FQDAN/CDAN has been produced, the corresponding FQ/channel is
+ * considered "disarmed". Ie. the user can issue pull dequeue operations on that
+ * traffic source for as long as it likes. Eventually it may wish to "rearm"
+ * that source to allow it to produce another FQDAN/CDAN, that's what this
+ * function achieves.
+ *
+ * Return 0 for success, or -ENODEV if no service available, -EBUSY/-EIO for not
+ * being able to implement the rearm the notifiaton due to setting CDAN or
+ * scheduling fq.
+ */
+int dpaa2_io_service_rearm(struct dpaa2_io *service,
+			  struct dpaa2_io_notification_ctx *ctx);
+
+/**
+ * dpaa2_io_from_registration() - Get the DPIO object from the given notification
+ * context.
+ * @ctx: the given notifiation context.
+ * @ret: the returned DPIO object.
+ *
+ * Like 'dpaa2_io_service_get_persistent()' (see below), except that the
+ * returned handle is not selected based on a 'cpu' argument, but is the same
+ * DPIO object that the given notification context is registered against. The
+ * returned handle carries a reference count, so a corresponding dpaa2_io_down()
+ * would be required when the reference is no longer needed.
+ *
+ * Return 0 for success, or -EINVAL for failure.
+ */
+int dpaa2_io_from_registration(struct dpaa2_io_notification_ctx *ctx,
+			      struct dpaa2_io **ret);
+
+/**********************************/
+/* General usage of DPIO services */
+/**********************************/
+
+/**
+ * dpaa2_io_service_get_persistent() - Get the DPIO resource from the given
+ * notification context and cpu.
+ * @service: the DPIO service.
+ * @cpu: the cpu that the DPIO resource has stashing affinity to.
+ * @ret: the returned DPIO resource.
+ *
+ * The various DPIO interfaces can accept a "struct dpaa2_io" handle that refers
+ * to an individual DPIO object or to a whole service. In the latter case, an
+ * internal choice is made for each operation. This function supports the former
+ * case, by selecting an individual DPIO object *from* the service in order for
+ * it to be used multiple times to provide "persistence". The returned handle
+ * also carries a reference count, so a corresponding dpaa2_io_down() would be
+ * required when the reference is no longer needed. Note, a parameter of -1 for
+ * 'cpu' will select a DPIO resource that has no particular stashing affinity to
+ * any cpu (eg. one that stashes to platform cache).
+ *
+ * Return 0 for success, or -ENODEV for failure.
+ */
+int dpaa2_io_service_get_persistent(struct dpaa2_io *service, int cpu,
+				   struct dpaa2_io **ret);
+
+/*****************/
+/* Pull dequeues */
+/*****************/
+
+/**
+ * dpaa2_io_service_pull_fq() - pull dequeue functions from a fq.
+ * @d: the given DPIO service.
+ * @fqid: the given frame queue id.
+ * @s: the dpaa2_io_store object for the result.
+ *
+ * To support DCA/order-preservation, it will be necessary to support an
+ * alternative form, because they must ultimately dequeue to DQRR rather than a
+ * user-supplied dpaa2_io_store. Furthermore, those dequeue results will
+ * "complete" using a caller-provided callback (from DQRR processing) rather
+ * than the caller explicitly looking at their dpaa2_io_store for results. Eg.
+ * the alternative form will likely take a callback parameter rather than a
+ * store parameter. Ignoring it for now to keep the picture clearer.
+ *
+ * Return 0 for success, or error code for failure.
+ */
+int dpaa2_io_service_pull_fq(struct dpaa2_io *d, uint32_t fqid,
+			    struct dpaa2_io_store *s);
+
+/**
+ * dpaa2_io_service_pull_channel() - pull dequeue functions from a channel.
+ * @d: the given DPIO service.
+ * @channelid: the given channel id.
+ * @s: the dpaa2_io_store object for the result.
+ *
+ * To support DCA/order-preservation, it will be necessary to support an
+ * alternative form, because they must ultimately dequeue to DQRR rather than a
+ * user-supplied dpaa2_io_store. Furthermore, those dequeue results will
+ * "complete" using a caller-provided callback (from DQRR processing) rather
+ * than the caller explicitly looking at their dpaa2_io_store for results. Eg.
+ * the alternative form will likely take a callback parameter rather than a
+ * store parameter. Ignoring it for now to keep the picture clearer.
+ *
+ * Return 0 for success, or error code for failure.
+ */
+int dpaa2_io_service_pull_channel(struct dpaa2_io *d, uint32_t channelid,
+				 struct dpaa2_io_store *s);
+
+/************/
+/* Enqueues */
+/************/
+
+/**
+ * dpaa2_io_service_enqueue_fq() - Enqueue a frame to a frame queue.
+ * @d: the given DPIO service.
+ * @fqid: the given frame queue id.
+ * @fd: the frame descriptor which is enqueued.
+ *
+ * This definition bypasses some features that are not expected to be priority-1
+ * features, and may not be needed at all via current assumptions (QBMan's
+ * feature set is wider than the MC object model is intendeding to support,
+ * initially at least). Plus, keeping them out (for now) keeps the API view
+ * simpler. Missing features are;
+ *  - enqueue confirmation (results DMA'd back to the user)
+ *  - DCA/order-preservation (see note in "pull dequeues")
+ *  - enqueue consumption interrupts
+ *
+ * Return 0 for successful enqueue, or -EBUSY if the enqueue ring is not ready,
+ * or -ENODEV if there is no dpio service.
+ */
+int dpaa2_io_service_enqueue_fq(struct dpaa2_io *d,
+			       uint32_t fqid,
+			       const struct dpaa2_fd *fd);
+
+/**
+ * dpaa2_io_service_enqueue_orp_fq() - Enqueue a frame to a frame queue with
+ * order restoration
+ * @d: the given DPIO service.
+ * @fqid: the given frame queue id.
+ * @fd: the frame descriptor which is enqueued.
+ * @orp_id: the order restoration point ID
+ * @seqnum: the order sequence number
+ * @last: must be set for the final frame if seqnum is shared (spilt frame)
+ *
+ * Performs an enqueue to a frame queue using the specified order restortation
+ * point. The QMan device will ensure the order of frames placed on the
+ * queue will be ordered as per the sequence number.
+ *
+ * In the case a frame is split it is possible to enqueue using the same
+ * sequence number more than once. The final frame in a shared sequence number
+ * most be indicated by setting last = 1. For non shared sequence numbers
+ * last = 1 must always be set.
+ *
+ * Return 0 for successful enqueue, or -EBUSY if the enqueue ring is not ready,
+ * or -ENODEV if there is no dpio service.
+ */
+int dpaa2_io_service_enqueue_orp_fq(struct dpaa2_io *d,
+				    uint32_t fqid,
+				    const struct dpaa2_fd *fd,
+				    uint16_t orp_id,
+				    uint16_t seqnum,
+				    int last);
+
+/**
+ * dpaa2_io_service_enqueue_qd() - Enqueue a frame to a QD.
+ * @d: the given DPIO service.
+ * @qdid: the given queuing destination id.
+ * @prio: the given queuing priority.
+ * @qdbin: the given queuing destination bin.
+ * @fd: the frame descriptor which is enqueued.
+ *
+ * This definition bypasses some features that are not expected to be priority-1
+ * features, and may not be needed at all via current assumptions (QBMan's
+ * feature set is wider than the MC object model is intendeding to support,
+ * initially at least). Plus, keeping them out (for now) keeps the API view
+ * simpler. Missing features are;
+ *  - enqueue confirmation (results DMA'd back to the user)
+ *  - DCA/order-preservation (see note in "pull dequeues")
+ *  - enqueue consumption interrupts
+ *
+ * Return 0 for successful enqueue, or -EBUSY if the enqueue ring is not ready,
+ * or -ENODEV if there is no dpio service.
+ */
+int dpaa2_io_service_enqueue_qd(struct dpaa2_io *d,
+			       uint32_t qdid, uint8_t prio, uint16_t qdbin,
+			       const struct dpaa2_fd *fd);
+
+/**
+ * dpaa2_io_service_enqueue_orp_qd() - Enqueue a frame to a queueing destination
+ * with order restoration
+ * @d: the given DPIO service.
+ * @qdid: the given queuing destination id.
+ * @fd: the frame descriptor which is enqueued.
+ * @orp_id: the order restoration point ID
+ * @seqnum: the order sequence number
+ * @last: must be set for the final frame if seqnum is shared (spilt frame)
+ *
+ * Performs an enqueue to a frame queue using the specified order restortation
+ * point. The QMan device will ensure the order of frames placed on the
+ * queue will be ordered as per the sequence number.
+ *
+ * In the case a frame is split it is possible to enqueue using the same
+ * sequence number more than once. The final frame in a shared sequence number
+ * most be indicated by setting last = 1. For non shared sequence numbers
+ * last = 1 must always be set.
+ *
+ * Return 0 for successful enqueue, or -EBUSY if the enqueue ring is not ready,
+ * or -ENODEV if there is no dpio service.
+ */
+int dpaa2_io_service_enqueue_orp_qd(struct dpaa2_io *d,
+				    uint32_t qdid, uint8_t prio, uint16_t qdbin,
+				    const struct dpaa2_fd *fd,
+				    uint16_t orp_id, uint16_t seqnum,
+				    int last);
+
+/**
+ * dpaa2_io_service_orp_seqnum_drop() - Remove a sequence number from
+ * an order restoration list
+ * @d: the given DPIO service.
+ * @orp_id: Order restoration point to remove a sequence number from
+ * @seqnum: Sequence number to remove
+ *
+ * Removes a frames sequeuence number from an order restoration point without
+ * enqueing the frame. Used to indicate that the order restoration hardware
+ * should not expect to see this sequence number. Typically used to indicate
+ * a frame was terminated or dropped from a flow.
+ *
+ * Return 0 for successful enqueue, or -EBUSY if the enqueue ring is not ready,
+ * or -ENODEV if there is no dpio service.
+ */
+int dpaa2_io_service_orp_seqnum_drop(struct dpaa2_io *d,
+				     uint16_t orp_id, uint16_t seqnum);
+
+
+/*******************/
+/* Buffer handling */
+/*******************/
+
+/**
+ * dpaa2_io_service_release() - Release buffers to a buffer pool.
+ * @d: the given DPIO object.
+ * @bpid: the buffer pool id.
+ * @buffers: the buffers to be released.
+ * @num_buffers: the number of the buffers to be released.
+ *
+ * Return 0 for success, and negative error code for failure.
+ */
+int dpaa2_io_service_release(struct dpaa2_io *d,
+			    uint32_t bpid,
+			    const uint64_t *buffers,
+			    unsigned int num_buffers);
+
+/**
+ * dpaa2_io_service_acquire() - Acquire buffers from a buffer pool.
+ * @d: the given DPIO object.
+ * @bpid: the buffer pool id.
+ * @buffers: the buffer addresses for acquired buffers.
+ * @num_buffers: the expected number of the buffers to acquire.
+ *
+ * Return a negative error code if the command failed, otherwise it returns
+ * the number of buffers acquired, which may be less than the number requested.
+ * Eg. if the buffer pool is empty, this will return zero.
+ */
+int dpaa2_io_service_acquire(struct dpaa2_io *d,
+			    uint32_t bpid,
+			    uint64_t *buffers,
+			    unsigned int num_buffers);
+
+/***************/
+/* DPIO stores */
+/***************/
+
+/* These are reusable memory blocks for retrieving dequeue results into, and to
+ * assist with parsing those results once they show up. They also hide the
+ * details of how to use "tokens" to make detection of DMA results possible (ie.
+ * comparing memory before the DMA and after it) while minimising the needless
+ * clearing/rewriting of those memory locations between uses.
+ */
+
+/**
+ * dpaa2_io_store_create() - Create the dma memory storage for dequeue
+ * result.
+ * @max_frames: the maximum number of dequeued result for frames, must be <= 16.
+ * @dev: the device to allow mapping/unmapping the DMAable region.
+ *
+ * Constructor - max_frames must be <= 16. The user provides the
+ * device struct to allow mapping/unmapping of the DMAable region. Area for
+ * storage will be allocated during create. The size of this storage is
+ * "max_frames*sizeof(struct dpaa2_dq)". The 'dpaa2_io_store' returned is a
+ * wrapper structure allocated within the DPIO code, which owns and manages
+ * allocated store.
+ *
+ * Return dpaa2_io_store struct for successfuly created storage memory, or NULL
+ * if not getting the stroage for dequeue result in create API.
+ */
+struct dpaa2_io_store *dpaa2_io_store_create(unsigned int max_frames,
+					   struct device *dev);
+
+/**
+ * dpaa2_io_store_destroy() - Destroy the dma memory storage for dequeue
+ * result.
+ * @s: the storage memory to be destroyed.
+ *
+ * Frees to specified storage memory.
+ */
+void dpaa2_io_store_destroy(struct dpaa2_io_store *s);
+
+/**
+ * dpaa2_io_store_next() - Determine when the next dequeue result is available.
+ * @s: the dpaa2_io_store object.
+ * @is_last: indicate whether this is the last frame in the pull command.
+ *
+ * Once dpaa2_io_store has been passed to a function that performs dequeues to
+ * it, like dpaa2_ni_rx(), this function can be used to determine when the next
+ * frame result is available. Once this function returns non-NULL, a subsequent
+ * call to it will try to find the *next* dequeue result.
+ *
+ * Note that if a pull-dequeue has a null result because the target FQ/channel
+ * was empty, then this function will return NULL rather than expect the caller
+ * to always check for this on his own side. As such, "is_last" can be used to
+ * differentiate between "end-of-empty-dequeue" and "still-waiting".
+ *
+ * Return dequeue result for a valid dequeue result, or NULL for empty dequeue.
+ */
+struct dpaa2_dq *dpaa2_io_store_next(struct dpaa2_io_store *s, int *is_last);
+
+#ifdef CONFIG_FSL_QBMAN_DEBUG
+/**
+ * dpaa2_io_query_fq_count() - Get the frame and byte count for a given fq.
+ * @d: the given DPIO object.
+ * @fqid: the id of frame queue to be queried.
+ * @fcnt: the queried frame count.
+ * @bcnt: the queried byte count.
+ *
+ * Knowing the FQ count at run-time can be useful in debugging situations.
+ * The instantaneous frame- and byte-count are hereby returned.
+ *
+ * Return 0 for a successful query, and negative error code if query fails.
+ */
+int dpaa2_io_query_fq_count(struct dpaa2_io *d, uint32_t fqid,
+			   uint32_t *fcnt, uint32_t *bcnt);
+
+/**
+ * dpaa2_io_query_bp_count() - Query the number of buffers currenty in a
+ * buffer pool.
+ * @d: the given DPIO object.
+ * @bpid: the index of buffer pool to be queried.
+ * @num: the queried number of buffers in the buffer pool.
+ *
+ * Return 0 for a sucessful query, and negative error code if query fails.
+ */
+int dpaa2_io_query_bp_count(struct dpaa2_io *d, uint32_t bpid,
+			   uint32_t *num);
+#endif
+#endif /* __FSL_DPAA2_IO_H */
diff --git a/drivers/staging/fsl-mc/include/mc-cmd.h b/drivers/staging/fsl-mc/include/mc-cmd.h
index 32501e0..c372776 100644
--- a/drivers/staging/fsl-mc/include/mc-cmd.h
+++ b/drivers/staging/fsl-mc/include/mc-cmd.h
@@ -1,4 +1,4 @@
-/* Copyright 2013-2015 Freescale Semiconductor Inc.
+/* Copyright 2013-2016 Freescale Semiconductor Inc.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -35,7 +35,8 @@
 #define MC_CMD_NUM_OF_PARAMS	7
 
 #define MAKE_UMASK64(_width) \
-	((uint64_t)((_width) < 64 ? ((uint64_t)1 << (_width)) - 1 : -1))
+	((uint64_t)((_width) < 64 ? ((uint64_t)1 << (_width)) - 1 : \
+				    (uint64_t)-1))
 
 static inline uint64_t mc_enc(int lsoffset, int width, uint64_t val)
 {
@@ -67,14 +68,36 @@ enum mc_cmd_status {
 	MC_CMD_STATUS_INVALID_STATE = 0xC /* Invalid state */
 };
 
-#define MC_CMD_HDR_CMDID_O	52	/* Command ID field offset */
-#define MC_CMD_HDR_CMDID_S	12	/* Command ID field size */
-#define MC_CMD_HDR_TOKEN_O	38	/* Token field offset */
-#define MC_CMD_HDR_TOKEN_S	10	/* Token field size */
+/*
+ * MC command flags
+ */
+
+/* High priority flag */
+#define MC_CMD_FLAG_PRI		0x00008000
+/* Command completion flag */
+#define MC_CMD_FLAG_INTR_DIS	0x01000000
+
+/* TODO Remove following two defines after completion of flib 8.0.0
+integration */
+#define MC_CMD_PRI_LOW		0 /*!< Low Priority command indication */
+#define MC_CMD_PRI_HIGH		1 /*!< High Priority command indication */
+
+#define MC_CMD_HDR_CMDID_O	48	/* Command ID field offset */
+#define MC_CMD_HDR_CMDID_S	16	/* Command ID field size */
+#define MC_CMD_HDR_TOKEN_O	32	/* Token field offset */
+#define MC_CMD_HDR_TOKEN_S	16	/* Token field size */
 #define MC_CMD_HDR_STATUS_O	16	/* Status field offset */
 #define MC_CMD_HDR_STATUS_S	8	/* Status field size*/
-#define MC_CMD_HDR_PRI_O	15	/* Priority field offset */
-#define MC_CMD_HDR_PRI_S	1	/* Priority field size */
+#define MC_CMD_HDR_FLAGS_O	0	/* Flags field offset */
+#define MC_CMD_HDR_FLAGS_S	32	/* Flags field size*/
+#define MC_CMD_HDR_FLAGS_MASK	0xFF00FF00 /* Command flags mask */
+
+#define MC_CMD_OBJ_ID_O		0	/* Object id field offset */
+#define MC_CMD_OBJ_ID_S		32	/* Object id field size */
+
+#define MC_CMD_OBJ_VERSION_MAJ_O	0 	/* Object major version offset */
+#define MC_CMD_OBJ_VERSION_MIN_O	16 	/* Object minor version offset */
+#define MC_CMD_OBJ_VERSION_S		16 	/* Object version field size */
 
 #define MC_CMD_HDR_READ_STATUS(_hdr) \
 	((enum mc_cmd_status)mc_dec((_hdr), \
@@ -83,11 +106,14 @@ enum mc_cmd_status {
 #define MC_CMD_HDR_READ_TOKEN(_hdr) \
 	((uint16_t)mc_dec((_hdr), MC_CMD_HDR_TOKEN_O, MC_CMD_HDR_TOKEN_S))
 
-#define MC_CMD_PRI_LOW		0 /* Low Priority command indication */
-#define MC_CMD_PRI_HIGH		1 /* High Priority command indication */
+#define MC_CMD_HDR_READ_FLAGS(_hdr) \
+	((uint32_t)mc_dec((_hdr), MC_CMD_HDR_FLAGS_O, MC_CMD_HDR_FLAGS_S))
+
+#define MC_PREP_OP(_ext, _param, _offset, _width, _type, _arg) \
+	((_ext)[_param] |= cpu_to_le64(mc_enc((_offset), (_width), _arg)))
 
 #define MC_EXT_OP(_ext, _param, _offset, _width, _type, _arg) \
-	((_ext)[_param] |= mc_enc((_offset), (_width), _arg))
+	(_arg = (_type)mc_dec(cpu_to_le64(_ext[_param]), (_offset), (_width)))
 
 #define MC_CMD_OP(_cmd, _param, _offset, _width, _type, _arg) \
 	((_cmd).params[_param] |= mc_enc((_offset), (_width), _arg))
@@ -95,15 +121,54 @@ enum mc_cmd_status {
 #define MC_RSP_OP(_cmd, _param, _offset, _width, _type, _arg) \
 	(_arg = (_type)mc_dec(_cmd.params[_param], (_offset), (_width)))
 
+static inline void get_mc_cmd_object_api_ver(struct mc_command *mc_cmd,
+		uint16_t *major_ver, uint16_t *minor_ver)
+{
+	*major_ver = (uint16_t)mc_dec(mc_cmd->params[0],
+			MC_CMD_OBJ_VERSION_MAJ_O,
+			MC_CMD_OBJ_VERSION_S);
+	*minor_ver = (uint16_t)mc_dec(mc_cmd->params[0],
+			MC_CMD_OBJ_VERSION_MIN_O,
+			MC_CMD_OBJ_VERSION_S);
+}
+
+static inline uint32_t get_mc_cmd_create_object_id(struct mc_command *cmd)
+{
+	return (uint32_t) mc_dec(cmd->params[0],
+			MC_CMD_OBJ_ID_O, MC_CMD_OBJ_ID_S);
+}
+
+
+static inline void set_mc_cmd_destroy_object_id(struct mc_command *cmd,
+		uint32_t object_id)
+{
+	cmd->params[0] = mc_enc(MC_CMD_OBJ_ID_O, MC_CMD_OBJ_ID_S, object_id);
+}
+
+static inline uint16_t get_mc_cmd_hdr_token(uint64_t mcp_header)
+{
+	return ((uint16_t)mc_dec((mcp_header),
+			MC_CMD_HDR_TOKEN_O,
+			MC_CMD_HDR_TOKEN_S));
+}
+
+static inline uint16_t get_mc_cmd_hdr_cmdid(uint64_t mcp_header)
+{
+	return ((uint16_t)mc_dec((mcp_header),
+			MC_CMD_HDR_CMDID_O,
+			MC_CMD_HDR_CMDID_S));
+}
+
 static inline uint64_t mc_encode_cmd_header(uint16_t cmd_id,
-					    uint8_t priority,
+					    uint32_t cmd_flags,
 					    uint16_t token)
 {
 	uint64_t hdr;
 
 	hdr = mc_enc(MC_CMD_HDR_CMDID_O, MC_CMD_HDR_CMDID_S, cmd_id);
+	hdr |= mc_enc(MC_CMD_HDR_FLAGS_O, MC_CMD_HDR_FLAGS_S,
+		       (cmd_flags & MC_CMD_HDR_FLAGS_MASK));
 	hdr |= mc_enc(MC_CMD_HDR_TOKEN_O, MC_CMD_HDR_TOKEN_S, token);
-	hdr |= mc_enc(MC_CMD_HDR_PRI_O, MC_CMD_HDR_PRI_S, priority);
 	hdr |= mc_enc(MC_CMD_HDR_STATUS_O, MC_CMD_HDR_STATUS_S,
 		       MC_CMD_STATUS_READY);
 
diff --git a/drivers/staging/fsl-mc/include/mc-private.h b/drivers/staging/fsl-mc/include/mc-private.h
index c045f49..9e4d36d 100644
--- a/drivers/staging/fsl-mc/include/mc-private.h
+++ b/drivers/staging/fsl-mc/include/mc-private.h
@@ -27,27 +27,66 @@
 	 strcmp(_obj_type, "dpcon") == 0)
 
 /**
+ * Maximum number of total IRQs that can be pre-allocated for an MC bus'
+ * IRQ pool
+ */
+#define FSL_MC_IRQ_POOL_MAX_TOTAL_IRQS	256
+
+/**
+ * Maximum number of extra IRQs pre-reallocated for an MC bus' IRQ pool,
+ * to be used by dynamically created MC objects
+ */
+#define FSL_MC_IRQ_POOL_MAX_EXTRA_IRQS	64
+
+/**
+ * dprc_scan_objects option to populate the mc bus IRQ resource pool before
+ * adding new devices
+ */
+#define FSL_MC_SCAN_DPRC_POPULATE_IRQ_POOL 1
+
+/**
  * struct fsl_mc - Private data of a "fsl,qoriq-mc" platform device
  * @root_mc_bus_dev: MC object device representing the root DPRC
+ * @irq_domain: IRQ domain for the fsl-mc bus type
+ * @gic_supported: boolean flag that indicates if the GIC interrupt controller
+ * is supported.
+ * @num_translation_ranges: number of entries in addr_translation_ranges
  * @addr_translation_ranges: array of bus to system address translation ranges
  */
 struct fsl_mc {
 	struct fsl_mc_device *root_mc_bus_dev;
+	struct irq_domain *irq_domain;
+	bool gic_supported;
 	uint8_t num_translation_ranges;
 	struct fsl_mc_addr_translation_range *translation_ranges;
 };
 
 /**
+ * enum mc_region_types - Types of MC MMIO regions
+ */
+enum fsl_mc_region_types {
+	FSL_MC_PORTAL = 0x0,
+	FSL_QBMAN_PORTAL,
+
+	/*
+	 * New offset types must be added above this entry
+	 */
+	FSL_NUM_MC_OFFSET_TYPES
+};
+
+/**
  * struct fsl_mc_addr_translation_range - bus to system address translation
  * range
- * @start_mc_addr: Start MC address of the range being translated
- * @end_mc_addr: MC address of the first byte after the range (last MC
- * address of the range is end_mc_addr - 1)
+ * @mc_region_type: Type of MC region for the range being translated
+ * @start_mc_offset: Start MC offset of the range being translated
+ * @end_mc_offset: MC offset of the first byte after the range (last MC
+ * offset of the range is end_mc_offset - 1)
  * @start_phys_addr: system physical address corresponding to start_mc_addr
  */
 struct fsl_mc_addr_translation_range {
-	uint64_t start_mc_addr;
-	uint64_t end_mc_addr;
+	enum fsl_mc_region_types mc_region_type;
+	uint64_t start_mc_offset;
+	uint64_t end_mc_offset;
 	phys_addr_t start_phys_addr;
 };
 
@@ -76,12 +115,21 @@ struct fsl_mc_resource_pool {
  * @resource_pools: array of resource pools (one pool per resource type)
  * for this MC bus. These resources represent allocatable entities
  * from the physical DPRC.
+ * @atomic_mc_io: mc_io object to be used to send DPRC commands to the MC
+ * in atomic context (e.g., when programming MSIs in program_msi_at_mc()).
+ * @atomic_dprc_handle: DPRC handle opened using the atomic_mc_io's portal.
+ * @irq_resources: Pointer to array of IRQ objects for the IRQ pool.
  * @scan_mutex: Serializes bus scanning
+ * @dprc_attr: DPRC attributes
  */
 struct fsl_mc_bus {
 	struct fsl_mc_device mc_dev;
 	struct fsl_mc_resource_pool resource_pools[FSL_MC_NUM_POOL_TYPES];
+	struct fsl_mc_device_irq *irq_resources;
+	struct fsl_mc_io *atomic_mc_io;
+	uint16_t atomic_dprc_handle;
 	struct mutex scan_mutex;    /* serializes bus scanning */
+	struct dprc_attributes dprc_attr;
 };
 
 #define to_fsl_mc_bus(_mc_dev) \
@@ -90,13 +138,15 @@ struct fsl_mc_bus {
 int __must_check fsl_mc_device_add(struct dprc_obj_desc *obj_desc,
 				   struct fsl_mc_io *mc_io,
 				   struct device *parent_dev,
+				   const char *driver_override,
 				   struct fsl_mc_device **new_mc_dev);
 
 void fsl_mc_device_remove(struct fsl_mc_device *mc_dev);
 
-int dprc_scan_container(struct fsl_mc_device *mc_bus_dev);
-
-int dprc_scan_objects(struct fsl_mc_device *mc_bus_dev);
+int dprc_scan_objects(struct fsl_mc_device *mc_bus_dev,
+		      const char *driver_override,
+		      unsigned int *total_irq_count,
+		      unsigned int scan_options);
 
 int __init dprc_driver_init(void);
 
@@ -113,4 +163,13 @@ int __must_check fsl_mc_resource_allocate(struct fsl_mc_bus *mc_bus,
 
 void fsl_mc_resource_free(struct fsl_mc_resource *resource);
 
+int __must_check fsl_mc_populate_irq_pool(struct fsl_mc_bus *mc_bus,
+					  unsigned int irq_count);
+
+void fsl_mc_cleanup_irq_pool(struct fsl_mc_bus *mc_bus);
+
+void dprc_init_all_resource_pools(struct fsl_mc_device *mc_bus_dev);
+
+void dprc_cleanup_all_resource_pools(struct fsl_mc_device *mc_bus_dev);
+
 #endif /* _FSL_MC_PRIVATE_H_ */
diff --git a/drivers/staging/fsl-mc/include/mc-sys.h b/drivers/staging/fsl-mc/include/mc-sys.h
index cb3b5a2..b08df85 100644
--- a/drivers/staging/fsl-mc/include/mc-sys.h
+++ b/drivers/staging/fsl-mc/include/mc-sys.h
@@ -39,6 +39,14 @@
 #include <linux/errno.h>
 #include <linux/io.h>
 #include <linux/dma-mapping.h>
+#include <linux/completion.h>
+#include <linux/mutex.h>
+#include <linux/spinlock.h>
+
+/**
+ * Bit masks for a MC I/O object (struct fsl_mc_io) flags
+ */
+#define FSL_MC_IO_ATOMIC_CONTEXT_PORTAL	0x0001
 
 struct fsl_mc_resource;
 struct mc_command;
@@ -50,27 +58,71 @@ struct mc_command;
  * @portal_size: MC command portal size in bytes
  * @portal_phys_addr: MC command portal physical address
  * @portal_virt_addr: MC command portal virtual address
- * @resource: generic resource associated with the MC portal if
- * the MC portal came from a resource pool, or NULL if the MC portal
- * is permanently bound to a device (e.g., a DPRC)
+ * @dpmcp_dev: pointer to the DPMCP device associated with the MC portal.
+ * @mc_command_done_irq_armed: Flag indicating that the MC command done IRQ
+ * is currently armed.
+ * @mc_command_done_completion: Completion variable to be signaled when an MC
+ * command sent to the MC fw is completed.
+ *
+ * Fields are only meaningful if the FSL_MC_IO_ATOMIC_CONTEXT_PORTAL flag is not
+ * set:
+ * @mutex: Mutex to serialize mc_send_command() calls that use the same MC
+ * portal, if the fsl_mc_io object was created with the
+ * FSL_MC_IO_ATOMIC_CONTEXT_PORTAL flag off. mc_send_command() calls for this
+ * fsl_mc_io object must be made only from non-atomic context.
+ * @mc_command_done_completion: Linux completion variable to be signaled
+ * when a DPMCP command completion interrupts is received.
+ * @mc_command_done_irq_armed: Boolean flag that indicates if interrupts have
+ * been successfully configured for the corresponding DPMCP object.
+ *
+ * Fields are only meaningful if the FSL_MC_IO_ATOMIC_CONTEXT_PORTAL flag is
+ * set:
+ * @spinlock: Spinlock to serialize mc_send_command() calls that use the same MC
+ * portal, if the fsl_mc_io object was created with the
+ * FSL_MC_IO_ATOMIC_CONTEXT_PORTAL flag on. mc_send_command() calls for this
+ * fsl_mc_io object can be made from atomic or non-atomic context.
  */
 struct fsl_mc_io {
 	struct device *dev;
-	uint32_t flags;
-	uint32_t portal_size;
+	uint16_t flags;
+	uint16_t portal_size;
 	phys_addr_t portal_phys_addr;
 	void __iomem *portal_virt_addr;
-	struct fsl_mc_resource *resource;
+	struct fsl_mc_device *dpmcp_dev;
+	union {
+		/*
+		 * These fields are only meaningful if the
+		 * FSL_MC_IO_ATOMIC_CONTEXT_PORTAL flag is not set
+		 */
+		struct {
+			struct mutex mutex; /* serializes mc_send_command() */
+			struct completion mc_command_done_completion;
+			bool mc_command_done_irq_armed;
+		};
+
+		/*
+		 * This field is only meaningful if the
+		 * FSL_MC_IO_ATOMIC_CONTEXT_PORTAL flag is set
+		 */
+		spinlock_t spinlock;	/* serializes mc_send_command() */
+	};
 };
 
 int __must_check fsl_create_mc_io(struct device *dev,
 				  phys_addr_t mc_portal_phys_addr,
 				  uint32_t mc_portal_size,
-				  struct fsl_mc_resource *resource,
+				  struct fsl_mc_device *dpmcp_dev,
 				  uint32_t flags, struct fsl_mc_io **new_mc_io);
 
 void fsl_destroy_mc_io(struct fsl_mc_io *mc_io);
 
+int fsl_mc_io_set_dpmcp(struct fsl_mc_io *mc_io,
+			struct fsl_mc_device *dpmcp_dev);
+
+void fsl_mc_io_unset_dpmcp(struct fsl_mc_io *mc_io);
+
+int fsl_mc_io_setup_dpmcp_irq(struct fsl_mc_io *mc_io);
+
 int mc_send_command(struct fsl_mc_io *mc_io, struct mc_command *cmd);
 
 #endif /* _FSL_MC_SYS_H */
diff --git a/drivers/staging/fsl-mc/include/mc.h b/drivers/staging/fsl-mc/include/mc.h
index fa02ef0..bbeb121 100644
--- a/drivers/staging/fsl-mc/include/mc.h
+++ b/drivers/staging/fsl-mc/include/mc.h
@@ -14,6 +14,8 @@
 #include <linux/device.h>
 #include <linux/mod_devicetable.h>
 #include <linux/list.h>
+#include <linux/interrupt.h>
+#include <linux/platform_device.h>
 #include "../include/dprc.h"
 
 #define FSL_MC_VENDOR_FREESCALE	0x1957
@@ -75,6 +77,7 @@ enum fsl_mc_pool_type {
 	FSL_MC_POOL_DPMCP = 0x0,    /* corresponds to "dpmcp" in the MC */
 	FSL_MC_POOL_DPBP,	    /* corresponds to "dpbp" in the MC */
 	FSL_MC_POOL_DPCON,	    /* corresponds to "dpcon" in the MC */
+	FSL_MC_POOL_IRQ,
 
 	/*
 	 * NOTE: New resource pool types must be added before this entry
@@ -104,11 +107,41 @@ struct fsl_mc_resource {
 };
 
 /**
+ * struct fsl_mc_device_irq - MC object device message-based interrupt
+ * @msi_paddr: message-based interrupt physical address
+ * @msi_value: message-based interrupt data value
+ * @irq_number: Linux IRQ number assigned to the interrupt
+ * @mc_dev: MC object device that owns this interrupt
+ * @dev_irq_index: device-relative IRQ index
+ * @resource: MC generic resource associated with the interrupt
+ */
+struct fsl_mc_device_irq {
+	phys_addr_t msi_paddr;
+	uint32_t msi_value;
+	uint32_t irq_number;
+	struct fsl_mc_device *mc_dev;
+	uint8_t dev_irq_index;
+	struct fsl_mc_resource resource;
+};
+
+#define to_fsl_mc_irq(_mc_resource) \
+	container_of(_mc_resource, struct fsl_mc_device_irq, resource)
+
+/**
  * Bit masks for a MC object device (struct fsl_mc_device) flags
  */
 #define FSL_MC_IS_DPRC	0x0001
 
 /**
+  * root dprc's parent is a platform device
+  * that platform device's bus type is platform_bus_type.
+  */
+#define is_root_dprc(dev) \
+	((to_fsl_mc_device(dev)->flags & FSL_MC_IS_DPRC) && \
+	((dev)->bus == &fsl_mc_bus_type) && \
+	((dev)->parent->bus == &platform_bus_type))
+
+/**
  * Default DMA mask for devices on a fsl-mc bus
  */
 #define FSL_MC_DEFAULT_DMA_MASK	(~0ULL)
@@ -124,7 +157,9 @@ struct fsl_mc_resource {
  * NULL if none.
  * @obj_desc: MC description of the DPAA device
  * @regions: pointer to array of MMIO region entries
+ * @irqs: pointer to array of pointers to interrupts allocated to this device
  * @resource: generic resource associated with this MC object device, if any.
+ * @driver_override: Driver name to force a match
  *
  * Generic device object for MC object devices that are "attached" to a
  * MC bus.
@@ -155,7 +190,9 @@ struct fsl_mc_device {
 	struct fsl_mc_io *mc_io;
 	struct dprc_obj_desc obj_desc;
 	struct resource *regions;
+	struct fsl_mc_device_irq **irqs;
 	struct fsl_mc_resource *resource;
+	const char *driver_override;
 };
 
 #define to_fsl_mc_device(_dev) \
@@ -182,6 +219,8 @@ int __must_check __fsl_mc_driver_register(struct fsl_mc_driver *fsl_mc_driver,
 
 void fsl_mc_driver_unregister(struct fsl_mc_driver *driver);
 
+bool fsl_mc_interrupts_supported(void);
+
 int __must_check fsl_mc_portal_allocate(struct fsl_mc_device *mc_dev,
 					uint16_t mc_io_flags,
 					struct fsl_mc_io **new_mc_io);
@@ -196,6 +235,10 @@ int __must_check fsl_mc_object_allocate(struct fsl_mc_device *mc_dev,
 
 void fsl_mc_object_free(struct fsl_mc_device *mc_adev);
 
+int __must_check fsl_mc_allocate_irqs(struct fsl_mc_device *mc_dev);
+
+void fsl_mc_free_irqs(struct fsl_mc_device *mc_dev);
+
 extern struct bus_type fsl_mc_bus_type;
 
 #endif /* _FSL_MC_H_ */
diff --git a/drivers/staging/fsl-mc/include/net.h b/drivers/staging/fsl-mc/include/net.h
new file mode 100644
index 0000000..43825b8
--- /dev/null
+++ b/drivers/staging/fsl-mc/include/net.h
@@ -0,0 +1,480 @@
+/* Copyright 2013-2015 Freescale Semiconductor Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ * * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * * Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in the
+ * documentation and/or other materials provided with the distribution.
+ * * Neither the name of the above-listed copyright holders nor the
+ * names of any contributors may be used to endorse or promote products
+ * derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef __FSL_NET_H
+#define __FSL_NET_H
+
+#define LAST_HDR_INDEX 0xFFFFFFFF
+
+/*****************************************************************************/
+/*                Protocol fields                                            */
+/*****************************************************************************/
+
+/*************************  Ethernet fields  *********************************/
+#define NH_FLD_ETH_DA                         (1)
+#define NH_FLD_ETH_SA                         (NH_FLD_ETH_DA << 1)
+#define NH_FLD_ETH_LENGTH                     (NH_FLD_ETH_DA << 2)
+#define NH_FLD_ETH_TYPE                       (NH_FLD_ETH_DA << 3)
+#define NH_FLD_ETH_FINAL_CKSUM                (NH_FLD_ETH_DA << 4)
+#define NH_FLD_ETH_PADDING                    (NH_FLD_ETH_DA << 5)
+#define NH_FLD_ETH_ALL_FIELDS                 ((NH_FLD_ETH_DA << 6) - 1)
+
+#define NH_FLD_ETH_ADDR_SIZE                 6
+
+/***************************  VLAN fields  ***********************************/
+#define NH_FLD_VLAN_VPRI                      (1)
+#define NH_FLD_VLAN_CFI                       (NH_FLD_VLAN_VPRI << 1)
+#define NH_FLD_VLAN_VID                       (NH_FLD_VLAN_VPRI << 2)
+#define NH_FLD_VLAN_LENGTH                    (NH_FLD_VLAN_VPRI << 3)
+#define NH_FLD_VLAN_TYPE                      (NH_FLD_VLAN_VPRI << 4)
+#define NH_FLD_VLAN_ALL_FIELDS                ((NH_FLD_VLAN_VPRI << 5) - 1)
+
+#define NH_FLD_VLAN_TCI                       (NH_FLD_VLAN_VPRI | \
+					       NH_FLD_VLAN_CFI | \
+					       NH_FLD_VLAN_VID)
+
+/************************  IP (generic) fields  ******************************/
+#define NH_FLD_IP_VER                         (1)
+#define NH_FLD_IP_DSCP                        (NH_FLD_IP_VER << 2)
+#define NH_FLD_IP_ECN                         (NH_FLD_IP_VER << 3)
+#define NH_FLD_IP_PROTO                       (NH_FLD_IP_VER << 4)
+#define NH_FLD_IP_SRC                         (NH_FLD_IP_VER << 5)
+#define NH_FLD_IP_DST                         (NH_FLD_IP_VER << 6)
+#define NH_FLD_IP_TOS_TC                      (NH_FLD_IP_VER << 7)
+#define NH_FLD_IP_ID                          (NH_FLD_IP_VER << 8)
+#define NH_FLD_IP_ALL_FIELDS                  ((NH_FLD_IP_VER << 9) - 1)
+
+#define NH_FLD_IP_PROTO_SIZE                  1
+
+/*****************************  IPV4 fields  *********************************/
+#define NH_FLD_IPV4_VER                       (1)
+#define NH_FLD_IPV4_HDR_LEN                   (NH_FLD_IPV4_VER << 1)
+#define NH_FLD_IPV4_TOS                       (NH_FLD_IPV4_VER << 2)
+#define NH_FLD_IPV4_TOTAL_LEN                 (NH_FLD_IPV4_VER << 3)
+#define NH_FLD_IPV4_ID                        (NH_FLD_IPV4_VER << 4)
+#define NH_FLD_IPV4_FLAG_D                    (NH_FLD_IPV4_VER << 5)
+#define NH_FLD_IPV4_FLAG_M                    (NH_FLD_IPV4_VER << 6)
+#define NH_FLD_IPV4_OFFSET                    (NH_FLD_IPV4_VER << 7)
+#define NH_FLD_IPV4_TTL                       (NH_FLD_IPV4_VER << 8)
+#define NH_FLD_IPV4_PROTO                     (NH_FLD_IPV4_VER << 9)
+#define NH_FLD_IPV4_CKSUM                     (NH_FLD_IPV4_VER << 10)
+#define NH_FLD_IPV4_SRC_IP                    (NH_FLD_IPV4_VER << 11)
+#define NH_FLD_IPV4_DST_IP                    (NH_FLD_IPV4_VER << 12)
+#define NH_FLD_IPV4_OPTS                      (NH_FLD_IPV4_VER << 13)
+#define NH_FLD_IPV4_OPTS_COUNT                (NH_FLD_IPV4_VER << 14)
+#define NH_FLD_IPV4_ALL_FIELDS                ((NH_FLD_IPV4_VER << 15) - 1)
+
+#define NH_FLD_IPV4_ADDR_SIZE                 4
+#define NH_FLD_IPV4_PROTO_SIZE                1
+
+/*****************************  IPV6 fields  *********************************/
+#define NH_FLD_IPV6_VER                       (1)
+#define NH_FLD_IPV6_TC                        (NH_FLD_IPV6_VER << 1)
+#define NH_FLD_IPV6_SRC_IP                    (NH_FLD_IPV6_VER << 2)
+#define NH_FLD_IPV6_DST_IP                    (NH_FLD_IPV6_VER << 3)
+#define NH_FLD_IPV6_NEXT_HDR                  (NH_FLD_IPV6_VER << 4)
+#define NH_FLD_IPV6_FL                        (NH_FLD_IPV6_VER << 5)
+#define NH_FLD_IPV6_HOP_LIMIT                 (NH_FLD_IPV6_VER << 6)
+#define NH_FLD_IPV6_ID			      (NH_FLD_IPV6_VER << 7)
+#define NH_FLD_IPV6_ALL_FIELDS                ((NH_FLD_IPV6_VER << 8) - 1)
+
+#define NH_FLD_IPV6_ADDR_SIZE                 16
+#define NH_FLD_IPV6_NEXT_HDR_SIZE             1
+
+/*****************************  ICMP fields  *********************************/
+#define NH_FLD_ICMP_TYPE                      (1)
+#define NH_FLD_ICMP_CODE                      (NH_FLD_ICMP_TYPE << 1)
+#define NH_FLD_ICMP_CKSUM                     (NH_FLD_ICMP_TYPE << 2)
+#define NH_FLD_ICMP_ID                        (NH_FLD_ICMP_TYPE << 3)
+#define NH_FLD_ICMP_SQ_NUM                    (NH_FLD_ICMP_TYPE << 4)
+#define NH_FLD_ICMP_ALL_FIELDS                ((NH_FLD_ICMP_TYPE << 5) - 1)
+
+#define NH_FLD_ICMP_CODE_SIZE                 1
+#define NH_FLD_ICMP_TYPE_SIZE                 1
+
+/*****************************  IGMP fields  *********************************/
+#define NH_FLD_IGMP_VERSION                   (1)
+#define NH_FLD_IGMP_TYPE                      (NH_FLD_IGMP_VERSION << 1)
+#define NH_FLD_IGMP_CKSUM                     (NH_FLD_IGMP_VERSION << 2)
+#define NH_FLD_IGMP_DATA                      (NH_FLD_IGMP_VERSION << 3)
+#define NH_FLD_IGMP_ALL_FIELDS                ((NH_FLD_IGMP_VERSION << 4) - 1)
+
+/*****************************  TCP fields  **********************************/
+#define NH_FLD_TCP_PORT_SRC                   (1)
+#define NH_FLD_TCP_PORT_DST                   (NH_FLD_TCP_PORT_SRC << 1)
+#define NH_FLD_TCP_SEQ                        (NH_FLD_TCP_PORT_SRC << 2)
+#define NH_FLD_TCP_ACK                        (NH_FLD_TCP_PORT_SRC << 3)
+#define NH_FLD_TCP_OFFSET                     (NH_FLD_TCP_PORT_SRC << 4)
+#define NH_FLD_TCP_FLAGS                      (NH_FLD_TCP_PORT_SRC << 5)
+#define NH_FLD_TCP_WINDOW                     (NH_FLD_TCP_PORT_SRC << 6)
+#define NH_FLD_TCP_CKSUM                      (NH_FLD_TCP_PORT_SRC << 7)
+#define NH_FLD_TCP_URGPTR                     (NH_FLD_TCP_PORT_SRC << 8)
+#define NH_FLD_TCP_OPTS                       (NH_FLD_TCP_PORT_SRC << 9)
+#define NH_FLD_TCP_OPTS_COUNT                 (NH_FLD_TCP_PORT_SRC << 10)
+#define NH_FLD_TCP_ALL_FIELDS                 ((NH_FLD_TCP_PORT_SRC << 11) - 1)
+
+#define NH_FLD_TCP_PORT_SIZE                  2
+
+/*****************************  UDP fields  **********************************/
+#define NH_FLD_UDP_PORT_SRC                   (1)
+#define NH_FLD_UDP_PORT_DST                   (NH_FLD_UDP_PORT_SRC << 1)
+#define NH_FLD_UDP_LEN                        (NH_FLD_UDP_PORT_SRC << 2)
+#define NH_FLD_UDP_CKSUM                      (NH_FLD_UDP_PORT_SRC << 3)
+#define NH_FLD_UDP_ALL_FIELDS                 ((NH_FLD_UDP_PORT_SRC << 4) - 1)
+
+#define NH_FLD_UDP_PORT_SIZE                  2
+
+/***************************  UDP-lite fields  *******************************/
+#define NH_FLD_UDP_LITE_PORT_SRC              (1)
+#define NH_FLD_UDP_LITE_PORT_DST              (NH_FLD_UDP_LITE_PORT_SRC << 1)
+#define NH_FLD_UDP_LITE_ALL_FIELDS \
+	((NH_FLD_UDP_LITE_PORT_SRC << 2) - 1)
+
+#define NH_FLD_UDP_LITE_PORT_SIZE             2
+
+/***************************  UDP-encap-ESP fields  **************************/
+#define NH_FLD_UDP_ENC_ESP_PORT_SRC         (1)
+#define NH_FLD_UDP_ENC_ESP_PORT_DST         (NH_FLD_UDP_ENC_ESP_PORT_SRC << 1)
+#define NH_FLD_UDP_ENC_ESP_LEN              (NH_FLD_UDP_ENC_ESP_PORT_SRC << 2)
+#define NH_FLD_UDP_ENC_ESP_CKSUM            (NH_FLD_UDP_ENC_ESP_PORT_SRC << 3)
+#define NH_FLD_UDP_ENC_ESP_SPI              (NH_FLD_UDP_ENC_ESP_PORT_SRC << 4)
+#define NH_FLD_UDP_ENC_ESP_SEQUENCE_NUM     (NH_FLD_UDP_ENC_ESP_PORT_SRC << 5)
+#define NH_FLD_UDP_ENC_ESP_ALL_FIELDS \
+	((NH_FLD_UDP_ENC_ESP_PORT_SRC << 6) - 1)
+
+#define NH_FLD_UDP_ENC_ESP_PORT_SIZE        2
+#define NH_FLD_UDP_ENC_ESP_SPI_SIZE         4
+
+/*****************************  SCTP fields  *********************************/
+#define NH_FLD_SCTP_PORT_SRC                  (1)
+#define NH_FLD_SCTP_PORT_DST                  (NH_FLD_SCTP_PORT_SRC << 1)
+#define NH_FLD_SCTP_VER_TAG                   (NH_FLD_SCTP_PORT_SRC << 2)
+#define NH_FLD_SCTP_CKSUM                     (NH_FLD_SCTP_PORT_SRC << 3)
+#define NH_FLD_SCTP_ALL_FIELDS                ((NH_FLD_SCTP_PORT_SRC << 4) - 1)
+
+#define NH_FLD_SCTP_PORT_SIZE                 2
+
+/*****************************  DCCP fields  *********************************/
+#define NH_FLD_DCCP_PORT_SRC                  (1)
+#define NH_FLD_DCCP_PORT_DST                  (NH_FLD_DCCP_PORT_SRC << 1)
+#define NH_FLD_DCCP_ALL_FIELDS                ((NH_FLD_DCCP_PORT_SRC << 2) - 1)
+
+#define NH_FLD_DCCP_PORT_SIZE                 2
+
+/*****************************  IPHC fields  *********************************/
+#define NH_FLD_IPHC_CID                       (1)
+#define NH_FLD_IPHC_CID_TYPE                  (NH_FLD_IPHC_CID << 1)
+#define NH_FLD_IPHC_HCINDEX                   (NH_FLD_IPHC_CID << 2)
+#define NH_FLD_IPHC_GEN                       (NH_FLD_IPHC_CID << 3)
+#define NH_FLD_IPHC_D_BIT                     (NH_FLD_IPHC_CID << 4)
+#define NH_FLD_IPHC_ALL_FIELDS                ((NH_FLD_IPHC_CID << 5) - 1)
+
+/*****************************  SCTP fields  *********************************/
+#define NH_FLD_SCTP_CHUNK_DATA_TYPE           (1)
+#define NH_FLD_SCTP_CHUNK_DATA_FLAGS          (NH_FLD_SCTP_CHUNK_DATA_TYPE << 1)
+#define NH_FLD_SCTP_CHUNK_DATA_LENGTH         (NH_FLD_SCTP_CHUNK_DATA_TYPE << 2)
+#define NH_FLD_SCTP_CHUNK_DATA_TSN            (NH_FLD_SCTP_CHUNK_DATA_TYPE << 3)
+#define NH_FLD_SCTP_CHUNK_DATA_STREAM_ID      (NH_FLD_SCTP_CHUNK_DATA_TYPE << 4)
+#define NH_FLD_SCTP_CHUNK_DATA_STREAM_SQN     (NH_FLD_SCTP_CHUNK_DATA_TYPE << 5)
+#define NH_FLD_SCTP_CHUNK_DATA_PAYLOAD_PID    (NH_FLD_SCTP_CHUNK_DATA_TYPE << 6)
+#define NH_FLD_SCTP_CHUNK_DATA_UNORDERED      (NH_FLD_SCTP_CHUNK_DATA_TYPE << 7)
+#define NH_FLD_SCTP_CHUNK_DATA_BEGGINING      (NH_FLD_SCTP_CHUNK_DATA_TYPE << 8)
+#define NH_FLD_SCTP_CHUNK_DATA_END            (NH_FLD_SCTP_CHUNK_DATA_TYPE << 9)
+#define NH_FLD_SCTP_CHUNK_DATA_ALL_FIELDS \
+	((NH_FLD_SCTP_CHUNK_DATA_TYPE << 10) - 1)
+
+/***************************  L2TPV2 fields  *********************************/
+#define NH_FLD_L2TPV2_TYPE_BIT                (1)
+#define NH_FLD_L2TPV2_LENGTH_BIT              (NH_FLD_L2TPV2_TYPE_BIT << 1)
+#define NH_FLD_L2TPV2_SEQUENCE_BIT            (NH_FLD_L2TPV2_TYPE_BIT << 2)
+#define NH_FLD_L2TPV2_OFFSET_BIT              (NH_FLD_L2TPV2_TYPE_BIT << 3)
+#define NH_FLD_L2TPV2_PRIORITY_BIT            (NH_FLD_L2TPV2_TYPE_BIT << 4)
+#define NH_FLD_L2TPV2_VERSION                 (NH_FLD_L2TPV2_TYPE_BIT << 5)
+#define NH_FLD_L2TPV2_LEN                     (NH_FLD_L2TPV2_TYPE_BIT << 6)
+#define NH_FLD_L2TPV2_TUNNEL_ID               (NH_FLD_L2TPV2_TYPE_BIT << 7)
+#define NH_FLD_L2TPV2_SESSION_ID              (NH_FLD_L2TPV2_TYPE_BIT << 8)
+#define NH_FLD_L2TPV2_NS                      (NH_FLD_L2TPV2_TYPE_BIT << 9)
+#define NH_FLD_L2TPV2_NR                      (NH_FLD_L2TPV2_TYPE_BIT << 10)
+#define NH_FLD_L2TPV2_OFFSET_SIZE             (NH_FLD_L2TPV2_TYPE_BIT << 11)
+#define NH_FLD_L2TPV2_FIRST_BYTE              (NH_FLD_L2TPV2_TYPE_BIT << 12)
+#define NH_FLD_L2TPV2_ALL_FIELDS \
+	((NH_FLD_L2TPV2_TYPE_BIT << 13) - 1)
+
+/***************************  L2TPV3 fields  *********************************/
+#define NH_FLD_L2TPV3_CTRL_TYPE_BIT           (1)
+#define NH_FLD_L2TPV3_CTRL_LENGTH_BIT         (NH_FLD_L2TPV3_CTRL_TYPE_BIT << 1)
+#define NH_FLD_L2TPV3_CTRL_SEQUENCE_BIT       (NH_FLD_L2TPV3_CTRL_TYPE_BIT << 2)
+#define NH_FLD_L2TPV3_CTRL_VERSION            (NH_FLD_L2TPV3_CTRL_TYPE_BIT << 3)
+#define NH_FLD_L2TPV3_CTRL_LENGTH             (NH_FLD_L2TPV3_CTRL_TYPE_BIT << 4)
+#define NH_FLD_L2TPV3_CTRL_CONTROL            (NH_FLD_L2TPV3_CTRL_TYPE_BIT << 5)
+#define NH_FLD_L2TPV3_CTRL_SENT               (NH_FLD_L2TPV3_CTRL_TYPE_BIT << 6)
+#define NH_FLD_L2TPV3_CTRL_RECV               (NH_FLD_L2TPV3_CTRL_TYPE_BIT << 7)
+#define NH_FLD_L2TPV3_CTRL_FIRST_BYTE         (NH_FLD_L2TPV3_CTRL_TYPE_BIT << 8)
+#define NH_FLD_L2TPV3_CTRL_ALL_FIELDS \
+	((NH_FLD_L2TPV3_CTRL_TYPE_BIT << 9) - 1)
+
+#define NH_FLD_L2TPV3_SESS_TYPE_BIT           (1)
+#define NH_FLD_L2TPV3_SESS_VERSION            (NH_FLD_L2TPV3_SESS_TYPE_BIT << 1)
+#define NH_FLD_L2TPV3_SESS_ID                 (NH_FLD_L2TPV3_SESS_TYPE_BIT << 2)
+#define NH_FLD_L2TPV3_SESS_COOKIE             (NH_FLD_L2TPV3_SESS_TYPE_BIT << 3)
+#define NH_FLD_L2TPV3_SESS_ALL_FIELDS \
+	((NH_FLD_L2TPV3_SESS_TYPE_BIT << 4) - 1)
+
+/****************************  PPP fields  ***********************************/
+#define NH_FLD_PPP_PID                        (1)
+#define NH_FLD_PPP_COMPRESSED                 (NH_FLD_PPP_PID << 1)
+#define NH_FLD_PPP_ALL_FIELDS                 ((NH_FLD_PPP_PID << 2) - 1)
+
+/**************************  PPPoE fields  ***********************************/
+#define NH_FLD_PPPOE_VER                      (1)
+#define NH_FLD_PPPOE_TYPE                     (NH_FLD_PPPOE_VER << 1)
+#define NH_FLD_PPPOE_CODE                     (NH_FLD_PPPOE_VER << 2)
+#define NH_FLD_PPPOE_SID                      (NH_FLD_PPPOE_VER << 3)
+#define NH_FLD_PPPOE_LEN                      (NH_FLD_PPPOE_VER << 4)
+#define NH_FLD_PPPOE_SESSION                  (NH_FLD_PPPOE_VER << 5)
+#define NH_FLD_PPPOE_PID                      (NH_FLD_PPPOE_VER << 6)
+#define NH_FLD_PPPOE_ALL_FIELDS               ((NH_FLD_PPPOE_VER << 7) - 1)
+
+/*************************  PPP-Mux fields  **********************************/
+#define NH_FLD_PPPMUX_PID                     (1)
+#define NH_FLD_PPPMUX_CKSUM                   (NH_FLD_PPPMUX_PID << 1)
+#define NH_FLD_PPPMUX_COMPRESSED              (NH_FLD_PPPMUX_PID << 2)
+#define NH_FLD_PPPMUX_ALL_FIELDS              ((NH_FLD_PPPMUX_PID << 3) - 1)
+
+/***********************  PPP-Mux sub-frame fields  **************************/
+#define NH_FLD_PPPMUX_SUBFRM_PFF            (1)
+#define NH_FLD_PPPMUX_SUBFRM_LXT            (NH_FLD_PPPMUX_SUBFRM_PFF << 1)
+#define NH_FLD_PPPMUX_SUBFRM_LEN            (NH_FLD_PPPMUX_SUBFRM_PFF << 2)
+#define NH_FLD_PPPMUX_SUBFRM_PID            (NH_FLD_PPPMUX_SUBFRM_PFF << 3)
+#define NH_FLD_PPPMUX_SUBFRM_USE_PID        (NH_FLD_PPPMUX_SUBFRM_PFF << 4)
+#define NH_FLD_PPPMUX_SUBFRM_ALL_FIELDS \
+	((NH_FLD_PPPMUX_SUBFRM_PFF << 5) - 1)
+
+/***************************  LLC fields  ************************************/
+#define NH_FLD_LLC_DSAP                       (1)
+#define NH_FLD_LLC_SSAP                       (NH_FLD_LLC_DSAP << 1)
+#define NH_FLD_LLC_CTRL                       (NH_FLD_LLC_DSAP << 2)
+#define NH_FLD_LLC_ALL_FIELDS                 ((NH_FLD_LLC_DSAP << 3) - 1)
+
+/***************************  NLPID fields  **********************************/
+#define NH_FLD_NLPID_NLPID                    (1)
+#define NH_FLD_NLPID_ALL_FIELDS               ((NH_FLD_NLPID_NLPID << 1) - 1)
+
+/***************************  SNAP fields  ***********************************/
+#define NH_FLD_SNAP_OUI                       (1)
+#define NH_FLD_SNAP_PID                       (NH_FLD_SNAP_OUI << 1)
+#define NH_FLD_SNAP_ALL_FIELDS                ((NH_FLD_SNAP_OUI << 2) - 1)
+
+/***************************  LLC SNAP fields  *******************************/
+#define NH_FLD_LLC_SNAP_TYPE                  (1)
+#define NH_FLD_LLC_SNAP_ALL_FIELDS            ((NH_FLD_LLC_SNAP_TYPE << 1) - 1)
+
+#define NH_FLD_ARP_HTYPE                      (1)
+#define NH_FLD_ARP_PTYPE                      (NH_FLD_ARP_HTYPE << 1)
+#define NH_FLD_ARP_HLEN                       (NH_FLD_ARP_HTYPE << 2)
+#define NH_FLD_ARP_PLEN                       (NH_FLD_ARP_HTYPE << 3)
+#define NH_FLD_ARP_OPER                       (NH_FLD_ARP_HTYPE << 4)
+#define NH_FLD_ARP_SHA                        (NH_FLD_ARP_HTYPE << 5)
+#define NH_FLD_ARP_SPA                        (NH_FLD_ARP_HTYPE << 6)
+#define NH_FLD_ARP_THA                        (NH_FLD_ARP_HTYPE << 7)
+#define NH_FLD_ARP_TPA                        (NH_FLD_ARP_HTYPE << 8)
+#define NH_FLD_ARP_ALL_FIELDS                 ((NH_FLD_ARP_HTYPE << 9) - 1)
+
+/***************************  RFC2684 fields  ********************************/
+#define NH_FLD_RFC2684_LLC                    (1)
+#define NH_FLD_RFC2684_NLPID                  (NH_FLD_RFC2684_LLC << 1)
+#define NH_FLD_RFC2684_OUI                    (NH_FLD_RFC2684_LLC << 2)
+#define NH_FLD_RFC2684_PID                    (NH_FLD_RFC2684_LLC << 3)
+#define NH_FLD_RFC2684_VPN_OUI                (NH_FLD_RFC2684_LLC << 4)
+#define NH_FLD_RFC2684_VPN_IDX                (NH_FLD_RFC2684_LLC << 5)
+#define NH_FLD_RFC2684_ALL_FIELDS             ((NH_FLD_RFC2684_LLC << 6) - 1)
+
+/***************************  User defined fields  ***************************/
+#define NH_FLD_USER_DEFINED_SRCPORT           (1)
+#define NH_FLD_USER_DEFINED_PCDID             (NH_FLD_USER_DEFINED_SRCPORT << 1)
+#define NH_FLD_USER_DEFINED_ALL_FIELDS \
+	((NH_FLD_USER_DEFINED_SRCPORT << 2) - 1)
+
+/***************************  Payload fields  ********************************/
+#define NH_FLD_PAYLOAD_BUFFER                 (1)
+#define NH_FLD_PAYLOAD_SIZE                   (NH_FLD_PAYLOAD_BUFFER << 1)
+#define NH_FLD_MAX_FRM_SIZE                   (NH_FLD_PAYLOAD_BUFFER << 2)
+#define NH_FLD_MIN_FRM_SIZE                   (NH_FLD_PAYLOAD_BUFFER << 3)
+#define NH_FLD_PAYLOAD_TYPE                   (NH_FLD_PAYLOAD_BUFFER << 4)
+#define NH_FLD_FRAME_SIZE                     (NH_FLD_PAYLOAD_BUFFER << 5)
+#define NH_FLD_PAYLOAD_ALL_FIELDS             ((NH_FLD_PAYLOAD_BUFFER << 6) - 1)
+
+/***************************  GRE fields  ************************************/
+#define NH_FLD_GRE_TYPE                       (1)
+#define NH_FLD_GRE_ALL_FIELDS                 ((NH_FLD_GRE_TYPE << 1) - 1)
+
+/***************************  MINENCAP fields  *******************************/
+#define NH_FLD_MINENCAP_SRC_IP                (1)
+#define NH_FLD_MINENCAP_DST_IP                (NH_FLD_MINENCAP_SRC_IP << 1)
+#define NH_FLD_MINENCAP_TYPE                  (NH_FLD_MINENCAP_SRC_IP << 2)
+#define NH_FLD_MINENCAP_ALL_FIELDS \
+	((NH_FLD_MINENCAP_SRC_IP << 3) - 1)
+
+/***************************  IPSEC AH fields  *******************************/
+#define NH_FLD_IPSEC_AH_SPI                   (1)
+#define NH_FLD_IPSEC_AH_NH                    (NH_FLD_IPSEC_AH_SPI << 1)
+#define NH_FLD_IPSEC_AH_ALL_FIELDS            ((NH_FLD_IPSEC_AH_SPI << 2) - 1)
+
+/***************************  IPSEC ESP fields  ******************************/
+#define NH_FLD_IPSEC_ESP_SPI                  (1)
+#define NH_FLD_IPSEC_ESP_SEQUENCE_NUM         (NH_FLD_IPSEC_ESP_SPI << 1)
+#define NH_FLD_IPSEC_ESP_ALL_FIELDS           ((NH_FLD_IPSEC_ESP_SPI << 2) - 1)
+
+#define NH_FLD_IPSEC_ESP_SPI_SIZE             4
+
+/***************************  MPLS fields  ***********************************/
+#define NH_FLD_MPLS_LABEL_STACK               (1)
+#define NH_FLD_MPLS_LABEL_STACK_ALL_FIELDS \
+	((NH_FLD_MPLS_LABEL_STACK << 1) - 1)
+
+/***************************  MACSEC fields  *********************************/
+#define NH_FLD_MACSEC_SECTAG                  (1)
+#define NH_FLD_MACSEC_ALL_FIELDS              ((NH_FLD_MACSEC_SECTAG << 1) - 1)
+
+/***************************  GTP fields  ************************************/
+#define NH_FLD_GTP_TEID                       (1)
+
+/* Protocol options */
+
+/* Ethernet options */
+#define	NH_OPT_ETH_BROADCAST			1
+#define	NH_OPT_ETH_MULTICAST			2
+#define	NH_OPT_ETH_UNICAST			3
+#define	NH_OPT_ETH_BPDU				4
+
+#define NH_ETH_IS_MULTICAST_ADDR(addr) (addr[0] & 0x01)
+/* also applicable for broadcast */
+
+/* VLAN options */
+#define	NH_OPT_VLAN_CFI				1
+
+/* IPV4 options */
+#define	NH_OPT_IPV4_UNICAST			1
+#define	NH_OPT_IPV4_MULTICAST			2
+#define	NH_OPT_IPV4_BROADCAST			3
+#define	NH_OPT_IPV4_OPTION			4
+#define	NH_OPT_IPV4_FRAG			5
+#define	NH_OPT_IPV4_INITIAL_FRAG		6
+
+/* IPV6 options */
+#define	NH_OPT_IPV6_UNICAST			1
+#define	NH_OPT_IPV6_MULTICAST			2
+#define	NH_OPT_IPV6_OPTION			3
+#define	NH_OPT_IPV6_FRAG			4
+#define	NH_OPT_IPV6_INITIAL_FRAG		5
+
+/* General IP options (may be used for any version) */
+#define	NH_OPT_IP_FRAG				1
+#define	NH_OPT_IP_INITIAL_FRAG			2
+#define	NH_OPT_IP_OPTION			3
+
+/* Minenc. options */
+#define	NH_OPT_MINENCAP_SRC_ADDR_PRESENT	1
+
+/* GRE. options */
+#define	NH_OPT_GRE_ROUTING_PRESENT		1
+
+/* TCP options */
+#define	NH_OPT_TCP_OPTIONS			1
+#define	NH_OPT_TCP_CONTROL_HIGH_BITS		2
+#define	NH_OPT_TCP_CONTROL_LOW_BITS		3
+
+/* CAPWAP options */
+#define	NH_OPT_CAPWAP_DTLS			1
+
+enum net_prot {
+	NET_PROT_NONE = 0,
+	NET_PROT_PAYLOAD,
+	NET_PROT_ETH,
+	NET_PROT_VLAN,
+	NET_PROT_IPV4,
+	NET_PROT_IPV6,
+	NET_PROT_IP,
+	NET_PROT_TCP,
+	NET_PROT_UDP,
+	NET_PROT_UDP_LITE,
+	NET_PROT_IPHC,
+	NET_PROT_SCTP,
+	NET_PROT_SCTP_CHUNK_DATA,
+	NET_PROT_PPPOE,
+	NET_PROT_PPP,
+	NET_PROT_PPPMUX,
+	NET_PROT_PPPMUX_SUBFRM,
+	NET_PROT_L2TPV2,
+	NET_PROT_L2TPV3_CTRL,
+	NET_PROT_L2TPV3_SESS,
+	NET_PROT_LLC,
+	NET_PROT_LLC_SNAP,
+	NET_PROT_NLPID,
+	NET_PROT_SNAP,
+	NET_PROT_MPLS,
+	NET_PROT_IPSEC_AH,
+	NET_PROT_IPSEC_ESP,
+	NET_PROT_UDP_ENC_ESP, /* RFC 3948 */
+	NET_PROT_MACSEC,
+	NET_PROT_GRE,
+	NET_PROT_MINENCAP,
+	NET_PROT_DCCP,
+	NET_PROT_ICMP,
+	NET_PROT_IGMP,
+	NET_PROT_ARP,
+	NET_PROT_CAPWAP_DATA,
+	NET_PROT_CAPWAP_CTRL,
+	NET_PROT_RFC2684,
+	NET_PROT_ICMPV6,
+	NET_PROT_FCOE,
+	NET_PROT_FIP,
+	NET_PROT_ISCSI,
+	NET_PROT_GTP,
+	NET_PROT_USER_DEFINED_L2,
+	NET_PROT_USER_DEFINED_L3,
+	NET_PROT_USER_DEFINED_L4,
+	NET_PROT_USER_DEFINED_L5,
+	NET_PROT_USER_DEFINED_SHIM1,
+	NET_PROT_USER_DEFINED_SHIM2,
+
+	NET_PROT_DUMMY_LAST
+};
+
+/*! IEEE8021.Q */
+#define NH_IEEE8021Q_ETYPE  0x8100
+#define NH_IEEE8021Q_HDR(etype, pcp, dei, vlan_id)      \
+	    ((((uint32_t)(etype & 0xFFFF)) << 16) |       \
+	    (((uint32_t)(pcp & 0x07)) << 13) |          \
+	    (((uint32_t)(dei & 0x01)) << 12) |          \
+	    (((uint32_t)(vlan_id & 0xFFF))))
+
+#endif /* __FSL_NET_H */
-- 
2.1.0.27.g96db324

